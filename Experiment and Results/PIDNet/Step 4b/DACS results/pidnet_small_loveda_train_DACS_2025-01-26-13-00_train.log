2025-01-26 13:00:31,782 Namespace(cfg='configs/loveda/pidnet_small_loveda_train_DACS.yaml', seed=304, opts=['GPUS', '[0]', 'TRAIN.BATCH_SIZE_PER_GPU', '6'])
2025-01-26 13:00:31,782 AUTO_RESUME: False
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  DATASET: loveDa
  EXTRA_TRAIN_SET: 
  NUM_CLASSES: 8
  ROOT: data/
  SOURCE_DATASET: loveDa
  SOURCE_TEST_SET: list/loveDA-Urban/val.lst
  SOURCE_TRAIN_SET: list/loveDA-Urban/train.lst
  TARGET_DATASET: loveDa
  TARGET_SET: list/loveDa/val.lst
  TARGET_TEST_SET: list/loveDa-Rural/val.lst
  TARGET_TRAIN_SET: list/loveDa-Rural/train.lst
  TEST_SET: list/loveDa/val.lst
  TRAIN_SET: list/loveDa/train.lst
GPUS: (0,)
LOG_DIR: log
LOSS:
  BALANCE_WEIGHTS: [0.4, 1.0]
  CLASS_BALANCE: False
  OHEMKEEP: 131072
  OHEMTHRES: 0.7
  SB_WEIGHTS: 0.5
  USE_DICE: False
  USE_FOCAL: False
  USE_OHEM: True
MODEL:
  ALIGN_CORNERS: True
  NAME: pidnet_small
  NUM_OUTPUTS: 2
  PRETRAINED: pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar
OUTPUT_DIR: output
PIN_MEMORY: True
PRINT_FREQ: 10
TEST:
  BASE_SIZE: 1024
  BATCH_SIZE_PER_GPU: 6
  FLIP_TEST: False
  IMAGE_SIZE: [1024, 1024]
  MODEL_FILE: 
  MULTI_SCALE: False
  OUTPUT_INDEX: 1
TRAIN:
  ADVERSARIAL: False
  AUG: True
  AUG1: False
  AUG2: True
  AUG3: True
  AUG4: False
  AUG_CHANCE: True
  BASE_SIZE: 720
  BATCH_SIZE_PER_GPU: 6
  BEGIN_EPOCH: 0
  D1: False
  END_EPOCH: 20
  EVAL_INTERVAL: 1
  EXTRA_EPOCH: 0
  EXTRA_LR: 0.001
  FLIP: True
  GAN: Vanilla
  IGNORE_LABEL: 0
  IMAGE_SIZE: [720, 720]
  LAMBDA_ADV1: 0.001
  LAMBDA_ADV2: 0.001
  LR: 0.001
  LR_D1: 0.001
  LR_D2: 0.001
  MOMENTUM: 0.9
  MULTI_SCALE: True
  NESTEROV: False
  OPTIMIZER: adam
  RESUME: False
  SCALE_FACTOR: 16
  SCHEDULER: True
  SHUFFLE: True
  WD: 0.0005
WORKERS: 0
2025-01-26 13:00:32,576 Attention!!!
2025-01-26 13:00:32,576 Loaded 302 parameters!
2025-01-26 13:00:32,576 Over!!!
2025-01-26 13:00:33,103 Attention!!!
2025-01-26 13:00:33,103 Loaded 302 parameters!
2025-01-26 13:00:33,103 Over!!!
2025-01-26 13:00:43,123 Epoch: [0/20] Iter:[0/286], Time: 5.70, lr: [0.0002], Loss: 7.457406, Acc:0.228910, Source Loss: 5.258076, Target Loss: 3.077286, MixUp Loss: 4.398661
2025-01-26 13:01:03,666 Epoch: [0/20] Iter:[10/286], Time: 2.76, lr: [0.00019968528716020792], Loss: 5.074372, Acc:0.347249, Source Loss: 3.564499, Target Loss: 2.540678, MixUp Loss: 1.951246
2025-01-26 13:01:23,908 Epoch: [0/20] Iter:[20/286], Time: 2.41, lr: [0.00019937051919947566], Loss: 4.042661, Acc:0.383190, Source Loss: 2.784773, Target Loss: 2.341356, MixUp Loss: 1.743394
2025-01-26 13:01:43,421 Epoch: [0/20] Iter:[30/286], Time: 2.26, lr: [0.00019905569601142006], Loss: 3.658977, Acc:0.428439, Source Loss: 2.526794, Target Loss: 2.168699, MixUp Loss: 2.174288
2025-01-26 13:02:03,604 Epoch: [0/20] Iter:[40/286], Time: 2.20, lr: [0.00019874081748926526], Loss: 3.414919, Acc:0.464132, Source Loss: 2.355636, Target Loss: 2.011966, MixUp Loss: 1.792377
2025-01-26 13:02:23,058 Epoch: [0/20] Iter:[50/286], Time: 2.15, lr: [0.00019842588352584058], Loss: 3.244680, Acc:0.484867, Source Loss: 2.248276, Target Loss: 1.898113, MixUp Loss: 1.705217
2025-01-26 13:02:43,295 Epoch: [0/20] Iter:[60/286], Time: 2.13, lr: [0.00019811089401357843], Loss: 3.105760, Acc:0.489851, Source Loss: 2.166138, Target Loss: 1.785138, MixUp Loss: 1.720351
2025-01-26 13:03:02,996 Epoch: [0/20] Iter:[70/286], Time: 2.11, lr: [0.00019779584884451205], Loss: 2.986103, Acc:0.501233, Source Loss: 2.073614, Target Loss: 1.730515, MixUp Loss: 1.210035
2025-01-26 13:03:22,910 Epoch: [0/20] Iter:[80/286], Time: 2.09, lr: [0.00019748074791027339], Loss: 2.900531, Acc:0.512875, Source Loss: 2.020520, Target Loss: 1.681386, MixUp Loss: 1.165593
2025-01-26 13:03:43,057 Epoch: [0/20] Iter:[90/286], Time: 2.09, lr: [0.00019716559110209074], Loss: 2.841089, Acc:0.519493, Source Loss: 1.976104, Target Loss: 1.638307, MixUp Loss: 1.196105
2025-01-26 13:04:02,480 Epoch: [0/20] Iter:[100/286], Time: 2.07, lr: [0.00019685037831078682], Loss: 2.772123, Acc:0.529415, Source Loss: 1.928075, Target Loss: 1.597127, MixUp Loss: 1.799218
2025-01-26 13:04:22,669 Epoch: [0/20] Iter:[110/286], Time: 2.07, lr: [0.00019653510942677625], Loss: 2.720704, Acc:0.537220, Source Loss: 1.892442, Target Loss: 1.565776, MixUp Loss: 1.516235
2025-01-26 13:04:42,201 Epoch: [0/20] Iter:[120/286], Time: 2.06, lr: [0.00019621978434006338], Loss: 2.680763, Acc:0.548442, Source Loss: 1.866989, Target Loss: 1.538317, MixUp Loss: 0.906426
2025-01-26 13:05:02,743 Epoch: [0/20] Iter:[130/286], Time: 2.06, lr: [0.00019590440294024007], Loss: 2.648602, Acc:0.553501, Source Loss: 1.845192, Target Loss: 1.514752, MixUp Loss: 0.983940
2025-01-26 13:05:22,770 Epoch: [0/20] Iter:[140/286], Time: 2.05, lr: [0.00019558896511648338], Loss: 2.612521, Acc:0.558951, Source Loss: 1.819934, Target Loss: 1.488166, MixUp Loss: 1.386096
2025-01-26 13:05:42,784 Epoch: [0/20] Iter:[150/286], Time: 2.05, lr: [0.00019527347075755326], Loss: 2.590157, Acc:0.562598, Source Loss: 1.806239, Target Loss: 1.461743, MixUp Loss: 0.991549
2025-01-26 13:06:03,170 Epoch: [0/20] Iter:[160/286], Time: 2.05, lr: [0.00019495791975179016], Loss: 2.558862, Acc:0.567360, Source Loss: 1.778255, Target Loss: 1.460777, MixUp Loss: 0.846443
2025-01-26 13:06:22,849 Epoch: [0/20] Iter:[170/286], Time: 2.04, lr: [0.0001946423119871129], Loss: 2.533595, Acc:0.571687, Source Loss: 1.760641, Target Loss: 1.442064, MixUp Loss: 1.405208
2025-01-26 13:06:43,208 Epoch: [0/20] Iter:[180/286], Time: 2.04, lr: [0.000194326647351016], Loss: 2.512812, Acc:0.576155, Source Loss: 1.747134, Target Loss: 1.424953, MixUp Loss: 1.131545
2025-01-26 13:07:02,688 Epoch: [0/20] Iter:[190/286], Time: 2.04, lr: [0.00019401092573056758], Loss: 2.482354, Acc:0.579023, Source Loss: 1.723807, Target Loss: 1.413758, MixUp Loss: 1.390049
2025-01-26 13:07:23,146 Epoch: [0/20] Iter:[200/286], Time: 2.04, lr: [0.00019369514701240685], Loss: 2.453358, Acc:0.583871, Source Loss: 1.703762, Target Loss: 1.402069, MixUp Loss: 1.069116
2025-01-26 13:07:43,442 Epoch: [0/20] Iter:[210/286], Time: 2.04, lr: [0.00019337931108274169], Loss: 2.434261, Acc:0.586802, Source Loss: 1.689925, Target Loss: 1.397963, MixUp Loss: 1.063992
2025-01-26 13:08:02,977 Epoch: [0/20] Iter:[220/286], Time: 2.03, lr: [0.00019306341782734628], Loss: 2.423028, Acc:0.592356, Source Loss: 1.683861, Target Loss: 1.388314, MixUp Loss: 1.117979
2025-01-26 13:08:23,192 Epoch: [0/20] Iter:[230/286], Time: 2.03, lr: [0.0001927474671315586], Loss: 2.403364, Acc:0.595974, Source Loss: 1.670676, Target Loss: 1.380174, MixUp Loss: 1.109613
2025-01-26 13:08:42,726 Epoch: [0/20] Iter:[240/286], Time: 2.03, lr: [0.00019243145888027797], Loss: 2.398229, Acc:0.600380, Source Loss: 1.670965, Target Loss: 1.366317, MixUp Loss: 1.199643
2025-01-26 13:09:03,336 Epoch: [0/20] Iter:[250/286], Time: 2.03, lr: [0.0001921153929579627], Loss: 2.380889, Acc:0.601730, Source Loss: 1.657146, Target Loss: 1.356157, MixUp Loss: 1.062566
2025-01-26 13:09:23,655 Epoch: [0/20] Iter:[260/286], Time: 2.03, lr: [0.0001917992692486273], Loss: 2.368243, Acc:0.603485, Source Loss: 1.648208, Target Loss: 1.351198, MixUp Loss: 1.279804
2025-01-26 13:09:43,626 Epoch: [0/20] Iter:[270/286], Time: 2.03, lr: [0.00019148308763584034], Loss: 2.359765, Acc:0.605319, Source Loss: 1.644307, Target Loss: 1.341257, MixUp Loss: 0.895238
2025-01-26 13:10:03,795 Epoch: [0/20] Iter:[280/286], Time: 2.03, lr: [0.00019116684800272153], Loss: 2.341607, Acc:0.608082, Source Loss: 1.630202, Target Loss: 1.334714, MixUp Loss: 1.250191
2025-01-26 13:15:51,917 0 [0.         0.39787044 0.10904349 0.08132832 0.26236087 0.14563135
 0.02117071 0.0163813 ] 0.1292233098150108
2025-01-26 13:15:51,918 1 [0.         0.41384087 0.2098956  0.16615778 0.33809753 0.04928633
 0.00463326 0.01501057] 0.14961524371933502
2025-01-26 13:15:51,920 Epoch 1/20 - Source Loss: 1.6298, Target Loss: 1.3303
2025-01-26 13:15:51,920 => saving checkpoint to output/loveDa/pidnet_small_loveda_train_DACScheckpoint.pth.tar
2025-01-26 13:15:52,221 Epoch [0], Loss: 2.340, MeanIoU: 0.1496, best_mIoU: 0.1496
2025-01-26 13:15:52,222 IoU per class: [0.         0.41384087 0.2098956  0.16615778 0.33809753 0.04928633
 0.00463326 0.01501057]
2025-01-26 13:15:52,386 Attention!!!
2025-01-26 13:15:52,386 Loaded 302 parameters!
2025-01-26 13:15:52,386 Over!!!
2025-01-26 13:15:55,060 Epoch: [1/20] Iter:[0/286], Time: 2.47, lr: [0.0003819541526485999], Loss: 1.781202, Acc:0.556109, Source Loss: 1.229811, Target Loss: 1.126291, MixUp Loss: 1.102783
2025-01-26 13:16:15,131 Epoch: [1/20] Iter:[10/286], Time: 2.05, lr: [0.00038132148722882446], Loss: 1.997492, Acc:0.587499, Source Loss: 1.390565, Target Loss: 1.133441, MixUp Loss: 1.091665
2025-01-26 13:16:35,638 Epoch: [1/20] Iter:[20/286], Time: 2.05, lr: [0.0003806887051563718], Loss: 2.056277, Acc:0.564820, Source Loss: 1.441314, Target Loss: 1.113145, MixUp Loss: 1.365796
2025-01-26 13:16:55,893 Epoch: [1/20] Iter:[30/286], Time: 2.04, lr: [0.0003800558061942085], Loss: 2.043338, Acc:0.581936, Source Loss: 1.437322, Target Loss: 1.118982, MixUp Loss: 1.069117
2025-01-26 13:17:16,732 Epoch: [1/20] Iter:[40/286], Time: 2.05, lr: [0.0003794227901043799], Loss: 2.044055, Acc:0.576084, Source Loss: 1.432949, Target Loss: 1.118631, MixUp Loss: 1.147508
2025-01-26 13:17:37,492 Epoch: [1/20] Iter:[50/286], Time: 2.06, lr: [0.0003787896566480047], Loss: 2.068826, Acc:0.591047, Source Loss: 1.447584, Target Loss: 1.135182, MixUp Loss: 1.742036
2025-01-26 13:17:57,302 Epoch: [1/20] Iter:[60/286], Time: 2.04, lr: [0.00037815640558527006], Loss: 2.043824, Acc:0.597700, Source Loss: 1.433503, Target Loss: 1.124356, MixUp Loss: 1.259074
2025-01-26 13:18:17,837 Epoch: [1/20] Iter:[70/286], Time: 2.05, lr: [0.0003775230366754255], Loss: 2.039695, Acc:0.597824, Source Loss: 1.428853, Target Loss: 1.137072, MixUp Loss: 0.846731
2025-01-26 13:18:37,719 Epoch: [1/20] Iter:[80/286], Time: 2.04, lr: [0.0003768895496767782], Loss: 2.026233, Acc:0.599047, Source Loss: 1.419468, Target Loss: 1.123324, MixUp Loss: 1.165772
2025-01-26 13:18:58,219 Epoch: [1/20] Iter:[90/286], Time: 2.04, lr: [0.00037625594434668726], Loss: 2.036898, Acc:0.602773, Source Loss: 1.430295, Target Loss: 1.117788, MixUp Loss: 1.318167
2025-01-26 13:19:18,456 Epoch: [1/20] Iter:[100/286], Time: 2.04, lr: [0.0003756222204415582], Loss: 2.024402, Acc:0.603198, Source Loss: 1.423225, Target Loss: 1.103469, MixUp Loss: 0.851676
2025-01-26 13:19:38,275 Epoch: [1/20] Iter:[110/286], Time: 2.03, lr: [0.0003749883777168373], Loss: 2.030548, Acc:0.602937, Source Loss: 1.425474, Target Loss: 1.112503, MixUp Loss: 1.395815
2025-01-26 13:19:58,562 Epoch: [1/20] Iter:[120/286], Time: 2.03, lr: [0.00037435441592700613], Loss: 2.033915, Acc:0.604821, Source Loss: 1.432274, Target Loss: 1.094482, MixUp Loss: 0.876953
2025-01-26 13:20:18,366 Epoch: [1/20] Iter:[130/286], Time: 2.03, lr: [0.00037372033482557603], Loss: 2.013485, Acc:0.601894, Source Loss: 1.414655, Target Loss: 1.093985, MixUp Loss: 0.922992
2025-01-26 13:20:39,017 Epoch: [1/20] Iter:[140/286], Time: 2.03, lr: [0.00037308613416508227], Loss: 2.008815, Acc:0.602781, Source Loss: 1.411829, Target Loss: 1.095247, MixUp Loss: 1.029090
2025-01-26 13:20:59,504 Epoch: [1/20] Iter:[150/286], Time: 2.03, lr: [0.0003724518136970785], Loss: 2.003365, Acc:0.604049, Source Loss: 1.407481, Target Loss: 1.096340, MixUp Loss: 0.917748
2025-01-26 13:21:19,346 Epoch: [1/20] Iter:[160/286], Time: 2.03, lr: [0.0003718173731721307], Loss: 1.986379, Acc:0.601618, Source Loss: 1.395385, Target Loss: 1.094265, MixUp Loss: 0.913942
2025-01-26 13:21:39,908 Epoch: [1/20] Iter:[170/286], Time: 2.03, lr: [0.0003711828123398116], Loss: 1.982034, Acc:0.604832, Source Loss: 1.391917, Target Loss: 1.093640, MixUp Loss: 1.276933
2025-01-26 13:21:59,462 Epoch: [1/20] Iter:[180/286], Time: 2.03, lr: [0.0003705481309486949], Loss: 1.979627, Acc:0.605823, Source Loss: 1.389979, Target Loss: 1.095566, MixUp Loss: 0.879486
2025-01-26 13:22:19,911 Epoch: [1/20] Iter:[190/286], Time: 2.03, lr: [0.0003699133287463493], Loss: 1.988269, Acc:0.608520, Source Loss: 1.398786, Target Loss: 1.091913, MixUp Loss: 0.774819
2025-01-26 13:22:40,026 Epoch: [1/20] Iter:[200/286], Time: 2.03, lr: [0.0003692784054793322], Loss: 1.986411, Acc:0.612236, Source Loss: 1.398550, Target Loss: 1.086994, MixUp Loss: 1.373766
2025-01-26 13:22:59,733 Epoch: [1/20] Iter:[210/286], Time: 2.02, lr: [0.0003686433608931844], Loss: 1.984744, Acc:0.614051, Source Loss: 1.397511, Target Loss: 1.085120, MixUp Loss: 1.293944
2025-01-26 13:23:20,271 Epoch: [1/20] Iter:[220/286], Time: 2.03, lr: [0.00036800819473242346], Loss: 1.982552, Acc:0.616953, Source Loss: 1.396903, Target Loss: 1.087070, MixUp Loss: 1.240316
2025-01-26 13:23:39,726 Epoch: [1/20] Iter:[230/286], Time: 2.02, lr: [0.00036737290674053805], Loss: 1.978126, Acc:0.618628, Source Loss: 1.393288, Target Loss: 1.087768, MixUp Loss: 0.975397
2025-01-26 13:24:00,199 Epoch: [1/20] Iter:[240/286], Time: 2.02, lr: [0.0003667374966599815], Loss: 1.983265, Acc:0.620765, Source Loss: 1.397287, Target Loss: 1.090725, MixUp Loss: 1.025321
2025-01-26 13:24:20,154 Epoch: [1/20] Iter:[250/286], Time: 2.02, lr: [0.0003661019642321656], Loss: 1.975397, Acc:0.622675, Source Loss: 1.391732, Target Loss: 1.086514, MixUp Loss: 0.696564
2025-01-26 13:24:40,663 Epoch: [1/20] Iter:[260/286], Time: 2.02, lr: [0.00036546630919745486], Loss: 1.972722, Acc:0.622354, Source Loss: 1.390238, Target Loss: 1.084731, MixUp Loss: 0.911330
2025-01-26 13:25:01,126 Epoch: [1/20] Iter:[270/286], Time: 2.02, lr: [0.00036483053129515963], Loss: 1.974259, Acc:0.622689, Source Loss: 1.392423, Target Loss: 1.083839, MixUp Loss: 1.109413
2025-01-26 13:25:20,699 Epoch: [1/20] Iter:[280/286], Time: 2.02, lr: [0.0003641946302635301], Loss: 1.974742, Acc:0.625252, Source Loss: 1.393370, Target Loss: 1.083379, MixUp Loss: 1.413892
2025-01-26 13:31:16,030 0 [0.         0.30352889 0.06997387 0.08792618 0.29688466 0.16148203
 0.02228348 0.01388774] 0.11949585656920403
2025-01-26 13:31:16,031 1 [0.         0.35750939 0.08306454 0.11893745 0.44815389 0.11238848
 0.03847481 0.02972316] 0.14853146425810754
2025-01-26 13:31:16,032 Epoch 2/20 - Source Loss: 1.3961, Target Loss: 1.0835
2025-01-26 13:31:16,032 => saving checkpoint to output/loveDa/pidnet_small_loveda_train_DACScheckpoint.pth.tar
2025-01-26 13:31:16,430 Epoch [1], Loss: 1.978, MeanIoU: 0.1485, best_mIoU: 0.1496
2025-01-26 13:31:16,430 IoU per class: [0.         0.35750939 0.08306454 0.11893745 0.44815389 0.11238848
 0.03847481 0.02972316]
2025-01-26 13:31:16,966 Attention!!!
2025-01-26 13:31:16,967 Loaded 302 parameters!
2025-01-26 13:31:16,967 Over!!!
2025-01-26 13:31:19,489 Epoch: [2/20] Iter:[0/286], Time: 2.69, lr: [0.0005457195456497774], Loss: 1.967949, Acc:0.627964, Source Loss: 1.347687, Target Loss: 1.168060, MixUp Loss: 1.240524
2025-01-26 13:31:39,249 Epoch: [2/20] Iter:[10/286], Time: 2.04, lr: [0.0005447653977712745], Loss: 1.990411, Acc:0.622992, Source Loss: 1.357936, Target Loss: 1.246320, MixUp Loss: 1.385722
2025-01-26 13:31:59,600 Epoch: [2/20] Iter:[20/286], Time: 2.04, lr: [0.0005438110641704341], Loss: 2.014244, Acc:0.650049, Source Loss: 1.402215, Target Loss: 1.224240, MixUp Loss: 1.456423
2025-01-26 13:32:19,139 Epoch: [2/20] Iter:[30/286], Time: 2.01, lr: [0.0005428565444488269], Loss: 1.959519, Acc:0.651092, Source Loss: 1.356126, Target Loss: 1.222571, MixUp Loss: 1.257140
2025-01-26 13:32:39,749 Epoch: [2/20] Iter:[40/286], Time: 2.02, lr: [0.0005419018382063879], Loss: 1.992317, Acc:0.658426, Source Loss: 1.386151, Target Loss: 1.196839, MixUp Loss: 1.007140
2025-01-26 13:33:00,345 Epoch: [2/20] Iter:[50/286], Time: 2.03, lr: [0.0005409469450414076], Loss: 2.004663, Acc:0.657761, Source Loss: 1.392447, Target Loss: 1.207462, MixUp Loss: 1.094563
2025-01-26 13:33:20,281 Epoch: [2/20] Iter:[60/286], Time: 2.02, lr: [0.0005399918645505214], Loss: 2.011265, Acc:0.650190, Source Loss: 1.399370, Target Loss: 1.193432, MixUp Loss: 1.154276
2025-01-26 13:33:40,653 Epoch: [2/20] Iter:[70/286], Time: 2.03, lr: [0.0005390365963286999], Loss: 1.988493, Acc:0.646691, Source Loss: 1.375684, Target Loss: 1.202323, MixUp Loss: 1.390275
2025-01-26 13:34:00,496 Epoch: [2/20] Iter:[80/286], Time: 2.02, lr: [0.0005380811399692384], Loss: 1.981188, Acc:0.654932, Source Loss: 1.371032, Target Loss: 1.186158, MixUp Loss: 1.453875
2025-01-26 13:34:20,851 Epoch: [2/20] Iter:[90/286], Time: 2.02, lr: [0.0005371254950637469], Loss: 1.981825, Acc:0.658319, Source Loss: 1.373609, Target Loss: 1.177088, MixUp Loss: 1.495261
2025-01-26 13:34:41,196 Epoch: [2/20] Iter:[100/286], Time: 2.02, lr: [0.0005361696612021393], Loss: 1.979567, Acc:0.659725, Source Loss: 1.375435, Target Loss: 1.173487, MixUp Loss: 1.106195
2025-01-26 13:35:00,991 Epoch: [2/20] Iter:[110/286], Time: 2.02, lr: [0.000535213637972624], Loss: 1.983799, Acc:0.660846, Source Loss: 1.379339, Target Loss: 1.176550, MixUp Loss: 1.254872
2025-01-26 13:35:21,517 Epoch: [2/20] Iter:[120/286], Time: 2.02, lr: [0.0005342574249616923], Loss: 1.992629, Acc:0.657106, Source Loss: 1.389683, Target Loss: 1.167896, MixUp Loss: 1.006701
2025-01-26 13:35:41,339 Epoch: [2/20] Iter:[130/286], Time: 2.02, lr: [0.0005333010217541081], Loss: 1.982197, Acc:0.653552, Source Loss: 1.382221, Target Loss: 1.165908, MixUp Loss: 1.248480
2025-01-26 13:36:01,934 Epoch: [2/20] Iter:[140/286], Time: 2.02, lr: [0.0005323444279328977], Loss: 1.974063, Acc:0.655962, Source Loss: 1.380315, Target Loss: 1.158916, MixUp Loss: 0.758951
2025-01-26 13:36:22,260 Epoch: [2/20] Iter:[150/286], Time: 2.02, lr: [0.0005313876430793387], Loss: 1.976873, Acc:0.656508, Source Loss: 1.381775, Target Loss: 1.160690, MixUp Loss: 1.637660
2025-01-26 13:36:42,354 Epoch: [2/20] Iter:[160/286], Time: 2.02, lr: [0.0005304306667729493], Loss: 1.980849, Acc:0.657980, Source Loss: 1.385097, Target Loss: 1.158550, MixUp Loss: 1.388294
2025-01-26 13:37:02,721 Epoch: [2/20] Iter:[170/286], Time: 2.02, lr: [0.0005294734985914768], Loss: 1.981233, Acc:0.655074, Source Loss: 1.384702, Target Loss: 1.164898, MixUp Loss: 1.414507
2025-01-26 13:37:22,600 Epoch: [2/20] Iter:[180/286], Time: 2.02, lr: [0.0005285161381108875], Loss: 1.990465, Acc:0.655877, Source Loss: 1.389124, Target Loss: 1.165848, MixUp Loss: 1.455294
2025-01-26 13:37:42,697 Epoch: [2/20] Iter:[190/286], Time: 2.02, lr: [0.0005275585849053547], Loss: 1.987122, Acc:0.656019, Source Loss: 1.386911, Target Loss: 1.163703, MixUp Loss: 0.986926
2025-01-26 13:38:02,548 Epoch: [2/20] Iter:[200/286], Time: 2.02, lr: [0.0005266008385472484], Loss: 1.987623, Acc:0.657007, Source Loss: 1.387194, Target Loss: 1.168410, MixUp Loss: 1.463670
2025-01-26 13:38:22,485 Epoch: [2/20] Iter:[210/286], Time: 2.02, lr: [0.0005256428986071227], Loss: 1.991884, Acc:0.658463, Source Loss: 1.389768, Target Loss: 1.171931, MixUp Loss: 1.132430
2025-01-26 13:38:42,991 Epoch: [2/20] Iter:[220/286], Time: 2.02, lr: [0.0005246847646537063], Loss: 1.991015, Acc:0.662362, Source Loss: 1.389513, Target Loss: 1.170944, MixUp Loss: 1.202505
2025-01-26 13:39:02,520 Epoch: [2/20] Iter:[230/286], Time: 2.02, lr: [0.0005237264362538889], Loss: 1.987031, Acc:0.662948, Source Loss: 1.386709, Target Loss: 1.169102, MixUp Loss: 1.215965
2025-01-26 13:39:22,943 Epoch: [2/20] Iter:[240/286], Time: 2.02, lr: [0.0005227679129727109], Loss: 1.985665, Acc:0.661167, Source Loss: 1.386001, Target Loss: 1.165662, MixUp Loss: 1.319331
2025-01-26 13:39:42,523 Epoch: [2/20] Iter:[250/286], Time: 2.01, lr: [0.0005218091943733518], Loss: 1.989100, Acc:0.663583, Source Loss: 1.389348, Target Loss: 1.167913, MixUp Loss: 1.085692
2025-01-26 13:40:02,658 Epoch: [2/20] Iter:[260/286], Time: 2.01, lr: [0.0005208502800171176], Loss: 1.986860, Acc:0.664800, Source Loss: 1.388251, Target Loss: 1.165271, MixUp Loss: 1.111788
2025-01-26 13:40:22,954 Epoch: [2/20] Iter:[270/286], Time: 2.02, lr: [0.0005198911694634297], Loss: 1.985063, Acc:0.665571, Source Loss: 1.386551, Target Loss: 1.166187, MixUp Loss: 1.288322
2025-01-26 13:40:42,501 Epoch: [2/20] Iter:[280/286], Time: 2.01, lr: [0.0005189318622698123], Loss: 1.984781, Acc:0.665179, Source Loss: 1.385980, Target Loss: 1.164573, MixUp Loss: 1.053680
2025-01-26 13:46:25,613 0 [0.         0.37710076 0.10820135 0.06674505 0.35540802 0.11711057
 0.01969517 0.01417137] 0.13230403713830308
2025-01-26 13:46:25,613 1 [0.         0.43464567 0.11216764 0.12025607 0.43649502 0.12605207
 0.0105157  0.05553666] 0.16195860528223097
2025-01-26 13:46:25,615 Epoch 3/20 - Source Loss: 1.3883, Target Loss: 1.1636
2025-01-26 13:46:25,615 => saving checkpoint to output/loveDa/pidnet_small_loveda_train_DACScheckpoint.pth.tar
2025-01-26 13:46:26,021 Epoch [2], Loss: 1.988, MeanIoU: 0.1620, best_mIoU: 0.1620
2025-01-26 13:46:26,021 IoU per class: [0.         0.43464567 0.11216764 0.12025607 0.43649502 0.12605207
 0.0105157  0.05553666]
2025-01-26 13:46:26,195 Attention!!!
2025-01-26 13:46:26,195 Loaded 302 parameters!
2025-01-26 13:46:26,195 Over!!!
2025-01-26 13:46:28,998 Epoch: [3/20] Iter:[0/286], Time: 2.61, lr: [0.0006911415778422553], Loss: 1.707858, Acc:0.718643, Source Loss: 1.101529, Target Loss: 1.472715, MixUp Loss: 1.212659
2025-01-26 13:46:49,141 Epoch: [3/20] Iter:[10/286], Time: 2.07, lr: [0.000689862080852091], Loss: 1.817096, Acc:0.631612, Source Loss: 1.264744, Target Loss: 1.219742, MixUp Loss: 1.288559
2025-01-26 13:47:09,982 Epoch: [3/20] Iter:[20/286], Time: 2.08, lr: [0.0006885823201294859], Loss: 1.882825, Acc:0.625490, Source Loss: 1.300874, Target Loss: 1.172491, MixUp Loss: 1.174711
2025-01-26 13:47:29,581 Epoch: [3/20] Iter:[30/286], Time: 2.04, lr: [0.0006873022950752329], Loss: 1.922838, Acc:0.612437, Source Loss: 1.335267, Target Loss: 1.179769, MixUp Loss: 1.041549
2025-01-26 13:47:50,258 Epoch: [3/20] Iter:[40/286], Time: 2.05, lr: [0.0006860220050875204], Loss: 1.924383, Acc:0.612953, Source Loss: 1.342758, Target Loss: 1.167382, MixUp Loss: 1.125433
2025-01-26 13:48:11,052 Epoch: [3/20] Iter:[50/286], Time: 2.05, lr: [0.0006847414495619158], Loss: 1.933535, Acc:0.626075, Source Loss: 1.354770, Target Loss: 1.140825, MixUp Loss: 1.003261
2025-01-26 13:48:30,948 Epoch: [3/20] Iter:[60/286], Time: 2.04, lr: [0.0006834606278913483], Loss: 1.931706, Acc:0.621448, Source Loss: 1.361099, Target Loss: 1.130092, MixUp Loss: 1.454921
2025-01-26 13:48:51,431 Epoch: [3/20] Iter:[70/286], Time: 2.04, lr: [0.0006821795394660922], Loss: 1.973408, Acc:0.623532, Source Loss: 1.394259, Target Loss: 1.127594, MixUp Loss: 1.077118
2025-01-26 13:49:12,161 Epoch: [3/20] Iter:[80/286], Time: 2.05, lr: [0.0006808981836737489], Loss: 1.983391, Acc:0.622524, Source Loss: 1.402079, Target Loss: 1.126810, MixUp Loss: 1.352024
2025-01-26 13:49:33,178 Epoch: [3/20] Iter:[90/286], Time: 2.05, lr: [0.0006796165598992311], Loss: 1.954348, Acc:0.621318, Source Loss: 1.373524, Target Loss: 1.135067, MixUp Loss: 1.413127
2025-01-26 13:49:54,627 Epoch: [3/20] Iter:[100/286], Time: 2.06, lr: [0.0006783346675247437], Loss: 1.959297, Acc:0.626773, Source Loss: 1.374429, Target Loss: 1.142953, MixUp Loss: 1.002576
2025-01-26 13:50:14,964 Epoch: [3/20] Iter:[110/286], Time: 2.06, lr: [0.0006770525059297671], Loss: 1.959890, Acc:0.625510, Source Loss: 1.374831, Target Loss: 1.141956, MixUp Loss: 1.427039
2025-01-26 13:50:36,062 Epoch: [3/20] Iter:[120/286], Time: 2.06, lr: [0.0006757700744910393], Loss: 1.960148, Acc:0.629495, Source Loss: 1.378500, Target Loss: 1.139311, MixUp Loss: 1.094110
2025-01-26 13:50:57,173 Epoch: [3/20] Iter:[130/286], Time: 2.07, lr: [0.0006744873725825377], Loss: 1.960144, Acc:0.630521, Source Loss: 1.378343, Target Loss: 1.134979, MixUp Loss: 0.908154
2025-01-26 13:51:17,322 Epoch: [3/20] Iter:[140/286], Time: 2.06, lr: [0.0006732043995754614], Loss: 1.959809, Acc:0.630006, Source Loss: 1.375226, Target Loss: 1.145257, MixUp Loss: 0.929573
2025-01-26 13:51:38,357 Epoch: [3/20] Iter:[150/286], Time: 2.07, lr: [0.0006719211548382127], Loss: 1.970385, Acc:0.634134, Source Loss: 1.387642, Target Loss: 1.141127, MixUp Loss: 1.184519
2025-01-26 13:51:58,730 Epoch: [3/20] Iter:[160/286], Time: 2.06, lr: [0.0006706376377363785], Loss: 1.981885, Acc:0.637683, Source Loss: 1.399044, Target Loss: 1.140971, MixUp Loss: 1.129130
2025-01-26 13:52:19,385 Epoch: [3/20] Iter:[170/286], Time: 2.06, lr: [0.0006693538476327124], Loss: 1.978695, Acc:0.636976, Source Loss: 1.397040, Target Loss: 1.139546, MixUp Loss: 0.728940
2025-01-26 13:52:40,648 Epoch: [3/20] Iter:[180/286], Time: 2.07, lr: [0.0006680697838871152], Loss: 1.983945, Acc:0.636828, Source Loss: 1.402216, Target Loss: 1.144302, MixUp Loss: 1.179716
2025-01-26 13:53:00,724 Epoch: [3/20] Iter:[190/286], Time: 2.06, lr: [0.0006667854458566166], Loss: 1.991080, Acc:0.641082, Source Loss: 1.408758, Target Loss: 1.147417, MixUp Loss: 0.918769
2025-01-26 13:53:21,684 Epoch: [3/20] Iter:[200/286], Time: 2.07, lr: [0.0006655008328953561], Loss: 1.985979, Acc:0.641136, Source Loss: 1.405380, Target Loss: 1.145177, MixUp Loss: 0.918188
2025-01-26 13:53:42,554 Epoch: [3/20] Iter:[210/286], Time: 2.07, lr: [0.0006642159443545629], Loss: 1.993395, Acc:0.640266, Source Loss: 1.410465, Target Loss: 1.149897, MixUp Loss: 0.768503
2025-01-26 13:54:02,576 Epoch: [3/20] Iter:[220/286], Time: 2.06, lr: [0.0006629307795825377], Loss: 1.988079, Acc:0.639062, Source Loss: 1.407365, Target Loss: 1.144690, MixUp Loss: 1.055145
2025-01-26 13:54:23,567 Epoch: [3/20] Iter:[230/286], Time: 2.07, lr: [0.0006616453379246329], Loss: 1.997834, Acc:0.639769, Source Loss: 1.415554, Target Loss: 1.146244, MixUp Loss: 1.306352
2025-01-26 13:54:43,831 Epoch: [3/20] Iter:[240/286], Time: 2.06, lr: [0.0006603596187232321], Loss: 1.991518, Acc:0.637021, Source Loss: 1.410853, Target Loss: 1.143753, MixUp Loss: 0.822011
2025-01-26 13:55:04,269 Epoch: [3/20] Iter:[250/286], Time: 2.06, lr: [0.000659073621317731], Loss: 1.989033, Acc:0.637655, Source Loss: 1.408001, Target Loss: 1.147608, MixUp Loss: 1.039342
2025-01-26 13:55:24,827 Epoch: [3/20] Iter:[260/286], Time: 2.06, lr: [0.0006577873450445169], Loss: 1.980480, Acc:0.640197, Source Loss: 1.401486, Target Loss: 1.147008, MixUp Loss: 1.175344
2025-01-26 13:55:44,537 Epoch: [3/20] Iter:[270/286], Time: 2.06, lr: [0.0006565007892369484], Loss: 1.975919, Acc:0.638685, Source Loss: 1.398625, Target Loss: 1.146042, MixUp Loss: 1.089552
2025-01-26 13:56:05,246 Epoch: [3/20] Iter:[280/286], Time: 2.06, lr: [0.0006552139532253356], Loss: 1.984903, Acc:0.638208, Source Loss: 1.405021, Target Loss: 1.145490, MixUp Loss: 1.641448
2025-01-26 14:01:51,505 0 [0.         0.43552588 0.13886119 0.13525706 0.27165776 0.13856384
 0.12311897 0.00108032] 0.15550812856197072
2025-01-26 14:01:51,506 1 [0.00000000e+00 4.79466733e-01 1.27745052e-01 1.50683127e-01
 2.71394695e-01 5.86618550e-02 1.29338091e-01 3.11155001e-04] 0.15220008844927024
2025-01-26 14:01:51,507 Epoch 4/20 - Source Loss: 1.4074, Target Loss: 1.1437
2025-01-26 14:01:51,507 => saving checkpoint to output/loveDa/pidnet_small_loveda_train_DACScheckpoint.pth.tar
2025-01-26 14:01:51,813 Epoch [3], Loss: 1.987, MeanIoU: 0.1522, best_mIoU: 0.1620
2025-01-26 14:01:51,814 IoU per class: [0.00000000e+00 4.79466733e-01 1.27745052e-01 1.50683127e-01
 2.71394695e-01 5.86618550e-02 1.29338091e-01 3.11155001e-04]
2025-01-26 14:01:51,967 Attention!!!
2025-01-26 14:01:51,967 Loaded 302 parameters!
2025-01-26 14:01:51,967 Over!!!
2025-01-26 14:01:54,255 Epoch: [4/20] Iter:[0/286], Time: 2.07, lr: [0.0008180521460508585], Loss: 2.445834, Acc:0.618760, Source Loss: 1.663294, Target Loss: 1.503531, MixUp Loss: 1.565079
2025-01-26 14:02:14,926 Epoch: [4/20] Iter:[10/286], Time: 2.07, lr: [0.0008164430388774716], Loss: 2.010396, Acc:0.632599, Source Loss: 1.382523, Target Loss: 1.352755, MixUp Loss: 0.905725
2025-01-26 14:02:34,999 Epoch: [4/20] Iter:[20/286], Time: 2.04, lr: [0.0008148335792545135], Loss: 1.933229, Acc:0.606511, Source Loss: 1.341154, Target Loss: 1.224931, MixUp Loss: 1.056881
2025-01-26 14:02:54,678 Epoch: [4/20] Iter:[30/286], Time: 2.02, lr: [0.0008132237663309356], Loss: 1.942029, Acc:0.612246, Source Loss: 1.347114, Target Loss: 1.189215, MixUp Loss: 1.027789
2025-01-26 14:03:15,411 Epoch: [4/20] Iter:[40/286], Time: 2.03, lr: [0.0008116135992517576], Loss: 1.887938, Acc:0.598952, Source Loss: 1.308793, Target Loss: 1.180478, MixUp Loss: 1.445514
2025-01-26 14:03:35,445 Epoch: [4/20] Iter:[50/286], Time: 2.02, lr: [0.0008100030771580406], Loss: 1.901955, Acc:0.614412, Source Loss: 1.311247, Target Loss: 1.175598, MixUp Loss: 1.159650
2025-01-26 14:03:56,333 Epoch: [4/20] Iter:[60/286], Time: 2.04, lr: [0.0008083921991868594], Loss: 1.864413, Acc:0.613050, Source Loss: 1.282779, Target Loss: 1.165512, MixUp Loss: 1.035936
2025-01-26 14:04:16,950 Epoch: [4/20] Iter:[70/286], Time: 2.04, lr: [0.0008067809644712763], Loss: 1.873827, Acc:0.614567, Source Loss: 1.297635, Target Loss: 1.149760, MixUp Loss: 1.092020
2025-01-26 14:04:37,096 Epoch: [4/20] Iter:[80/286], Time: 2.04, lr: [0.0008051693721403125], Loss: 1.879191, Acc:0.615844, Source Loss: 1.307577, Target Loss: 1.134913, MixUp Loss: 1.237287
2025-01-26 14:04:58,164 Epoch: [4/20] Iter:[90/286], Time: 2.04, lr: [0.0008035574213189205], Loss: 1.886777, Acc:0.619259, Source Loss: 1.314049, Target Loss: 1.139870, MixUp Loss: 1.155945
2025-01-26 14:05:18,913 Epoch: [4/20] Iter:[100/286], Time: 2.05, lr: [0.0008019451111279563], Loss: 1.889741, Acc:0.625939, Source Loss: 1.316743, Target Loss: 1.149407, MixUp Loss: 1.559469
2025-01-26 14:05:39,354 Epoch: [4/20] Iter:[110/286], Time: 2.05, lr: [0.0008003324406841505], Loss: 1.896728, Acc:0.633183, Source Loss: 1.324278, Target Loss: 1.138930, MixUp Loss: 1.627480
2025-01-26 14:06:00,075 Epoch: [4/20] Iter:[120/286], Time: 2.05, lr: [0.0007987194091000798], Loss: 1.878646, Acc:0.630766, Source Loss: 1.309110, Target Loss: 1.147058, MixUp Loss: 1.385756
2025-01-26 14:06:20,280 Epoch: [4/20] Iter:[130/286], Time: 2.05, lr: [0.0007971060154841387], Loss: 1.881794, Acc:0.632792, Source Loss: 1.311029, Target Loss: 1.145430, MixUp Loss: 1.139482
2025-01-26 14:06:41,266 Epoch: [4/20] Iter:[140/286], Time: 2.05, lr: [0.0007954922589405094], Loss: 1.863754, Acc:0.632450, Source Loss: 1.296239, Target Loss: 1.147745, MixUp Loss: 1.071859
2025-01-26 14:07:02,139 Epoch: [4/20] Iter:[150/286], Time: 2.05, lr: [0.000793878138569133], Loss: 1.874403, Acc:0.632218, Source Loss: 1.302337, Target Loss: 1.153702, MixUp Loss: 1.205149
2025-01-26 14:07:22,104 Epoch: [4/20] Iter:[160/286], Time: 2.05, lr: [0.0007922636534656797], Loss: 1.876083, Acc:0.634201, Source Loss: 1.305012, Target Loss: 1.154748, MixUp Loss: 1.153527
2025-01-26 14:07:42,986 Epoch: [4/20] Iter:[170/286], Time: 2.05, lr: [0.0007906488027215184], Loss: 1.883843, Acc:0.638593, Source Loss: 1.310463, Target Loss: 1.160106, MixUp Loss: 1.594877
2025-01-26 14:08:03,120 Epoch: [4/20] Iter:[180/286], Time: 2.05, lr: [0.0007890335854236874], Loss: 1.901302, Acc:0.640809, Source Loss: 1.325208, Target Loss: 1.159250, MixUp Loss: 1.410916
2025-01-26 14:08:23,955 Epoch: [4/20] Iter:[190/286], Time: 2.05, lr: [0.0007874180006548622], Loss: 1.917139, Acc:0.643544, Source Loss: 1.340962, Target Loss: 1.157855, MixUp Loss: 1.273052
2025-01-26 14:08:44,635 Epoch: [4/20] Iter:[200/286], Time: 2.05, lr: [0.0007858020474933266], Loss: 1.913538, Acc:0.643252, Source Loss: 1.341085, Target Loss: 1.153720, MixUp Loss: 0.888433
2025-01-26 14:09:04,586 Epoch: [4/20] Iter:[210/286], Time: 2.05, lr: [0.0007841857250129404], Loss: 1.925762, Acc:0.642853, Source Loss: 1.351069, Target Loss: 1.158129, MixUp Loss: 1.263150
2025-01-26 14:09:25,073 Epoch: [4/20] Iter:[220/286], Time: 2.05, lr: [0.0007825690322831078], Loss: 1.921613, Acc:0.642030, Source Loss: 1.349494, Target Loss: 1.155063, MixUp Loss: 0.804857
2025-01-26 14:09:44,700 Epoch: [4/20] Iter:[230/286], Time: 2.05, lr: [0.000780951968368747], Loss: 1.928197, Acc:0.643182, Source Loss: 1.356596, Target Loss: 1.157732, MixUp Loss: 1.259208
2025-01-26 14:10:05,195 Epoch: [4/20] Iter:[240/286], Time: 2.05, lr: [0.0007793345323302562], Loss: 1.931314, Acc:0.643920, Source Loss: 1.360290, Target Loss: 1.155899, MixUp Loss: 0.945974
2025-01-26 14:10:25,835 Epoch: [4/20] Iter:[250/286], Time: 2.05, lr: [0.0007777167232234833], Loss: 1.934245, Acc:0.645078, Source Loss: 1.361436, Target Loss: 1.161341, MixUp Loss: 1.039471
2025-01-26 14:10:45,672 Epoch: [4/20] Iter:[260/286], Time: 2.04, lr: [0.0007760985400996923], Loss: 1.935216, Acc:0.645586, Source Loss: 1.364596, Target Loss: 1.155823, MixUp Loss: 1.197340
2025-01-26 14:11:06,379 Epoch: [4/20] Iter:[270/286], Time: 2.05, lr: [0.00077447998200553], Loss: 1.925942, Acc:0.645612, Source Loss: 1.358147, Target Loss: 1.152247, MixUp Loss: 0.847483
2025-01-26 14:11:26,525 Epoch: [4/20] Iter:[280/286], Time: 2.04, lr: [0.0007728610479829936], Loss: 1.932472, Acc:0.647162, Source Loss: 1.363925, Target Loss: 1.155790, MixUp Loss: 1.328738
2025-01-26 14:17:15,298 0 [0.         0.43949575 0.14207545 0.09056624 0.26353018 0.17428663
 0.02167318 0.00070017] 0.14154094912347848
2025-01-26 14:17:15,299 1 [0.         0.48959108 0.10551637 0.11141034 0.26662054 0.06246198
 0.02150301 0.00278741] 0.13248633933413753
2025-01-26 14:17:15,300 Epoch 5/20 - Source Loss: 1.3605, Target Loss: 1.1541
2025-01-26 14:17:15,300 => saving checkpoint to output/loveDa/pidnet_small_loveda_train_DACScheckpoint.pth.tar
2025-01-26 14:17:15,596 Epoch [4], Loss: 1.928, MeanIoU: 0.1325, best_mIoU: 0.1620
2025-01-26 14:17:15,597 IoU per class: [0.         0.48959108 0.10551637 0.11141034 0.26662054 0.06246198
 0.02150301 0.00278741]
2025-01-26 14:17:15,769 Attention!!!
2025-01-26 14:17:15,769 Loaded 302 parameters!
2025-01-26 14:17:15,770 Over!!!
2025-01-26 14:17:17,885 Epoch: [5/20] Iter:[0/286], Time: 1.91, lr: [0.0005894354967909492], Loss: 1.973837, Acc:0.721402, Source Loss: 1.391901, Target Loss: 1.549309, MixUp Loss: 1.163872
2025-01-26 14:17:38,188 Epoch: [5/20] Iter:[10/286], Time: 2.02, lr: [0.0005881987745790142], Loss: 1.995151, Acc:0.640052, Source Loss: 1.436911, Target Loss: 1.262284, MixUp Loss: 1.234285
2025-01-26 14:17:58,065 Epoch: [5/20] Iter:[20/286], Time: 2.00, lr: [0.0005869617633792564], Loss: 1.947912, Acc:0.626577, Source Loss: 1.376448, Target Loss: 1.245446, MixUp Loss: 1.090609
2025-01-26 14:18:18,698 Epoch: [5/20] Iter:[30/286], Time: 2.02, lr: [0.0005857244624471221], Loss: 1.936962, Acc:0.627977, Source Loss: 1.375073, Target Loss: 1.213035, MixUp Loss: 1.293467
2025-01-26 14:18:38,760 Epoch: [5/20] Iter:[40/286], Time: 2.02, lr: [0.0005844868710343868], Loss: 1.864685, Acc:0.612378, Source Loss: 1.321342, Target Loss: 1.190241, MixUp Loss: 0.729863
2025-01-26 14:18:58,224 Epoch: [5/20] Iter:[50/286], Time: 2.01, lr: [0.0005832489883891285], Loss: 1.846634, Acc:0.612248, Source Loss: 1.306796, Target Loss: 1.195196, MixUp Loss: 0.778858
2025-01-26 14:19:18,202 Epoch: [5/20] Iter:[60/286], Time: 2.00, lr: [0.0005820108137557008], Loss: 1.817798, Acc:0.607454, Source Loss: 1.282502, Target Loss: 1.189521, MixUp Loss: 0.853881
2025-01-26 14:19:37,670 Epoch: [5/20] Iter:[70/286], Time: 2.00, lr: [0.0005807723463747051], Loss: 1.803217, Acc:0.609771, Source Loss: 1.272126, Target Loss: 1.176541, MixUp Loss: 1.211882
2025-01-26 14:19:58,129 Epoch: [5/20] Iter:[80/286], Time: 2.00, lr: [0.0005795335854829635], Loss: 1.816396, Acc:0.615767, Source Loss: 1.284217, Target Loss: 1.179093, MixUp Loss: 1.090876
2025-01-26 14:20:17,966 Epoch: [5/20] Iter:[90/286], Time: 2.00, lr: [0.0005782945303134907], Loss: 1.839880, Acc:0.618763, Source Loss: 1.299220, Target Loss: 1.190802, MixUp Loss: 0.855094
2025-01-26 14:20:38,608 Epoch: [5/20] Iter:[100/286], Time: 2.01, lr: [0.0005770551800954662], Loss: 1.839388, Acc:0.626328, Source Loss: 1.302144, Target Loss: 1.181134, MixUp Loss: 0.973721
2025-01-26 14:20:59,136 Epoch: [5/20] Iter:[110/286], Time: 2.01, lr: [0.0005758155340542057], Loss: 1.852113, Acc:0.628951, Source Loss: 1.313016, Target Loss: 1.181119, MixUp Loss: 1.212590
2025-01-26 14:21:19,101 Epoch: [5/20] Iter:[120/286], Time: 2.01, lr: [0.0005745755914111321], Loss: 1.851675, Acc:0.627451, Source Loss: 1.314466, Target Loss: 1.180095, MixUp Loss: 0.786105
2025-01-26 14:21:39,553 Epoch: [5/20] Iter:[130/286], Time: 2.01, lr: [0.0005733353513837476], Loss: 1.848279, Acc:0.627869, Source Loss: 1.310460, Target Loss: 1.189784, MixUp Loss: 1.259994
2025-01-26 14:21:59,228 Epoch: [5/20] Iter:[140/286], Time: 2.01, lr: [0.000572094813185603], Loss: 1.855000, Acc:0.630595, Source Loss: 1.317385, Target Loss: 1.197253, MixUp Loss: 1.325557
2025-01-26 14:22:19,707 Epoch: [5/20] Iter:[150/286], Time: 2.01, lr: [0.0005708539760262699], Loss: 1.860002, Acc:0.630955, Source Loss: 1.320414, Target Loss: 1.195293, MixUp Loss: 0.778664
2025-01-26 14:22:40,402 Epoch: [5/20] Iter:[160/286], Time: 2.02, lr: [0.000569612839111309], Loss: 1.857108, Acc:0.630039, Source Loss: 1.315058, Target Loss: 1.203632, MixUp Loss: 0.757492
2025-01-26 14:23:00,347 Epoch: [5/20] Iter:[170/286], Time: 2.01, lr: [0.0005683714016422416], Loss: 1.850079, Acc:0.630990, Source Loss: 1.312241, Target Loss: 1.196987, MixUp Loss: 1.035197
2025-01-26 14:23:20,782 Epoch: [5/20] Iter:[180/286], Time: 2.02, lr: [0.0005671296628165188], Loss: 1.844082, Acc:0.630745, Source Loss: 1.307198, Target Loss: 1.199142, MixUp Loss: 0.861776
2025-01-26 14:23:40,613 Epoch: [5/20] Iter:[190/286], Time: 2.01, lr: [0.0005658876218274897], Loss: 1.841743, Acc:0.629959, Source Loss: 1.304504, Target Loss: 1.198727, MixUp Loss: 1.381096
2025-01-26 14:24:00,933 Epoch: [5/20] Iter:[200/286], Time: 2.01, lr: [0.0005646452778643723], Loss: 1.837970, Acc:0.631033, Source Loss: 1.300724, Target Loss: 1.201015, MixUp Loss: 1.053047
2025-01-26 14:24:21,044 Epoch: [5/20] Iter:[210/286], Time: 2.01, lr: [0.0005634026301122202], Loss: 1.843421, Acc:0.629540, Source Loss: 1.304801, Target Loss: 1.200675, MixUp Loss: 1.146386
2025-01-26 14:24:41,203 Epoch: [5/20] Iter:[220/286], Time: 2.01, lr: [0.0005621596777518925], Loss: 1.853929, Acc:0.631947, Source Loss: 1.312722, Target Loss: 1.206907, MixUp Loss: 1.200804
2025-01-26 14:25:01,827 Epoch: [5/20] Iter:[230/286], Time: 2.02, lr: [0.0005609164199600209], Loss: 1.844580, Acc:0.628310, Source Loss: 1.305061, Target Loss: 1.201869, MixUp Loss: 1.158189
2025-01-26 14:25:21,613 Epoch: [5/20] Iter:[240/286], Time: 2.02, lr: [0.0005596728559089782], Loss: 1.854108, Acc:0.628804, Source Loss: 1.312964, Target Loss: 1.202092, MixUp Loss: 1.274535
2025-01-26 14:25:42,190 Epoch: [5/20] Iter:[250/286], Time: 2.02, lr: [0.0005584289847668448], Loss: 1.855427, Acc:0.629426, Source Loss: 1.315581, Target Loss: 1.198028, MixUp Loss: 1.070717
2025-01-26 14:26:02,128 Epoch: [5/20] Iter:[260/286], Time: 2.02, lr: [0.0005571848056973766], Loss: 1.856244, Acc:0.630366, Source Loss: 1.316093, Target Loss: 1.200021, MixUp Loss: 0.988751
2025-01-26 14:26:22,768 Epoch: [5/20] Iter:[270/286], Time: 2.02, lr: [0.0005559403178599708], Loss: 1.859263, Acc:0.630510, Source Loss: 1.317164, Target Loss: 1.208146, MixUp Loss: 1.026315
2025-01-26 14:26:43,639 Epoch: [5/20] Iter:[280/286], Time: 2.02, lr: [0.0005546955204096333], Loss: 1.861974, Acc:0.629465, Source Loss: 1.318462, Target Loss: 1.207640, MixUp Loss: 1.176334
2025-01-26 14:32:31,144 0 [0.         0.47717673 0.27743339 0.137091   0.40032409 0.03273336
 0.10366134 0.00600076] 0.17930258338046315
2025-01-26 14:32:31,145 1 [0.00000000e+00 4.77009589e-01 3.60135830e-01 1.78343878e-01
 3.76682528e-01 2.70349329e-04 2.83386148e-02 3.64439978e-03] 0.17805314857586702
2025-01-26 14:32:31,146 Epoch 6/20 - Source Loss: 1.3211, Target Loss: 1.2099
2025-01-26 14:32:31,146 => saving checkpoint to output/loveDa/pidnet_small_loveda_train_DACScheckpoint.pth.tar
2025-01-26 14:32:31,548 Epoch [5], Loss: 1.866, MeanIoU: 0.1781, best_mIoU: 0.1781
2025-01-26 14:32:31,549 IoU per class: [0.00000000e+00 4.77009589e-01 3.60135830e-01 1.78343878e-01
 3.76682528e-01 2.70349329e-04 2.83386148e-02 3.64439978e-03]
2025-01-26 14:32:31,722 Attention!!!
2025-01-26 14:32:31,722 Loaded 302 parameters!
2025-01-26 14:32:31,722 Over!!!
2025-01-26 14:32:33,922 Epoch: [6/20] Iter:[0/286], Time: 2.01, lr: [0.00038883180291978005], Loss: 2.057412, Acc:0.885499, Source Loss: 1.446820, Target Loss: 1.205691, MixUp Loss: 1.221185
2025-01-26 14:32:54,307 Epoch: [6/20] Iter:[10/286], Time: 2.04, lr: [0.00038795769612013845], Loss: 1.989610, Acc:0.666950, Source Loss: 1.414448, Target Loss: 1.092014, MixUp Loss: 1.321169
2025-01-26 14:33:14,481 Epoch: [6/20] Iter:[20/286], Time: 2.03, lr: [0.000387083370437874], Loss: 1.972133, Acc:0.658576, Source Loss: 1.410663, Target Loss: 1.049805, MixUp Loss: 1.224910
2025-01-26 14:33:33,803 Epoch: [6/20] Iter:[30/286], Time: 2.00, lr: [0.0003862088252685651], Loss: 1.955911, Acc:0.681299, Source Loss: 1.418658, Target Loss: 1.006862, MixUp Loss: 0.919367
2025-01-26 14:33:54,072 Epoch: [6/20] Iter:[40/286], Time: 2.00, lr: [0.00038533406000459557], Loss: 1.885053, Acc:0.663028, Source Loss: 1.352989, Target Loss: 1.020359, MixUp Loss: 0.964576
2025-01-26 14:34:13,942 Epoch: [6/20] Iter:[50/286], Time: 2.00, lr: [0.0003844590740351299], Loss: 1.867841, Acc:0.652757, Source Loss: 1.336665, Target Loss: 1.050235, MixUp Loss: 0.866744
2025-01-26 14:34:34,257 Epoch: [6/20] Iter:[60/286], Time: 2.01, lr: [0.0003835838667460882], Loss: 1.833122, Acc:0.654113, Source Loss: 1.312127, Target Loss: 1.033228, MixUp Loss: 0.888571
2025-01-26 14:34:54,436 Epoch: [6/20] Iter:[70/286], Time: 2.01, lr: [0.00038270843752012006], Loss: 1.851208, Acc:0.652678, Source Loss: 1.325266, Target Loss: 1.041189, MixUp Loss: 1.149016
2025-01-26 14:35:14,950 Epoch: [6/20] Iter:[80/286], Time: 2.01, lr: [0.00038183278573657945], Loss: 1.843753, Acc:0.662289, Source Loss: 1.322373, Target Loss: 1.038707, MixUp Loss: 0.975758
2025-01-26 14:35:35,910 Epoch: [6/20] Iter:[90/286], Time: 2.02, lr: [0.0003809569107714984], Loss: 1.863224, Acc:0.673509, Source Loss: 1.339020, Target Loss: 1.036070, MixUp Loss: 1.289757
2025-01-26 14:35:55,965 Epoch: [6/20] Iter:[100/286], Time: 2.02, lr: [0.0003800808119975605], Loss: 1.854371, Acc:0.674579, Source Loss: 1.334870, Target Loss: 1.029945, MixUp Loss: 0.740642
2025-01-26 14:36:16,647 Epoch: [6/20] Iter:[110/286], Time: 2.02, lr: [0.00037920448878407475], Loss: 1.887448, Acc:0.683233, Source Loss: 1.362088, Target Loss: 1.037182, MixUp Loss: 1.361157
2025-01-26 14:36:36,676 Epoch: [6/20] Iter:[120/286], Time: 2.02, lr: [0.00037832794049694825], Loss: 1.894633, Acc:0.685531, Source Loss: 1.369561, Target Loss: 1.037012, MixUp Loss: 1.177577
2025-01-26 14:36:56,364 Epoch: [6/20] Iter:[130/286], Time: 2.02, lr: [0.00037745116649865937], Loss: 1.891357, Acc:0.684257, Source Loss: 1.367202, Target Loss: 1.039620, MixUp Loss: 1.008213
2025-01-26 14:37:16,434 Epoch: [6/20] Iter:[140/286], Time: 2.02, lr: [0.00037657416614823007], Loss: 1.866415, Acc:0.676781, Source Loss: 1.348034, Target Loss: 1.040798, MixUp Loss: 0.748477
2025-01-26 14:37:36,015 Epoch: [6/20] Iter:[150/286], Time: 2.01, lr: [0.0003756969388011982], Loss: 1.864491, Acc:0.673747, Source Loss: 1.345958, Target Loss: 1.043339, MixUp Loss: 0.903636
2025-01-26 14:37:56,708 Epoch: [6/20] Iter:[160/286], Time: 2.02, lr: [0.0003748194838095899], Loss: 1.856820, Acc:0.674892, Source Loss: 1.339855, Target Loss: 1.043025, MixUp Loss: 0.728912
2025-01-26 14:38:16,928 Epoch: [6/20] Iter:[170/286], Time: 2.02, lr: [0.00037394180052189045], Loss: 1.852502, Acc:0.675153, Source Loss: 1.335151, Target Loss: 1.045025, MixUp Loss: 0.843226
2025-01-26 14:38:37,483 Epoch: [6/20] Iter:[180/286], Time: 2.02, lr: [0.00037306388828301645], Loss: 1.848411, Acc:0.676222, Source Loss: 1.333521, Target Loss: 1.043800, MixUp Loss: 0.883796
2025-01-26 14:38:57,745 Epoch: [6/20] Iter:[190/286], Time: 2.02, lr: [0.0003721857464342865], Loss: 1.856102, Acc:0.675045, Source Loss: 1.338986, Target Loss: 1.046970, MixUp Loss: 1.025640
2025-01-26 14:39:17,163 Epoch: [6/20] Iter:[200/286], Time: 2.02, lr: [0.00037130737431339156], Loss: 1.855797, Acc:0.676276, Source Loss: 1.336768, Target Loss: 1.051577, MixUp Loss: 1.593333
2025-01-26 14:39:37,266 Epoch: [6/20] Iter:[210/286], Time: 2.02, lr: [0.00037042877125436664], Loss: 1.851969, Acc:0.676153, Source Loss: 1.333665, Target Loss: 1.053560, MixUp Loss: 0.942262
2025-01-26 14:39:56,685 Epoch: [6/20] Iter:[220/286], Time: 2.01, lr: [0.0003695499365875593], Loss: 1.846176, Acc:0.674744, Source Loss: 1.329495, Target Loss: 1.049270, MixUp Loss: 0.872498
2025-01-26 14:40:16,828 Epoch: [6/20] Iter:[230/286], Time: 2.01, lr: [0.00036867086963960065], Loss: 1.846254, Acc:0.673531, Source Loss: 1.330757, Target Loss: 1.050692, MixUp Loss: 0.766101
2025-01-26 14:40:36,444 Epoch: [6/20] Iter:[240/286], Time: 2.01, lr: [0.00036779156973337437], Loss: 1.852703, Acc:0.673232, Source Loss: 1.336667, Target Loss: 1.049719, MixUp Loss: 1.100609
2025-01-26 14:40:56,668 Epoch: [6/20] Iter:[250/286], Time: 2.01, lr: [0.00036691203618798577], Loss: 1.852998, Acc:0.671527, Source Loss: 1.335030, Target Loss: 1.051412, MixUp Loss: 1.247345
2025-01-26 14:41:17,199 Epoch: [6/20] Iter:[260/286], Time: 2.01, lr: [0.00036603226831873075], Loss: 1.853543, Acc:0.671961, Source Loss: 1.333227, Target Loss: 1.057093, MixUp Loss: 1.097426
2025-01-26 14:41:36,801 Epoch: [6/20] Iter:[270/286], Time: 2.01, lr: [0.0003651522654370643], Loss: 1.850751, Acc:0.671649, Source Loss: 1.332025, Target Loss: 1.053966, MixUp Loss: 0.869076
2025-01-26 14:41:57,143 Epoch: [6/20] Iter:[280/286], Time: 2.01, lr: [0.00036427202685056817], Loss: 1.852835, Acc:0.671424, Source Loss: 1.333910, Target Loss: 1.057088, MixUp Loss: 1.274250
2025-01-26 14:47:38,666 0 [0.         0.42442003 0.20816389 0.09712494 0.28164039 0.12754461
 0.04967029 0.0283942 ] 0.15211979256592734
2025-01-26 14:47:38,667 1 [0.         0.4309734  0.21803006 0.1302208  0.25954499 0.02079162
 0.02407234 0.16105664] 0.1555862322304846
2025-01-26 14:47:38,668 Epoch 7/20 - Source Loss: 1.3324, Target Loss: 1.0570
2025-01-26 14:47:38,668 => saving checkpoint to output/loveDa/pidnet_small_loveda_train_DACScheckpoint.pth.tar
2025-01-26 14:47:38,983 Epoch [6], Loss: 1.852, MeanIoU: 0.1556, best_mIoU: 0.1781
2025-01-26 14:47:38,984 IoU per class: [0.         0.4309734  0.21803006 0.1302208  0.25954499 0.02079162
 0.02407234 0.16105664]
2025-01-26 14:47:39,448 Attention!!!
2025-01-26 14:47:39,448 Loaded 302 parameters!
2025-01-26 14:47:39,448 Over!!!
2025-01-26 14:47:41,603 Epoch: [7/20] Iter:[0/286], Time: 2.25, lr: [0.0002334508871673768], Loss: 1.907789, Acc:0.551072, Source Loss: 1.303336, Target Loss: 1.688734, MixUp Loss: 1.208906
2025-01-26 14:48:02,141 Epoch: [7/20] Iter:[10/286], Time: 2.07, lr: [0.00023288570674356607], Loss: 1.883320, Acc:0.635093, Source Loss: 1.272829, Target Loss: 1.414466, MixUp Loss: 1.119702
2025-01-26 14:48:22,110 Epoch: [7/20] Iter:[20/286], Time: 2.04, lr: [0.00023232037387710137], Loss: 1.820764, Acc:0.639073, Source Loss: 1.245862, Target Loss: 1.290542, MixUp Loss: 1.011796
2025-01-26 14:48:42,971 Epoch: [7/20] Iter:[30/286], Time: 2.05, lr: [0.00023175488811446717], Loss: 1.818575, Acc:0.656785, Source Loss: 1.259636, Target Loss: 1.221245, MixUp Loss: 1.063254
2025-01-26 14:49:03,648 Epoch: [7/20] Iter:[40/286], Time: 2.06, lr: [0.00023118924899956546], Loss: 1.765686, Acc:0.663785, Source Loss: 1.225507, Target Loss: 1.210379, MixUp Loss: 0.866320
2025-01-26 14:49:23,540 Epoch: [7/20] Iter:[50/286], Time: 2.04, lr: [0.00023062345607369333], Loss: 1.783788, Acc:0.667197, Source Loss: 1.226346, Target Loss: 1.241378, MixUp Loss: 0.995686
2025-01-26 14:49:43,910 Epoch: [7/20] Iter:[60/286], Time: 2.04, lr: [0.00023005750887552175], Loss: 1.794030, Acc:0.674496, Source Loss: 1.237294, Target Loss: 1.244135, MixUp Loss: 1.000306
2025-01-26 14:50:03,503 Epoch: [7/20] Iter:[70/286], Time: 2.03, lr: [0.00022949140694107273], Loss: 1.778413, Acc:0.672787, Source Loss: 1.230586, Target Loss: 1.232536, MixUp Loss: 1.332931
2025-01-26 14:50:23,747 Epoch: [7/20] Iter:[80/286], Time: 2.03, lr: [0.0002289251498036968], Loss: 1.758350, Acc:0.672992, Source Loss: 1.221094, Target Loss: 1.216487, MixUp Loss: 0.924537
2025-01-26 14:50:43,817 Epoch: [7/20] Iter:[90/286], Time: 2.03, lr: [0.00022835873699405084], Loss: 1.775943, Acc:0.680972, Source Loss: 1.234083, Target Loss: 1.216587, MixUp Loss: 1.365694
2025-01-26 14:51:04,226 Epoch: [7/20] Iter:[100/286], Time: 2.03, lr: [0.00022779216804007428], Loss: 1.793227, Acc:0.682999, Source Loss: 1.251306, Target Loss: 1.198875, MixUp Loss: 1.345458
2025-01-26 14:51:24,717 Epoch: [7/20] Iter:[110/286], Time: 2.03, lr: [0.00022722544246696623], Loss: 1.805421, Acc:0.686503, Source Loss: 1.262103, Target Loss: 1.198554, MixUp Loss: 1.151180
2025-01-26 14:51:44,391 Epoch: [7/20] Iter:[120/286], Time: 2.03, lr: [0.00022665855979716213], Loss: 1.802078, Acc:0.688813, Source Loss: 1.259637, Target Loss: 1.194853, MixUp Loss: 1.204894
2025-01-26 14:52:04,873 Epoch: [7/20] Iter:[130/286], Time: 2.03, lr: [0.0002260915195503092], Loss: 1.806997, Acc:0.691145, Source Loss: 1.259442, Target Loss: 1.206500, MixUp Loss: 0.947274
2025-01-26 14:52:24,784 Epoch: [7/20] Iter:[140/286], Time: 2.02, lr: [0.0002255243212432434], Loss: 1.806084, Acc:0.692483, Source Loss: 1.261544, Target Loss: 1.193691, MixUp Loss: 1.121416
2025-01-26 14:52:45,583 Epoch: [7/20] Iter:[150/286], Time: 2.03, lr: [0.00022495696438996402], Loss: 1.798556, Acc:0.696066, Source Loss: 1.258270, Target Loss: 1.180461, MixUp Loss: 1.039681
2025-01-26 14:53:06,347 Epoch: [7/20] Iter:[160/286], Time: 2.03, lr: [0.00022438944850160982], Loss: 1.796842, Acc:0.696005, Source Loss: 1.257598, Target Loss: 1.179727, MixUp Loss: 1.194603
2025-01-26 14:53:26,302 Epoch: [7/20] Iter:[170/286], Time: 2.03, lr: [0.0002238217730864336], Loss: 1.805745, Acc:0.701326, Source Loss: 1.265162, Target Loss: 1.179998, MixUp Loss: 0.968939
2025-01-26 14:53:46,876 Epoch: [7/20] Iter:[180/286], Time: 2.03, lr: [0.00022325393764977726], Loss: 1.812251, Acc:0.705758, Source Loss: 1.271040, Target Loss: 1.174913, MixUp Loss: 1.081801
2025-01-26 14:54:06,595 Epoch: [7/20] Iter:[190/286], Time: 2.03, lr: [0.00022268594169404623], Loss: 1.814685, Acc:0.707976, Source Loss: 1.274711, Target Loss: 1.168192, MixUp Loss: 1.090258
2025-01-26 14:54:27,268 Epoch: [7/20] Iter:[200/286], Time: 2.03, lr: [0.0002221177847186835], Loss: 1.829728, Acc:0.709556, Source Loss: 1.286475, Target Loss: 1.168991, MixUp Loss: 1.156750
2025-01-26 14:54:48,048 Epoch: [7/20] Iter:[210/286], Time: 2.03, lr: [0.0002215494662201438], Loss: 1.833151, Acc:0.711485, Source Loss: 1.291317, Target Loss: 1.162662, MixUp Loss: 1.356986
2025-01-26 14:55:08,038 Epoch: [7/20] Iter:[220/286], Time: 2.03, lr: [0.00022098098569186704], Loss: 1.821067, Acc:0.711779, Source Loss: 1.284111, Target Loss: 1.153305, MixUp Loss: 0.886652
2025-01-26 14:55:29,033 Epoch: [7/20] Iter:[230/286], Time: 2.03, lr: [0.0002204123426242514], Loss: 1.824422, Acc:0.711553, Source Loss: 1.289018, Target Loss: 1.149018, MixUp Loss: 0.836709
2025-01-26 14:55:48,996 Epoch: [7/20] Iter:[240/286], Time: 2.03, lr: [0.00021984353650462662], Loss: 1.824220, Acc:0.710769, Source Loss: 1.288975, Target Loss: 1.144711, MixUp Loss: 0.946146
2025-01-26 14:56:09,230 Epoch: [7/20] Iter:[250/286], Time: 2.03, lr: [0.0002192745668172265], Loss: 1.823479, Acc:0.711923, Source Loss: 1.288506, Target Loss: 1.145485, MixUp Loss: 1.151686
2025-01-26 14:56:29,460 Epoch: [7/20] Iter:[260/286], Time: 2.03, lr: [0.00021870543304316123], Loss: 1.821326, Acc:0.712186, Source Loss: 1.285903, Target Loss: 1.148395, MixUp Loss: 1.323443
2025-01-26 14:56:49,288 Epoch: [7/20] Iter:[270/286], Time: 2.03, lr: [0.00021813613466038938], Loss: 1.824988, Acc:0.714785, Source Loss: 1.289642, Target Loss: 1.150657, MixUp Loss: 1.026309
2025-01-26 14:57:09,765 Epoch: [7/20] Iter:[280/286], Time: 2.03, lr: [0.0002175666711436895], Loss: 1.830721, Acc:0.715590, Source Loss: 1.294701, Target Loss: 1.152509, MixUp Loss: 1.418818
2025-01-26 15:02:42,269 0 [0.         0.45426253 0.25009028 0.13424022 0.39564996 0.07298383
 0.0267486  0.03747839] 0.17143172771236323
2025-01-26 15:02:42,269 1 [0.         0.51963344 0.38777493 0.231345   0.37887897 0.11852543
 0.05492205 0.24413093] 0.24190134387659856
2025-01-26 15:02:42,271 Epoch 8/20 - Source Loss: 1.2988, Target Loss: 1.1520
2025-01-26 15:02:42,271 => saving checkpoint to output/loveDa/pidnet_small_loveda_train_DACScheckpoint.pth.tar
2025-01-26 15:02:42,665 Epoch [7], Loss: 1.835, MeanIoU: 0.2419, best_mIoU: 0.2419
2025-01-26 15:02:42,666 IoU per class: [0.         0.51963344 0.38777493 0.231345   0.37887897 0.11852543
 0.05492205 0.24413093]
2025-01-26 15:02:42,839 Attention!!!
2025-01-26 15:02:42,839 Loaded 302 parameters!
2025-01-26 15:02:42,839 Over!!!
2025-01-26 15:02:44,878 Epoch: [8/20] Iter:[0/286], Time: 1.85, lr: [0.0001266411320141524], Loss: 1.317456, Acc:0.598256, Source Loss: 0.968356, Target Loss: 1.049854, MixUp Loss: 0.698199
2025-01-26 15:03:05,297 Epoch: [8/20] Iter:[10/286], Time: 2.02, lr: [0.00012630898270872147], Loss: 1.707260, Acc:0.731840, Source Loss: 1.197109, Target Loss: 1.248931, MixUp Loss: 0.838300
2025-01-26 15:03:25,570 Epoch: [8/20] Iter:[20/286], Time: 2.03, lr: [0.0001259767363260439], Loss: 1.724118, Acc:0.720773, Source Loss: 1.235587, Target Loss: 1.265168, MixUp Loss: 0.777822
2025-01-26 15:03:45,481 Epoch: [8/20] Iter:[30/286], Time: 2.01, lr: [0.00012564439255310401], Loss: 1.788046, Acc:0.727496, Source Loss: 1.277162, Target Loss: 1.267000, MixUp Loss: 1.139111
2025-01-26 15:04:06,075 Epoch: [8/20] Iter:[40/286], Time: 2.03, lr: [0.00012531195107495373], Loss: 1.809365, Acc:0.744511, Source Loss: 1.295582, Target Loss: 1.246410, MixUp Loss: 0.991706
2025-01-26 15:04:25,912 Epoch: [8/20] Iter:[50/286], Time: 2.02, lr: [0.00012497941157469481], Loss: 1.837367, Acc:0.748848, Source Loss: 1.318536, Target Loss: 1.243929, MixUp Loss: 0.844162
2025-01-26 15:04:46,290 Epoch: [8/20] Iter:[60/286], Time: 2.02, lr: [0.00012464677373346097], Loss: 1.842893, Acc:0.751960, Source Loss: 1.323779, Target Loss: 1.229446, MixUp Loss: 1.082704
2025-01-26 15:05:06,246 Epoch: [8/20] Iter:[70/286], Time: 2.02, lr: [0.00012431403723039982], Loss: 1.803812, Acc:0.744895, Source Loss: 1.291363, Target Loss: 1.211332, MixUp Loss: 0.967151
2025-01-26 15:05:26,046 Epoch: [8/20] Iter:[80/286], Time: 2.01, lr: [0.00012398120174265446], Loss: 1.805479, Acc:0.751591, Source Loss: 1.297140, Target Loss: 1.179365, MixUp Loss: 0.989491
2025-01-26 15:05:46,279 Epoch: [8/20] Iter:[90/286], Time: 2.01, lr: [0.00012364826694534513], Loss: 1.801961, Acc:0.752454, Source Loss: 1.297646, Target Loss: 1.168177, MixUp Loss: 1.251561
2025-01-26 15:06:06,051 Epoch: [8/20] Iter:[100/286], Time: 2.01, lr: [0.00012331523251155022], Loss: 1.804804, Acc:0.752660, Source Loss: 1.296992, Target Loss: 1.171662, MixUp Loss: 1.065599
2025-01-26 15:06:26,521 Epoch: [8/20] Iter:[110/286], Time: 2.01, lr: [0.0001229820981122874], Loss: 1.806058, Acc:0.754156, Source Loss: 1.298232, Target Loss: 1.175897, MixUp Loss: 0.865574
2025-01-26 15:06:46,444 Epoch: [8/20] Iter:[120/286], Time: 2.01, lr: [0.00012264886341649436], Loss: 1.825379, Acc:0.759785, Source Loss: 1.318003, Target Loss: 1.172052, MixUp Loss: 1.165186
2025-01-26 15:07:06,846 Epoch: [8/20] Iter:[130/286], Time: 2.01, lr: [0.00012231552809100935], Loss: 1.824246, Acc:0.762204, Source Loss: 1.312153, Target Loss: 1.184320, MixUp Loss: 1.005501
2025-01-26 15:07:27,317 Epoch: [8/20] Iter:[140/286], Time: 2.02, lr: [0.00012198209180055144], Loss: 1.824409, Acc:0.767485, Source Loss: 1.311644, Target Loss: 1.183417, MixUp Loss: 0.662531
2025-01-26 15:07:46,945 Epoch: [8/20] Iter:[150/286], Time: 2.01, lr: [0.00012164855420770059], Loss: 1.822172, Acc:0.768782, Source Loss: 1.308981, Target Loss: 1.185955, MixUp Loss: 1.441608
2025-01-26 15:08:07,316 Epoch: [8/20] Iter:[160/286], Time: 2.01, lr: [0.00012131491497287736], Loss: 1.813060, Acc:0.769631, Source Loss: 1.301221, Target Loss: 1.191922, MixUp Loss: 0.934077
2025-01-26 15:08:26,867 Epoch: [8/20] Iter:[170/286], Time: 2.01, lr: [0.00012098117375432266], Loss: 1.807560, Acc:0.772263, Source Loss: 1.297102, Target Loss: 1.187386, MixUp Loss: 1.067610
2025-01-26 15:08:47,144 Epoch: [8/20] Iter:[180/286], Time: 2.01, lr: [0.0001206473302080767], Loss: 1.816643, Acc:0.771426, Source Loss: 1.305344, Target Loss: 1.190520, MixUp Loss: 0.893213
2025-01-26 15:09:07,277 Epoch: [8/20] Iter:[190/286], Time: 2.01, lr: [0.00012031338398795832], Loss: 1.817724, Acc:0.774129, Source Loss: 1.306278, Target Loss: 1.188320, MixUp Loss: 0.853018
2025-01-26 15:09:27,117 Epoch: [8/20] Iter:[200/286], Time: 2.01, lr: [0.00011997933474554366], Loss: 1.813285, Acc:0.775170, Source Loss: 1.303078, Target Loss: 1.179622, MixUp Loss: 0.688972
2025-01-26 15:09:47,677 Epoch: [8/20] Iter:[210/286], Time: 2.01, lr: [0.00011964518213014445], Loss: 1.810665, Acc:0.774499, Source Loss: 1.301443, Target Loss: 1.179414, MixUp Loss: 0.639692
2025-01-26 15:10:07,334 Epoch: [8/20] Iter:[220/286], Time: 2.01, lr: [0.00011931092578878647], Loss: 1.803924, Acc:0.774428, Source Loss: 1.297585, Target Loss: 1.175132, MixUp Loss: 0.916046
2025-01-26 15:10:27,780 Epoch: [8/20] Iter:[230/286], Time: 2.01, lr: [0.00011897656536618744], Loss: 1.799674, Acc:0.776434, Source Loss: 1.293671, Target Loss: 1.169783, MixUp Loss: 1.070749
2025-01-26 15:10:47,376 Epoch: [8/20] Iter:[240/286], Time: 2.01, lr: [0.00011864210050473452], Loss: 1.792352, Acc:0.774593, Source Loss: 1.288092, Target Loss: 1.166877, MixUp Loss: 0.820355
2025-01-26 15:11:07,546 Epoch: [8/20] Iter:[250/286], Time: 2.01, lr: [0.00011830753084446187], Loss: 1.783056, Acc:0.773753, Source Loss: 1.280526, Target Loss: 1.163745, MixUp Loss: 0.689814
2025-01-26 15:11:27,762 Epoch: [8/20] Iter:[260/286], Time: 2.01, lr: [0.00011797285602302752], Loss: 1.779660, Acc:0.771823, Source Loss: 1.277111, Target Loss: 1.163199, MixUp Loss: 1.616329
2025-01-26 15:11:47,299 Epoch: [8/20] Iter:[270/286], Time: 2.01, lr: [0.00011763807567569031], Loss: 1.777209, Acc:0.771682, Source Loss: 1.275316, Target Loss: 1.163414, MixUp Loss: 0.763832
2025-01-26 15:12:07,739 Epoch: [8/20] Iter:[280/286], Time: 2.01, lr: [0.00011730318943528637], Loss: 1.783822, Acc:0.773569, Source Loss: 1.281279, Target Loss: 1.163612, MixUp Loss: 1.002749
2025-01-26 15:17:49,307 0 [0.         0.27960626 0.2231742  0.15800334 0.39447301 0.05525952
 0.11936349 0.01456342] 0.1555554059413255
2025-01-26 15:17:49,307 1 [0.         0.40436786 0.2048197  0.32818232 0.45987482 0.0695628
 0.1923617  0.39855989] 0.25721613811205973
2025-01-26 15:17:49,308 Epoch 9/20 - Source Loss: 1.2804, Target Loss: 1.1640
2025-01-26 15:17:49,308 => saving checkpoint to output/loveDa/pidnet_small_loveda_train_DACScheckpoint.pth.tar
2025-01-26 15:17:49,709 Epoch [8], Loss: 1.782, MeanIoU: 0.2572, best_mIoU: 0.2572
2025-01-26 15:17:49,711 IoU per class: [0.         0.40436786 0.2048197  0.32818232 0.45987482 0.0695628
 0.1923617  0.39855989]
2025-01-26 15:17:49,874 Attention!!!
2025-01-26 15:17:49,874 Loaded 302 parameters!
2025-01-26 15:17:49,874 Over!!!
2025-01-26 15:17:52,008 Epoch: [9/20] Iter:[0/286], Time: 1.92, lr: [6.152257535518514e-05], Loss: 2.555204, Acc:0.657948, Source Loss: 1.803383, Target Loss: 1.218489, MixUp Loss: 1.503642
2025-01-26 15:18:12,754 Epoch: [9/20] Iter:[10/286], Time: 2.06, lr: [6.134654506844819e-05], Loss: 1.800977, Acc:0.663502, Source Loss: 1.210453, Target Loss: 1.409022, MixUp Loss: 1.091858
2025-01-26 15:18:33,273 Epoch: [9/20] Iter:[20/286], Time: 2.06, lr: [6.1170458640554e-05], Loss: 1.830927, Acc:0.686522, Source Loss: 1.260940, Target Loss: 1.312839, MixUp Loss: 1.018310
2025-01-26 15:18:53,908 Epoch: [9/20] Iter:[30/286], Time: 2.06, lr: [6.099431587391664e-05], Loss: 1.884690, Acc:0.696967, Source Loss: 1.298901, Target Loss: 1.327120, MixUp Loss: 1.399833
2025-01-26 15:19:14,289 Epoch: [9/20] Iter:[40/286], Time: 2.05, lr: [6.0818116569618324e-05], Loss: 1.836810, Acc:0.708258, Source Loss: 1.272814, Target Loss: 1.291182, MixUp Loss: 0.820759
2025-01-26 15:19:34,192 Epoch: [9/20] Iter:[50/286], Time: 2.04, lr: [6.06418605273962e-05], Loss: 1.800277, Acc:0.724771, Source Loss: 1.245606, Target Loss: 1.268676, MixUp Loss: 0.823875
2025-01-26 15:19:54,732 Epoch: [9/20] Iter:[60/286], Time: 2.04, lr: [6.046554754562874e-05], Loss: 1.798719, Acc:0.720209, Source Loss: 1.246414, Target Loss: 1.257622, MixUp Loss: 1.007299
2025-01-26 15:20:14,701 Epoch: [9/20] Iter:[70/286], Time: 2.04, lr: [6.028917742132223e-05], Loss: 1.805653, Acc:0.719760, Source Loss: 1.248829, Target Loss: 1.269610, MixUp Loss: 1.748642
2025-01-26 15:20:35,203 Epoch: [9/20] Iter:[80/286], Time: 2.04, lr: [6.011274995009686e-05], Loss: 1.818395, Acc:0.720342, Source Loss: 1.260363, Target Loss: 1.251939, MixUp Loss: 0.797575
2025-01-26 15:20:54,967 Epoch: [9/20] Iter:[90/286], Time: 2.03, lr: [5.9936264926172644e-05], Loss: 1.827872, Acc:0.723226, Source Loss: 1.265493, Target Loss: 1.263547, MixUp Loss: 1.446421
2025-01-26 15:21:15,494 Epoch: [9/20] Iter:[100/286], Time: 2.03, lr: [5.9759722142355464e-05], Loss: 1.819608, Acc:0.722677, Source Loss: 1.258805, Target Loss: 1.259725, MixUp Loss: 1.045563
2025-01-26 15:21:36,173 Epoch: [9/20] Iter:[110/286], Time: 2.04, lr: [5.958312139002232e-05], Loss: 1.822440, Acc:0.723919, Source Loss: 1.265082, Target Loss: 1.254867, MixUp Loss: 1.378426
2025-01-26 15:21:55,891 Epoch: [9/20] Iter:[120/286], Time: 2.03, lr: [5.940646245910705e-05], Loss: 1.829211, Acc:0.731195, Source Loss: 1.271378, Target Loss: 1.255418, MixUp Loss: 0.977116
2025-01-26 15:22:16,405 Epoch: [9/20] Iter:[130/286], Time: 2.03, lr: [5.922974513808535e-05], Loss: 1.828639, Acc:0.732552, Source Loss: 1.272000, Target Loss: 1.253157, MixUp Loss: 1.070450
2025-01-26 15:22:36,103 Epoch: [9/20] Iter:[140/286], Time: 2.03, lr: [5.905296921395986e-05], Loss: 1.826421, Acc:0.734485, Source Loss: 1.270959, Target Loss: 1.256741, MixUp Loss: 1.051200
2025-01-26 15:22:56,652 Epoch: [9/20] Iter:[150/286], Time: 2.03, lr: [5.8876134472244995e-05], Loss: 1.835220, Acc:0.734528, Source Loss: 1.279471, Target Loss: 1.255077, MixUp Loss: 1.194028
2025-01-26 15:23:16,844 Epoch: [9/20] Iter:[160/286], Time: 2.03, lr: [5.869924069695146e-05], Loss: 1.815321, Acc:0.733494, Source Loss: 1.262809, Target Loss: 1.252534, MixUp Loss: 0.889385
2025-01-26 15:23:36,758 Epoch: [9/20] Iter:[170/286], Time: 2.03, lr: [5.8522287670570693e-05], Loss: 1.814851, Acc:0.735914, Source Loss: 1.264007, Target Loss: 1.247644, MixUp Loss: 0.848090
2025-01-26 15:23:57,169 Epoch: [9/20] Iter:[180/286], Time: 2.03, lr: [5.8345275174059074e-05], Loss: 1.814432, Acc:0.738014, Source Loss: 1.263956, Target Loss: 1.246534, MixUp Loss: 0.982840
2025-01-26 15:24:16,841 Epoch: [9/20] Iter:[190/286], Time: 2.02, lr: [5.8168202986821744e-05], Loss: 1.817091, Acc:0.737964, Source Loss: 1.266262, Target Loss: 1.250005, MixUp Loss: 1.334965
2025-01-26 15:24:37,320 Epoch: [9/20] Iter:[200/286], Time: 2.03, lr: [5.799107088669652e-05], Loss: 1.805626, Acc:0.738045, Source Loss: 1.257789, Target Loss: 1.247088, MixUp Loss: 0.669255
2025-01-26 15:24:57,341 Epoch: [9/20] Iter:[210/286], Time: 2.02, lr: [5.781387864993721e-05], Loss: 1.794329, Acc:0.740115, Source Loss: 1.248949, Target Loss: 1.251539, MixUp Loss: 1.098031
2025-01-26 15:25:17,724 Epoch: [9/20] Iter:[220/286], Time: 2.03, lr: [5.763662605119703e-05], Loss: 1.817576, Acc:0.740026, Source Loss: 1.267866, Target Loss: 1.253317, MixUp Loss: 1.217888
2025-01-26 15:25:38,275 Epoch: [9/20] Iter:[230/286], Time: 2.03, lr: [5.74593128635116e-05], Loss: 1.811189, Acc:0.741282, Source Loss: 1.263625, Target Loss: 1.252410, MixUp Loss: 1.391051
2025-01-26 15:25:57,983 Epoch: [9/20] Iter:[240/286], Time: 2.02, lr: [5.728193885828167e-05], Loss: 1.810776, Acc:0.743974, Source Loss: 1.264384, Target Loss: 1.250543, MixUp Loss: 0.844594
2025-01-26 15:26:18,381 Epoch: [9/20] Iter:[250/286], Time: 2.03, lr: [5.7104503805255795e-05], Loss: 1.816422, Acc:0.745082, Source Loss: 1.269789, Target Loss: 1.247994, MixUp Loss: 0.974805
2025-01-26 15:26:38,152 Epoch: [9/20] Iter:[260/286], Time: 2.02, lr: [5.692700747251258e-05], Loss: 1.820780, Acc:0.747813, Source Loss: 1.274544, Target Loss: 1.244457, MixUp Loss: 1.279129
2025-01-26 15:26:58,373 Epoch: [9/20] Iter:[270/286], Time: 2.02, lr: [5.674944962644274e-05], Loss: 1.810995, Acc:0.745822, Source Loss: 1.266382, Target Loss: 1.241312, MixUp Loss: 0.979899
2025-01-26 15:27:19,115 Epoch: [9/20] Iter:[280/286], Time: 2.03, lr: [5.657183003173094e-05], Loss: 1.809065, Acc:0.746781, Source Loss: 1.266490, Target Loss: 1.234079, MixUp Loss: 1.347193
2025-01-26 15:32:51,292 0 [0.         0.33597095 0.10145157 0.13545625 0.37716007 0.1558666
 0.18451862 0.08806232] 0.17231079752216671
2025-01-26 15:32:51,292 1 [0.         0.46499908 0.28054168 0.26961441 0.29974479 0.12602305
 0.12251659 0.33678669] 0.23752828547529137
2025-01-26 15:32:51,294 Epoch 10/20 - Source Loss: 1.2721, Target Loss: 1.2388
2025-01-26 15:32:51,294 => saving checkpoint to output/loveDa/pidnet_small_loveda_train_DACScheckpoint.pth.tar
2025-01-26 15:32:51,572 Epoch [9], Loss: 1.817, MeanIoU: 0.2375, best_mIoU: 0.2572
2025-01-26 15:32:51,572 IoU per class: [0.         0.46499908 0.28054168 0.26961441 0.29974479 0.12602305
 0.12251659 0.33678669]
2025-01-26 15:32:51,718 Attention!!!
2025-01-26 15:32:51,718 Loaded 302 parameters!
2025-01-26 15:32:51,718 Over!!!
2025-01-26 15:32:53,817 Epoch: [10/20] Iter:[0/286], Time: 1.87, lr: [2.6482874185693436e-05], Loss: 1.772854, Acc:0.778513, Source Loss: 1.307457, Target Loss: 1.224529, MixUp Loss: 0.930794
2025-01-26 15:33:14,148 Epoch: [10/20] Iter:[10/286], Time: 2.02, lr: [2.6399521881480454e-05], Loss: 1.650572, Acc:0.697990, Source Loss: 1.141408, Target Loss: 1.133755, MixUp Loss: 1.136020
2025-01-26 15:33:34,512 Epoch: [10/20] Iter:[20/286], Time: 2.03, lr: [2.631614032565036e-05], Loss: 1.714287, Acc:0.706915, Source Loss: 1.185832, Target Loss: 1.155157, MixUp Loss: 0.988925
2025-01-26 15:33:55,209 Epoch: [10/20] Iter:[30/286], Time: 2.04, lr: [2.6232729404884222e-05], Loss: 1.724794, Acc:0.711390, Source Loss: 1.199236, Target Loss: 1.168932, MixUp Loss: 1.099799
2025-01-26 15:34:16,031 Epoch: [10/20] Iter:[40/286], Time: 2.05, lr: [2.6149289005022055e-05], Loss: 1.761089, Acc:0.734364, Source Loss: 1.228429, Target Loss: 1.183747, MixUp Loss: 1.266953
2025-01-26 15:34:35,723 Epoch: [10/20] Iter:[50/286], Time: 2.03, lr: [2.6065819011053613e-05], Loss: 1.792587, Acc:0.741244, Source Loss: 1.256428, Target Loss: 1.192494, MixUp Loss: 1.076779
2025-01-26 15:34:55,933 Epoch: [10/20] Iter:[60/286], Time: 2.03, lr: [2.5982319307108982e-05], Loss: 1.790220, Acc:0.739757, Source Loss: 1.255460, Target Loss: 1.189618, MixUp Loss: 1.232574
2025-01-26 15:35:15,908 Epoch: [10/20] Iter:[70/286], Time: 2.03, lr: [2.5898789776449058e-05], Loss: 1.774427, Acc:0.734449, Source Loss: 1.247187, Target Loss: 1.193108, MixUp Loss: 1.218117
2025-01-26 15:35:36,642 Epoch: [10/20] Iter:[80/286], Time: 2.03, lr: [2.581523030145588e-05], Loss: 1.787370, Acc:0.740404, Source Loss: 1.259505, Target Loss: 1.194513, MixUp Loss: 1.144977
2025-01-26 15:35:57,488 Epoch: [10/20] Iter:[90/286], Time: 2.04, lr: [2.5731640763622867e-05], Loss: 1.812222, Acc:0.737054, Source Loss: 1.274684, Target Loss: 1.212275, MixUp Loss: 1.078655
2025-01-26 15:36:17,376 Epoch: [10/20] Iter:[100/286], Time: 2.03, lr: [2.5648021043544822e-05], Loss: 1.806713, Acc:0.740893, Source Loss: 1.270447, Target Loss: 1.202638, MixUp Loss: 0.881683
2025-01-26 15:36:37,778 Epoch: [10/20] Iter:[110/286], Time: 2.03, lr: [2.556437102090787e-05], Loss: 1.810080, Acc:0.738814, Source Loss: 1.274307, Target Loss: 1.208450, MixUp Loss: 1.271443
2025-01-26 15:36:57,595 Epoch: [10/20] Iter:[120/286], Time: 2.03, lr: [2.548069057447921e-05], Loss: 1.804649, Acc:0.741726, Source Loss: 1.271587, Target Loss: 1.201822, MixUp Loss: 0.863917
2025-01-26 15:37:18,128 Epoch: [10/20] Iter:[130/286], Time: 2.03, lr: [2.539697958209668e-05], Loss: 1.815424, Acc:0.747588, Source Loss: 1.279378, Target Loss: 1.208671, MixUp Loss: 0.868745
2025-01-26 15:37:38,405 Epoch: [10/20] Iter:[140/286], Time: 2.03, lr: [2.5313237920658276e-05], Loss: 1.802063, Acc:0.748481, Source Loss: 1.269615, Target Loss: 1.202673, MixUp Loss: 0.943474
2025-01-26 15:37:57,985 Epoch: [10/20] Iter:[150/286], Time: 2.03, lr: [2.5229465466111345e-05], Loss: 1.799751, Acc:0.749224, Source Loss: 1.266874, Target Loss: 1.202831, MixUp Loss: 1.073280
2025-01-26 15:38:18,228 Epoch: [10/20] Iter:[160/286], Time: 2.03, lr: [2.514566209344179e-05], Loss: 1.804752, Acc:0.752514, Source Loss: 1.271424, Target Loss: 1.198160, MixUp Loss: 0.729675
2025-01-26 15:38:37,753 Epoch: [10/20] Iter:[170/286], Time: 2.02, lr: [2.506182767666299e-05], Loss: 1.802258, Acc:0.749986, Source Loss: 1.268109, Target Loss: 1.195446, MixUp Loss: 0.891100
2025-01-26 15:38:58,630 Epoch: [10/20] Iter:[180/286], Time: 2.03, lr: [2.497796208880458e-05], Loss: 1.809489, Acc:0.751099, Source Loss: 1.274516, Target Loss: 1.198740, MixUp Loss: 1.220683
2025-01-26 15:39:18,931 Epoch: [10/20] Iter:[190/286], Time: 2.03, lr: [2.4894065201901098e-05], Loss: 1.802582, Acc:0.751347, Source Loss: 1.270975, Target Loss: 1.191284, MixUp Loss: 0.962077
2025-01-26 15:39:39,007 Epoch: [10/20] Iter:[200/286], Time: 2.03, lr: [2.4810136886980424e-05], Loss: 1.800421, Acc:0.755535, Source Loss: 1.270547, Target Loss: 1.191336, MixUp Loss: 1.381336
2025-01-26 15:39:59,632 Epoch: [10/20] Iter:[210/286], Time: 2.03, lr: [2.4726177014052023e-05], Loss: 1.809139, Acc:0.758804, Source Loss: 1.279583, Target Loss: 1.189491, MixUp Loss: 0.630835
2025-01-26 15:40:19,645 Epoch: [10/20] Iter:[220/286], Time: 2.03, lr: [2.4642185452095045e-05], Loss: 1.807560, Acc:0.759493, Source Loss: 1.279381, Target Loss: 1.187478, MixUp Loss: 0.820450
2025-01-26 15:40:40,072 Epoch: [10/20] Iter:[230/286], Time: 2.03, lr: [2.4558162069046237e-05], Loss: 1.799142, Acc:0.761381, Source Loss: 1.273902, Target Loss: 1.181365, MixUp Loss: 1.126132
2025-01-26 15:41:00,282 Epoch: [10/20] Iter:[240/286], Time: 2.03, lr: [2.447410673178763e-05], Loss: 1.803610, Acc:0.763536, Source Loss: 1.279055, Target Loss: 1.180368, MixUp Loss: 1.174871
2025-01-26 15:41:19,980 Epoch: [10/20] Iter:[250/286], Time: 2.02, lr: [2.4390019306134076e-05], Loss: 1.797103, Acc:0.759724, Source Loss: 1.273064, Target Loss: 1.177352, MixUp Loss: 1.017997
2025-01-26 15:41:40,439 Epoch: [10/20] Iter:[260/286], Time: 2.02, lr: [2.430589965682056e-05], Loss: 1.802695, Acc:0.762239, Source Loss: 1.276790, Target Loss: 1.179255, MixUp Loss: 0.927388
2025-01-26 15:42:00,227 Epoch: [10/20] Iter:[270/286], Time: 2.02, lr: [2.422174764748931e-05], Loss: 1.804957, Acc:0.762388, Source Loss: 1.277990, Target Loss: 1.178980, MixUp Loss: 1.104767
2025-01-26 15:42:20,369 Epoch: [10/20] Iter:[280/286], Time: 2.02, lr: [2.4137563140676746e-05], Loss: 1.802794, Acc:0.761316, Source Loss: 1.276569, Target Loss: 1.180222, MixUp Loss: 1.005512
2025-01-26 15:47:57,975 0 [0.         0.44371413 0.23996662 0.1074697  0.35309511 0.15090636
 0.16455416 0.07742915] 0.19214190383323454
2025-01-26 15:47:57,976 1 [0.         0.54540099 0.33455392 0.29137426 0.43432919 0.10167111
 0.23107316 0.39580972] 0.2917765436232146
2025-01-26 15:47:57,977 Epoch 11/20 - Source Loss: 1.2741, Target Loss: 1.1793
2025-01-26 15:47:57,977 => saving checkpoint to output/loveDa/pidnet_small_loveda_train_DACScheckpoint.pth.tar
2025-01-26 15:47:58,542 Epoch [10], Loss: 1.800, MeanIoU: 0.2918, best_mIoU: 0.2918
2025-01-26 15:47:58,544 IoU per class: [0.         0.54540099 0.33455392 0.29137426 0.43432919 0.10167111
 0.23107316 0.39580972]
2025-01-26 15:47:58,760 Attention!!!
2025-01-26 15:47:58,760 Loaded 302 parameters!
2025-01-26 15:47:58,760 Over!!!
2025-01-26 15:48:00,873 Epoch: [11/20] Iter:[0/286], Time: 1.96, lr: [9.985785139803017e-06], Loss: 2.019854, Acc:0.800933, Source Loss: 1.388132, Target Loss: 1.072598, MixUp Loss: 1.263444
2025-01-26 15:48:21,169 Epoch: [11/20] Iter:[10/286], Time: 2.02, lr: [9.95086301515505e-06], Loss: 1.812981, Acc:0.810656, Source Loss: 1.274533, Target Loss: 1.110705, MixUp Loss: 0.940975
2025-01-26 15:48:41,953 Epoch: [11/20] Iter:[20/286], Time: 2.05, lr: [9.915927267641005e-06], Loss: 1.819172, Acc:0.818933, Source Loss: 1.278568, Target Loss: 1.096598, MixUp Loss: 1.090328
2025-01-26 15:49:02,736 Epoch: [11/20] Iter:[30/286], Time: 2.06, lr: [9.88097783857583e-06], Loss: 1.780462, Acc:0.801795, Source Loss: 1.257765, Target Loss: 1.084878, MixUp Loss: 0.819035
2025-01-26 15:49:22,670 Epoch: [11/20] Iter:[40/286], Time: 2.04, lr: [9.846014668789938e-06], Loss: 1.826540, Acc:0.793123, Source Loss: 1.300642, Target Loss: 1.077773, MixUp Loss: 1.113163
2025-01-26 15:49:43,573 Epoch: [11/20] Iter:[50/286], Time: 2.05, lr: [9.811037698623294e-06], Loss: 1.830229, Acc:0.800895, Source Loss: 1.307526, Target Loss: 1.081637, MixUp Loss: 1.032138
2025-01-26 15:50:03,480 Epoch: [11/20] Iter:[60/286], Time: 2.04, lr: [9.776046867919379e-06], Loss: 1.828519, Acc:0.808103, Source Loss: 1.312988, Target Loss: 1.090107, MixUp Loss: 0.836078
2025-01-26 15:50:23,655 Epoch: [11/20] Iter:[70/286], Time: 2.04, lr: [9.741042116019062e-06], Loss: 1.807827, Acc:0.804385, Source Loss: 1.294730, Target Loss: 1.083433, MixUp Loss: 0.906442
2025-01-26 15:50:44,034 Epoch: [11/20] Iter:[80/286], Time: 2.04, lr: [9.706023381754393e-06], Loss: 1.802938, Acc:0.804427, Source Loss: 1.290465, Target Loss: 1.080058, MixUp Loss: 1.520752
2025-01-26 15:51:03,996 Epoch: [11/20] Iter:[90/286], Time: 2.03, lr: [9.670990603442264e-06], Loss: 1.807779, Acc:0.811061, Source Loss: 1.296628, Target Loss: 1.081047, MixUp Loss: 0.984174
2025-01-26 15:51:24,443 Epoch: [11/20] Iter:[100/286], Time: 2.03, lr: [9.635943718877987e-06], Loss: 1.815087, Acc:0.808343, Source Loss: 1.303767, Target Loss: 1.073372, MixUp Loss: 1.435173
2025-01-26 15:51:44,131 Epoch: [11/20] Iter:[110/286], Time: 2.03, lr: [9.600882665328741e-06], Loss: 1.804902, Acc:0.808545, Source Loss: 1.296057, Target Loss: 1.081217, MixUp Loss: 1.157447
2025-01-26 15:52:04,517 Epoch: [11/20] Iter:[120/286], Time: 2.03, lr: [9.565807379526949e-06], Loss: 1.814063, Acc:0.811786, Source Loss: 1.306101, Target Loss: 1.078163, MixUp Loss: 0.575376
2025-01-26 15:52:24,687 Epoch: [11/20] Iter:[130/286], Time: 2.03, lr: [9.530717797663501e-06], Loss: 1.808674, Acc:0.806306, Source Loss: 1.303068, Target Loss: 1.080743, MixUp Loss: 0.796824
2025-01-26 15:52:44,824 Epoch: [11/20] Iter:[140/286], Time: 2.03, lr: [9.495613855380902e-06], Loss: 1.813565, Acc:0.810489, Source Loss: 1.304496, Target Loss: 1.080875, MixUp Loss: 1.136631
2025-01-26 15:53:05,280 Epoch: [11/20] Iter:[150/286], Time: 2.03, lr: [9.460495487766274e-06], Loss: 1.815376, Acc:0.811221, Source Loss: 1.305400, Target Loss: 1.086150, MixUp Loss: 1.138555
2025-01-26 15:53:25,023 Epoch: [11/20] Iter:[160/286], Time: 2.03, lr: [9.42536262934424e-06], Loss: 1.803081, Acc:0.809653, Source Loss: 1.294204, Target Loss: 1.085454, MixUp Loss: 1.190394
2025-01-26 15:53:45,451 Epoch: [11/20] Iter:[170/286], Time: 2.03, lr: [9.390215214069733e-06], Loss: 1.803937, Acc:0.812409, Source Loss: 1.296150, Target Loss: 1.084414, MixUp Loss: 1.261208
2025-01-26 15:54:05,516 Epoch: [11/20] Iter:[180/286], Time: 2.03, lr: [9.355053175320619e-06], Loss: 1.795146, Acc:0.810295, Source Loss: 1.287774, Target Loss: 1.088990, MixUp Loss: 1.216266
2025-01-26 15:54:25,665 Epoch: [11/20] Iter:[190/286], Time: 2.02, lr: [9.319876445890232e-06], Loss: 1.789547, Acc:0.808816, Source Loss: 1.281034, Target Loss: 1.091600, MixUp Loss: 1.003612
2025-01-26 15:54:46,073 Epoch: [11/20] Iter:[200/286], Time: 2.03, lr: [9.284684957979775e-06], Loss: 1.787368, Acc:0.807251, Source Loss: 1.278744, Target Loss: 1.091379, MixUp Loss: 1.176807
2025-01-26 15:55:06,081 Epoch: [11/20] Iter:[210/286], Time: 2.02, lr: [9.249478643190575e-06], Loss: 1.791881, Acc:0.808727, Source Loss: 1.283238, Target Loss: 1.089639, MixUp Loss: 0.776121
2025-01-26 15:55:26,346 Epoch: [11/20] Iter:[220/286], Time: 2.02, lr: [9.214257432516234e-06], Loss: 1.783710, Acc:0.806881, Source Loss: 1.275370, Target Loss: 1.092043, MixUp Loss: 1.120995
2025-01-26 15:55:46,071 Epoch: [11/20] Iter:[230/286], Time: 2.02, lr: [9.179021256334605e-06], Loss: 1.789086, Acc:0.808125, Source Loss: 1.278616, Target Loss: 1.093946, MixUp Loss: 1.194674
2025-01-26 15:56:06,679 Epoch: [11/20] Iter:[240/286], Time: 2.02, lr: [9.14377004439966e-06], Loss: 1.779658, Acc:0.805883, Source Loss: 1.270887, Target Loss: 1.092665, MixUp Loss: 0.545325
2025-01-26 15:56:27,183 Epoch: [11/20] Iter:[250/286], Time: 2.02, lr: [9.108503725833187e-06], Loss: 1.777997, Acc:0.806821, Source Loss: 1.269537, Target Loss: 1.090433, MixUp Loss: 1.145352
2025-01-26 15:56:46,953 Epoch: [11/20] Iter:[260/286], Time: 2.02, lr: [9.073222229116375e-06], Loss: 1.776992, Acc:0.806486, Source Loss: 1.266885, Target Loss: 1.093666, MixUp Loss: 1.350786
2025-01-26 15:57:07,401 Epoch: [11/20] Iter:[270/286], Time: 2.02, lr: [9.037925482081213e-06], Loss: 1.779707, Acc:0.807401, Source Loss: 1.269200, Target Loss: 1.092784, MixUp Loss: 0.884553
2025-01-26 15:57:27,027 Epoch: [11/20] Iter:[280/286], Time: 2.02, lr: [9.002613411901763e-06], Loss: 1.776115, Acc:0.807708, Source Loss: 1.264709, Target Loss: 1.091977, MixUp Loss: 1.213027
2025-01-26 16:03:12,185 0 [0.         0.4922154  0.32898706 0.12089315 0.37026539 0.14129292
 0.06055208 0.06831749] 0.19781543689743009
2025-01-26 16:03:12,185 1 [0.         0.539048   0.25696156 0.31168981 0.43109753 0.1163024
 0.0264959  0.35989493] 0.2551862651468827
2025-01-26 16:03:12,186 Epoch 12/20 - Source Loss: 1.2661, Target Loss: 1.0945
2025-01-26 16:03:12,186 => saving checkpoint to output/loveDa/pidnet_small_loveda_train_DACScheckpoint.pth.tar
2025-01-26 16:03:12,494 Epoch [11], Loss: 1.778, MeanIoU: 0.2552, best_mIoU: 0.2918
2025-01-26 16:03:12,494 IoU per class: [0.         0.539048   0.25696156 0.31168981 0.43109753 0.1163024
 0.0264959  0.35989493]
2025-01-26 16:03:12,640 Attention!!!
2025-01-26 16:03:12,640 Loaded 302 parameters!
2025-01-26 16:03:12,640 Over!!!
2025-01-26 16:03:14,805 Epoch: [12/20] Iter:[0/286], Time: 1.94, lr: [3.2763098646082523e-06], Loss: 2.488863, Acc:0.733055, Source Loss: 1.884604, Target Loss: 0.868054, MixUp Loss: 1.208518
2025-01-26 16:03:34,630 Epoch: [12/20] Iter:[10/286], Time: 1.98, lr: [3.2634194612327813e-06], Loss: 1.790893, Acc:0.727827, Source Loss: 1.256199, Target Loss: 1.154410, MixUp Loss: 0.984742
2025-01-26 16:03:55,032 Epoch: [12/20] Iter:[20/286], Time: 2.01, lr: [3.2505233979465975e-06], Loss: 1.782027, Acc:0.734917, Source Loss: 1.243294, Target Loss: 1.157749, MixUp Loss: 1.311865
2025-01-26 16:04:15,602 Epoch: [12/20] Iter:[30/286], Time: 2.02, lr: [3.237621647292404e-06], Loss: 1.789510, Acc:0.742847, Source Loss: 1.261401, Target Loss: 1.140254, MixUp Loss: 1.042667
2025-01-26 16:04:35,116 Epoch: [12/20] Iter:[40/286], Time: 2.01, lr: [3.224714181557486e-06], Loss: 1.757718, Acc:0.734105, Source Loss: 1.232011, Target Loss: 1.151404, MixUp Loss: 0.808700
2025-01-26 16:04:55,594 Epoch: [12/20] Iter:[50/286], Time: 2.01, lr: [3.211800972770185e-06], Loss: 1.758306, Acc:0.739696, Source Loss: 1.230789, Target Loss: 1.142487, MixUp Loss: 1.365482
2025-01-26 16:05:15,523 Epoch: [12/20] Iter:[60/286], Time: 2.01, lr: [3.1988819926963135e-06], Loss: 1.801396, Acc:0.744823, Source Loss: 1.262550, Target Loss: 1.154304, MixUp Loss: 1.073467
2025-01-26 16:05:35,997 Epoch: [12/20] Iter:[70/286], Time: 2.02, lr: [3.1859572128355005e-06], Loss: 1.786442, Acc:0.737620, Source Loss: 1.250302, Target Loss: 1.160474, MixUp Loss: 0.964871
2025-01-26 16:05:56,487 Epoch: [12/20] Iter:[80/286], Time: 2.02, lr: [3.1730266044174715e-06], Loss: 1.782466, Acc:0.735519, Source Loss: 1.243161, Target Loss: 1.151252, MixUp Loss: 1.127789
2025-01-26 16:06:16,289 Epoch: [12/20] Iter:[90/286], Time: 2.02, lr: [3.1600901383982525e-06], Loss: 1.792511, Acc:0.738582, Source Loss: 1.254165, Target Loss: 1.153441, MixUp Loss: 0.872097
2025-01-26 16:06:37,465 Epoch: [12/20] Iter:[100/286], Time: 2.03, lr: [3.147147785456319e-06], Loss: 1.789332, Acc:0.737536, Source Loss: 1.251250, Target Loss: 1.156231, MixUp Loss: 1.238708
2025-01-26 16:06:57,627 Epoch: [12/20] Iter:[110/286], Time: 2.02, lr: [3.134199515988654e-06], Loss: 1.804707, Acc:0.739932, Source Loss: 1.261918, Target Loss: 1.156660, MixUp Loss: 1.070427
2025-01-26 16:07:18,286 Epoch: [12/20] Iter:[120/286], Time: 2.03, lr: [3.1212453001067434e-06], Loss: 1.799157, Acc:0.739261, Source Loss: 1.258507, Target Loss: 1.149827, MixUp Loss: 0.941684
2025-01-26 16:07:38,933 Epoch: [12/20] Iter:[130/286], Time: 2.03, lr: [3.108285107632494e-06], Loss: 1.795481, Acc:0.736988, Source Loss: 1.254568, Target Loss: 1.149478, MixUp Loss: 0.786663
2025-01-26 16:07:58,839 Epoch: [12/20] Iter:[140/286], Time: 2.03, lr: [3.0953189080940704e-06], Loss: 1.787278, Acc:0.731901, Source Loss: 1.244856, Target Loss: 1.162752, MixUp Loss: 1.117810
2025-01-26 16:08:19,451 Epoch: [12/20] Iter:[150/286], Time: 2.03, lr: [3.082346670721655e-06], Loss: 1.787486, Acc:0.730473, Source Loss: 1.246460, Target Loss: 1.164970, MixUp Loss: 0.998928
2025-01-26 16:08:39,471 Epoch: [12/20] Iter:[160/286], Time: 2.03, lr: [3.0693683644431297e-06], Loss: 1.793919, Acc:0.734873, Source Loss: 1.252891, Target Loss: 1.169577, MixUp Loss: 1.400787
2025-01-26 16:08:59,702 Epoch: [12/20] Iter:[170/286], Time: 2.03, lr: [3.056383957879665e-06], Loss: 1.793478, Acc:0.736628, Source Loss: 1.253251, Target Loss: 1.171504, MixUp Loss: 0.960233
2025-01-26 16:09:20,188 Epoch: [12/20] Iter:[180/286], Time: 2.03, lr: [3.0433934193412373e-06], Loss: 1.799861, Acc:0.740538, Source Loss: 1.260535, Target Loss: 1.165759, MixUp Loss: 0.837404
2025-01-26 16:09:39,853 Epoch: [12/20] Iter:[190/286], Time: 2.03, lr: [3.030396716822041e-06], Loss: 1.802786, Acc:0.741662, Source Loss: 1.265622, Target Loss: 1.158261, MixUp Loss: 0.907646
2025-01-26 16:10:00,208 Epoch: [12/20] Iter:[200/286], Time: 2.03, lr: [3.0173938179958325e-06], Loss: 1.790712, Acc:0.738572, Source Loss: 1.256044, Target Loss: 1.153597, MixUp Loss: 0.934070
2025-01-26 16:10:19,775 Epoch: [12/20] Iter:[210/286], Time: 2.02, lr: [3.0043846902111646e-06], Loss: 1.788768, Acc:0.739124, Source Loss: 1.256425, Target Loss: 1.147097, MixUp Loss: 0.981683
2025-01-26 16:10:40,087 Epoch: [12/20] Iter:[220/286], Time: 2.02, lr: [2.991369300486537e-06], Loss: 1.783748, Acc:0.739245, Source Loss: 1.250676, Target Loss: 1.147433, MixUp Loss: 1.105580
2025-01-26 16:11:00,767 Epoch: [12/20] Iter:[230/286], Time: 2.03, lr: [2.9783476155054415e-06], Loss: 1.785904, Acc:0.739509, Source Loss: 1.253093, Target Loss: 1.148487, MixUp Loss: 0.944003
2025-01-26 16:11:20,655 Epoch: [12/20] Iter:[240/286], Time: 2.02, lr: [2.965319601611325e-06], Loss: 1.773049, Acc:0.738006, Source Loss: 1.242870, Target Loss: 1.149535, MixUp Loss: 0.469602
2025-01-26 16:11:41,353 Epoch: [12/20] Iter:[250/286], Time: 2.03, lr: [2.952285224802431e-06], Loss: 1.779332, Acc:0.741163, Source Loss: 1.248762, Target Loss: 1.148318, MixUp Loss: 0.668493
2025-01-26 16:12:01,456 Epoch: [12/20] Iter:[260/286], Time: 2.03, lr: [2.939244450726553e-06], Loss: 1.789915, Acc:0.742855, Source Loss: 1.255869, Target Loss: 1.154693, MixUp Loss: 1.416123
2025-01-26 16:12:22,222 Epoch: [12/20] Iter:[270/286], Time: 2.03, lr: [2.9261972446756746e-06], Loss: 1.787018, Acc:0.742166, Source Loss: 1.253067, Target Loss: 1.155148, MixUp Loss: 1.110480
2025-01-26 16:12:42,584 Epoch: [12/20] Iter:[280/286], Time: 2.03, lr: [2.9131435715805004e-06], Loss: 1.787940, Acc:0.742136, Source Loss: 1.254066, Target Loss: 1.151412, MixUp Loss: 0.936532
2025-01-26 16:18:24,479 0 [0.         0.48335287 0.29110638 0.11284011 0.35589517 0.13868213
 0.11236829 0.07054237] 0.19559841596105032
2025-01-26 16:18:24,480 1 [0.         0.54886969 0.2953153  0.29943265 0.4483967  0.0941044
 0.13294179 0.36614101] 0.2731501923711611
2025-01-26 16:18:24,481 Epoch 13/20 - Source Loss: 1.2567, Target Loss: 1.1514
2025-01-26 16:18:24,481 => saving checkpoint to output/loveDa/pidnet_small_loveda_train_DACScheckpoint.pth.tar
2025-01-26 16:18:24,803 Epoch [12], Loss: 1.790, MeanIoU: 0.2732, best_mIoU: 0.2918
2025-01-26 16:18:24,803 IoU per class: [0.         0.54886969 0.2953153  0.29943265 0.4483967  0.0941044
 0.13294179 0.36614101]
2025-01-26 16:18:24,957 Attention!!!
2025-01-26 16:18:24,957 Loaded 302 parameters!
2025-01-26 16:18:24,957 Over!!!
2025-01-26 16:18:27,010 Epoch: [13/20] Iter:[0/286], Time: 1.85, lr: [9.606675692344068e-07], Loss: 1.102631, Acc:0.653552, Source Loss: 0.725816, Target Loss: 0.919807, MixUp Loss: 0.753628
2025-01-26 16:18:48,041 Epoch: [13/20] Iter:[10/286], Time: 2.08, lr: [9.563478032848357e-07], Loss: 1.693632, Acc:0.728604, Source Loss: 1.190083, Target Loss: 1.208862, MixUp Loss: 0.889549
2025-01-26 16:19:08,369 Epoch: [13/20] Iter:[20/286], Time: 2.06, lr: [9.52025868224085e-07], Loss: 1.760497, Acc:0.744727, Source Loss: 1.243720, Target Loss: 1.302511, MixUp Loss: 1.128910
2025-01-26 16:19:28,849 Epoch: [13/20] Iter:[30/286], Time: 2.05, lr: [9.477017520105569e-07], Loss: 1.796802, Acc:0.742216, Source Loss: 1.272327, Target Loss: 1.288808, MixUp Loss: 1.025792
2025-01-26 16:19:48,733 Epoch: [13/20] Iter:[40/286], Time: 2.04, lr: [9.433754424743889e-07], Loss: 1.780483, Acc:0.728459, Source Loss: 1.252980, Target Loss: 1.268561, MixUp Loss: 1.245788
2025-01-26 16:20:09,447 Epoch: [13/20] Iter:[50/286], Time: 2.04, lr: [9.390469273154241e-07], Loss: 1.756005, Acc:0.731776, Source Loss: 1.231161, Target Loss: 1.272980, MixUp Loss: 1.238219
2025-01-26 16:20:29,923 Epoch: [13/20] Iter:[60/286], Time: 2.05, lr: [9.347161941011434e-07], Loss: 1.759153, Acc:0.733352, Source Loss: 1.229883, Target Loss: 1.276087, MixUp Loss: 0.860622
2025-01-26 16:20:49,891 Epoch: [13/20] Iter:[70/286], Time: 2.04, lr: [9.3038323026455e-07], Loss: 1.749938, Acc:0.724058, Source Loss: 1.222034, Target Loss: 1.283425, MixUp Loss: 1.043466
2025-01-26 16:21:10,267 Epoch: [13/20] Iter:[80/286], Time: 2.04, lr: [9.26048023102013e-07], Loss: 1.734311, Acc:0.724626, Source Loss: 1.208844, Target Loss: 1.271185, MixUp Loss: 0.714106
2025-01-26 16:21:30,038 Epoch: [13/20] Iter:[90/286], Time: 2.03, lr: [9.217105597710619e-07], Loss: 1.742813, Acc:0.731788, Source Loss: 1.218390, Target Loss: 1.261035, MixUp Loss: 1.055987
2025-01-26 16:21:50,584 Epoch: [13/20] Iter:[100/286], Time: 2.03, lr: [9.173708272881356e-07], Loss: 1.757131, Acc:0.731983, Source Loss: 1.229768, Target Loss: 1.266040, MixUp Loss: 1.072519
2025-01-26 16:22:11,073 Epoch: [13/20] Iter:[110/286], Time: 2.04, lr: [9.130288125262813e-07], Loss: 1.762078, Acc:0.733952, Source Loss: 1.232065, Target Loss: 1.269044, MixUp Loss: 0.772670
2025-01-26 16:22:30,885 Epoch: [13/20] Iter:[120/286], Time: 2.03, lr: [9.086845022128044e-07], Loss: 1.744480, Acc:0.731854, Source Loss: 1.219381, Target Loss: 1.258676, MixUp Loss: 0.881759
2025-01-26 16:22:51,352 Epoch: [13/20] Iter:[130/286], Time: 2.03, lr: [9.043378829268685e-07], Loss: 1.756148, Acc:0.729655, Source Loss: 1.224625, Target Loss: 1.266629, MixUp Loss: 1.176460
2025-01-26 16:23:11,095 Epoch: [13/20] Iter:[140/286], Time: 2.03, lr: [8.999889410970402e-07], Loss: 1.765420, Acc:0.728173, Source Loss: 1.231035, Target Loss: 1.277481, MixUp Loss: 1.259802
2025-01-26 16:23:31,651 Epoch: [13/20] Iter:[150/286], Time: 2.03, lr: [8.956376629987817e-07], Loss: 1.781513, Acc:0.727843, Source Loss: 1.245753, Target Loss: 1.279012, MixUp Loss: 0.900365
2025-01-26 16:23:51,410 Epoch: [13/20] Iter:[160/286], Time: 2.03, lr: [8.912840347518876e-07], Loss: 1.772579, Acc:0.725302, Source Loss: 1.239228, Target Loss: 1.278855, MixUp Loss: 0.511972
2025-01-26 16:24:11,603 Epoch: [13/20] Iter:[170/286], Time: 2.03, lr: [8.869280423178622e-07], Loss: 1.771666, Acc:0.725750, Source Loss: 1.240153, Target Loss: 1.269797, MixUp Loss: 1.099214
2025-01-26 16:24:32,018 Epoch: [13/20] Iter:[180/286], Time: 2.03, lr: [8.825696714972439e-07], Loss: 1.762048, Acc:0.725913, Source Loss: 1.230518, Target Loss: 1.275664, MixUp Loss: 0.949334
2025-01-26 16:24:52,001 Epoch: [13/20] Iter:[190/286], Time: 2.03, lr: [8.782089079268624e-07], Loss: 1.769215, Acc:0.726315, Source Loss: 1.239062, Target Loss: 1.272695, MixUp Loss: 0.911103
2025-01-26 16:25:12,855 Epoch: [13/20] Iter:[200/286], Time: 2.03, lr: [8.738457370770394e-07], Loss: 1.771476, Acc:0.728736, Source Loss: 1.240222, Target Loss: 1.278265, MixUp Loss: 1.395074
2025-01-26 16:25:32,898 Epoch: [13/20] Iter:[210/286], Time: 2.03, lr: [8.694801442487212e-07], Loss: 1.764405, Acc:0.726804, Source Loss: 1.232424, Target Loss: 1.283509, MixUp Loss: 0.965364
2025-01-26 16:25:53,367 Epoch: [13/20] Iter:[220/286], Time: 2.03, lr: [8.651121145705494e-07], Loss: 1.761938, Acc:0.725802, Source Loss: 1.230446, Target Loss: 1.286452, MixUp Loss: 0.969368
2025-01-26 16:26:14,057 Epoch: [13/20] Iter:[230/286], Time: 2.03, lr: [8.60741632995862e-07], Loss: 1.760197, Acc:0.724788, Source Loss: 1.228214, Target Loss: 1.290206, MixUp Loss: 1.064909
2025-01-26 16:26:34,409 Epoch: [13/20] Iter:[240/286], Time: 2.03, lr: [8.563686842996258e-07], Loss: 1.773355, Acc:0.726584, Source Loss: 1.239856, Target Loss: 1.291725, MixUp Loss: 1.138613
2025-01-26 16:26:55,152 Epoch: [13/20] Iter:[250/286], Time: 2.03, lr: [8.519932530752974e-07], Loss: 1.773781, Acc:0.728166, Source Loss: 1.240648, Target Loss: 1.288101, MixUp Loss: 0.925304
2025-01-26 16:27:15,752 Epoch: [13/20] Iter:[260/286], Time: 2.03, lr: [8.47615323731609e-07], Loss: 1.769367, Acc:0.726418, Source Loss: 1.237355, Target Loss: 1.283639, MixUp Loss: 0.934109
2025-01-26 16:27:36,326 Epoch: [13/20] Iter:[270/286], Time: 2.03, lr: [8.432348804892825e-07], Loss: 1.765640, Acc:0.725933, Source Loss: 1.232847, Target Loss: 1.285629, MixUp Loss: 0.876415
2025-01-26 16:27:57,430 Epoch: [13/20] Iter:[280/286], Time: 2.04, lr: [8.388519073776621e-07], Loss: 1.770019, Acc:0.729250, Source Loss: 1.235711, Target Loss: 1.284305, MixUp Loss: 1.592588
2025-01-26 16:33:44,962 0 [0.         0.47802239 0.28527097 0.11934593 0.33569885 0.13367026
 0.12977354 0.06643719] 0.1935273921093106
2025-01-26 16:33:44,963 1 [0.         0.54083461 0.25532343 0.27317711 0.46442086 0.10198862
 0.17631442 0.34813356] 0.27002407531043493
2025-01-26 16:33:44,964 Epoch 14/20 - Source Loss: 1.2366, Target Loss: 1.2850
2025-01-26 16:33:44,964 => saving checkpoint to output/loveDa/pidnet_small_loveda_train_DACScheckpoint.pth.tar
2025-01-26 16:33:45,281 Epoch [13], Loss: 1.772, MeanIoU: 0.2700, best_mIoU: 0.2918
2025-01-26 16:33:45,282 IoU per class: [0.         0.54083461 0.25532343 0.27317711 0.46442086 0.10198862
 0.17631442 0.34813356]
2025-01-26 16:33:45,430 Attention!!!
2025-01-26 16:33:45,430 Loaded 302 parameters!
2025-01-26 16:33:45,430 Over!!!
2025-01-26 16:33:47,625 Epoch: [14/20] Iter:[0/286], Time: 1.97, lr: [2.983884587326541e-07], Loss: 2.274704, Acc:0.762613, Source Loss: 1.749930, Target Loss: 1.183402, MixUp Loss: 1.049548
2025-01-26 16:34:08,634 Epoch: [14/20] Iter:[10/286], Time: 2.09, lr: [2.968230273265201e-07], Loss: 1.688041, Acc:0.776793, Source Loss: 1.176716, Target Loss: 1.225795, MixUp Loss: 1.175639
2025-01-26 16:34:29,264 Epoch: [14/20] Iter:[20/286], Time: 2.08, lr: [2.9525667804247524e-07], Loss: 1.802206, Acc:0.792749, Source Loss: 1.291994, Target Loss: 1.194788, MixUp Loss: 0.971596
2025-01-26 16:34:49,235 Epoch: [14/20] Iter:[30/286], Time: 2.05, lr: [2.9368940492547777e-07], Loss: 1.805144, Acc:0.761645, Source Loss: 1.272756, Target Loss: 1.239636, MixUp Loss: 1.681053
2025-01-26 16:35:10,263 Epoch: [14/20] Iter:[40/286], Time: 2.06, lr: [2.921212019462894e-07], Loss: 1.785842, Acc:0.768958, Source Loss: 1.258579, Target Loss: 1.226783, MixUp Loss: 0.968786
2025-01-26 16:35:30,427 Epoch: [14/20] Iter:[50/286], Time: 2.05, lr: [2.9055206300010285e-07], Loss: 1.745666, Acc:0.757637, Source Loss: 1.213620, Target Loss: 1.247675, MixUp Loss: 1.170456
2025-01-26 16:35:50,572 Epoch: [14/20] Iter:[60/286], Time: 2.05, lr: [2.889819819051346e-07], Loss: 1.765788, Acc:0.754225, Source Loss: 1.237030, Target Loss: 1.230850, MixUp Loss: 0.652751
2025-01-26 16:36:11,363 Epoch: [14/20] Iter:[70/286], Time: 2.05, lr: [2.874109524011844e-07], Loss: 1.789992, Acc:0.758017, Source Loss: 1.256666, Target Loss: 1.240476, MixUp Loss: 0.998309
2025-01-26 16:36:31,223 Epoch: [14/20] Iter:[80/286], Time: 2.04, lr: [2.8583896814815695e-07], Loss: 1.793220, Acc:0.758011, Source Loss: 1.260868, Target Loss: 1.229689, MixUp Loss: 1.142908
2025-01-26 16:36:52,025 Epoch: [14/20] Iter:[90/286], Time: 2.05, lr: [2.8426602272454845e-07], Loss: 1.812687, Acc:0.760379, Source Loss: 1.278940, Target Loss: 1.218966, MixUp Loss: 0.993442
2025-01-26 16:37:12,762 Epoch: [14/20] Iter:[100/286], Time: 2.05, lr: [2.8269210962589284e-07], Loss: 1.834650, Acc:0.764654, Source Loss: 1.300669, Target Loss: 1.211547, MixUp Loss: 1.036528
2025-01-26 16:37:33,270 Epoch: [14/20] Iter:[110/286], Time: 2.05, lr: [2.81117222263171e-07], Loss: 1.820897, Acc:0.762287, Source Loss: 1.288070, Target Loss: 1.211075, MixUp Loss: 1.030949
2025-01-26 16:37:54,352 Epoch: [14/20] Iter:[120/286], Time: 2.06, lr: [2.795413539611774e-07], Loss: 1.814075, Acc:0.763641, Source Loss: 1.283315, Target Loss: 1.218993, MixUp Loss: 0.999749
2025-01-26 16:38:14,621 Epoch: [14/20] Iter:[130/286], Time: 2.05, lr: [2.779644979568456e-07], Loss: 1.802292, Acc:0.763200, Source Loss: 1.273012, Target Loss: 1.223823, MixUp Loss: 0.946446
2025-01-26 16:38:35,285 Epoch: [14/20] Iter:[140/286], Time: 2.05, lr: [2.7638664739753047e-07], Loss: 1.805297, Acc:0.763740, Source Loss: 1.273653, Target Loss: 1.225453, MixUp Loss: 1.165484
2025-01-26 16:38:55,943 Epoch: [14/20] Iter:[150/286], Time: 2.05, lr: [2.7480779533924533e-07], Loss: 1.794834, Acc:0.763722, Source Loss: 1.262910, Target Loss: 1.226425, MixUp Loss: 1.131372
2025-01-26 16:39:15,851 Epoch: [14/20] Iter:[160/286], Time: 2.05, lr: [2.7322793474485345e-07], Loss: 1.802588, Acc:0.764365, Source Loss: 1.270585, Target Loss: 1.218759, MixUp Loss: 1.293813
2025-01-26 16:39:36,239 Epoch: [14/20] Iter:[170/286], Time: 2.05, lr: [2.716470584822114e-07], Loss: 1.798361, Acc:0.762453, Source Loss: 1.263916, Target Loss: 1.222023, MixUp Loss: 1.305385
2025-01-26 16:39:55,942 Epoch: [14/20] Iter:[180/286], Time: 2.05, lr: [2.700651593222635e-07], Loss: 1.805365, Acc:0.763704, Source Loss: 1.268617, Target Loss: 1.226443, MixUp Loss: 0.792769
2025-01-26 16:40:16,594 Epoch: [14/20] Iter:[190/286], Time: 2.05, lr: [2.684822299370848e-07], Loss: 1.798896, Acc:0.760018, Source Loss: 1.262637, Target Loss: 1.222490, MixUp Loss: 0.911340
2025-01-26 16:40:37,749 Epoch: [14/20] Iter:[200/286], Time: 2.05, lr: [2.6689826289787243e-07], Loss: 1.811600, Acc:0.760782, Source Loss: 1.271815, Target Loss: 1.223945, MixUp Loss: 1.242360
2025-01-26 16:40:58,181 Epoch: [14/20] Iter:[210/286], Time: 2.05, lr: [2.653132506728817e-07], Loss: 1.803000, Acc:0.758677, Source Loss: 1.266273, Target Loss: 1.220001, MixUp Loss: 0.927838
2025-01-26 16:41:18,745 Epoch: [14/20] Iter:[220/286], Time: 2.05, lr: [2.6372718562530667e-07], Loss: 1.807674, Acc:0.760009, Source Loss: 1.272399, Target Loss: 1.216227, MixUp Loss: 0.938424
2025-01-26 16:41:38,525 Epoch: [14/20] Iter:[230/286], Time: 2.05, lr: [2.6214006001110174e-07], Loss: 1.805021, Acc:0.757309, Source Loss: 1.268969, Target Loss: 1.219547, MixUp Loss: 0.988933
2025-01-26 16:41:59,172 Epoch: [14/20] Iter:[240/286], Time: 2.05, lr: [2.605518659767441e-07], Loss: 1.802060, Acc:0.757428, Source Loss: 1.266365, Target Loss: 1.220986, MixUp Loss: 0.966721
2025-01-26 16:42:19,604 Epoch: [14/20] Iter:[250/286], Time: 2.05, lr: [2.589625955569336e-07], Loss: 1.796377, Acc:0.757204, Source Loss: 1.263334, Target Loss: 1.219397, MixUp Loss: 0.799399
2025-01-26 16:42:39,506 Epoch: [14/20] Iter:[260/286], Time: 2.05, lr: [2.5737224067222796e-07], Loss: 1.789913, Acc:0.755404, Source Loss: 1.256672, Target Loss: 1.224474, MixUp Loss: 0.882431
2025-01-26 16:43:00,504 Epoch: [14/20] Iter:[270/286], Time: 2.05, lr: [2.5578079312661173e-07], Loss: 1.795271, Acc:0.756839, Source Loss: 1.260573, Target Loss: 1.223372, MixUp Loss: 1.560160
2025-01-26 16:43:20,992 Epoch: [14/20] Iter:[280/286], Time: 2.05, lr: [2.541882446049965e-07], Loss: 1.793927, Acc:0.756339, Source Loss: 1.258846, Target Loss: 1.223910, MixUp Loss: 1.081602
