2025-01-20 12:08:12,866 Namespace(cfg='configs/loveDa/pidnet_small_loveda_3b_AUG_CHANCE+AUG3.yaml', seed=304, opts=['GPUS', '[0]', 'TRAIN.BATCH_SIZE_PER_GPU', '6'])
2025-01-20 12:08:12,867 AUTO_RESUME: False
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  DATASET: loveDa
  EXTRA_TRAIN_SET: 
  NUM_CLASSES: 8
  ROOT: data/
  SOURCE_DATASET: loveDA-Urban
  SOURCE_TEST_SET: list/loveDA-Urban/val.lst
  SOURCE_TRAIN_SET: list/loveDA-Urban/train.lst
  TARGET_DATASET: loveDA-Rural
  TARGET_SET: list/cityscapes/val.lst
  TARGET_TEST_SET: list/loveDA-Rural/val.lst
  TARGET_TRAIN_SET: list/loveDA-Rural/train.lst
  TEST_SET: list/loveDa-Rural/val.lst
  TRAIN_SET: list/loveDA-Urban/train.lst
GPUS: (0,)
LOG_DIR: log
LOSS:
  BALANCE_WEIGHTS: [0.4, 1.0]
  CLASS_BALANCE: False
  OHEMKEEP: 131072
  OHEMTHRES: 0.7
  SB_WEIGHTS: 0.5
  USE_DICE: False
  USE_FOCAL: False
  USE_OHEM: True
MODEL:
  ALIGN_CORNERS: True
  NAME: pidnet_small
  NUM_OUTPUTS: 2
  PRETRAINED: pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar
OUTPUT_DIR: output
PIN_MEMORY: True
PRINT_FREQ: 10
TEST:
  BASE_SIZE: 2048
  BATCH_SIZE_PER_GPU: 20
  FLIP_TEST: False
  IMAGE_SIZE: [1024, 1024]
  MODEL_FILE: 
  MULTI_SCALE: False
  OUTPUT_INDEX: 1
TRAIN:
  ADVERSARIAL: False
  AUG: True
  AUG1: False
  AUG2: False
  AUG3: True
  AUG4: False
  AUG_CHANCE: True
  BASE_SIZE: 720
  BATCH_SIZE_PER_GPU: 6
  BEGIN_EPOCH: 1
  END_EPOCH: 20
  EVAL_INTERVAL: 1
  EXTRA_EPOCH: 0
  EXTRA_LR: 0.001
  FLIP: True
  GAN: Vanilla
  IGNORE_LABEL: 0
  IMAGE_SIZE: [720, 720]
  LAMBDA_ADV1: 0.001
  LAMBDA_ADV2: 0.001
  LR: 0.001
  LR_D1: 0.001
  LR_D2: 0.001
  MOMENTUM: 0.9
  MULTI_SCALE: True
  NESTEROV: False
  OPTIMIZER: adam
  RESUME: False
  SCALE_FACTOR: 16
  SCHEDULER: True
  SHUFFLE: True
  WD: 0.0005
WORKERS: 0
2025-01-20 12:08:13,026 Attention!!!
2025-01-20 12:08:13,026 Loaded 302 parameters!
2025-01-20 12:08:13,027 Over!!!
2025-01-20 12:08:16,694 Epoch: [0/20] Iter:[0/289], Time: 3.44, lr: [0.0002], Loss: 5.980091, Acc:0.148680, Semantic loss: 0.634092, BCE loss: 5.104026, SB loss: 0.241973
2025-01-20 12:08:49,078 Namespace(cfg='configs/loveDa/pidnet_small_loveda_3b_AUG_CHANCE+AUG3.yaml', seed=304, opts=['GPUS', '[0]', 'TRAIN.BATCH_SIZE_PER_GPU', '6'])
2025-01-20 12:08:49,079 AUTO_RESUME: False
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  DATASET: loveDa
  EXTRA_TRAIN_SET: 
  NUM_CLASSES: 8
  ROOT: data/
  SOURCE_DATASET: loveDA-Urban
  SOURCE_TEST_SET: list/loveDA-Urban/val.lst
  SOURCE_TRAIN_SET: list/loveDA-Urban/train.lst
  TARGET_DATASET: loveDA-Rural
  TARGET_SET: list/cityscapes/val.lst
  TARGET_TEST_SET: list/loveDA-Rural/val.lst
  TARGET_TRAIN_SET: list/loveDA-Rural/train.lst
  TEST_SET: list/loveDa-Rural/val.lst
  TRAIN_SET: list/loveDA-Urban/train.lst
GPUS: (0,)
LOG_DIR: log
LOSS:
  BALANCE_WEIGHTS: [0.4, 1.0]
  CLASS_BALANCE: False
  OHEMKEEP: 131072
  OHEMTHRES: 0.7
  SB_WEIGHTS: 0.5
  USE_DICE: False
  USE_FOCAL: False
  USE_OHEM: True
MODEL:
  ALIGN_CORNERS: True
  NAME: pidnet_small
  NUM_OUTPUTS: 2
  PRETRAINED: pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar
OUTPUT_DIR: output
PIN_MEMORY: True
PRINT_FREQ: 10
TEST:
  BASE_SIZE: 2048
  BATCH_SIZE_PER_GPU: 20
  FLIP_TEST: False
  IMAGE_SIZE: [1024, 1024]
  MODEL_FILE: 
  MULTI_SCALE: False
  OUTPUT_INDEX: 1
TRAIN:
  ADVERSARIAL: False
  AUG: True
  AUG1: False
  AUG2: False
  AUG3: True
  AUG4: False
  AUG_CHANCE: True
  BASE_SIZE: 720
  BATCH_SIZE_PER_GPU: 6
  BEGIN_EPOCH: 1
  END_EPOCH: 20
  EVAL_INTERVAL: 1
  EXTRA_EPOCH: 0
  EXTRA_LR: 0.001
  FLIP: True
  GAN: Vanilla
  IGNORE_LABEL: 0
  IMAGE_SIZE: [720, 720]
  LAMBDA_ADV1: 0.001
  LAMBDA_ADV2: 0.001
  LR: 0.001
  LR_D1: 0.001
  LR_D2: 0.001
  MOMENTUM: 0.9
  MULTI_SCALE: True
  NESTEROV: False
  OPTIMIZER: adam
  RESUME: False
  SCALE_FACTOR: 16
  SCHEDULER: True
  SHUFFLE: True
  WD: 0.0005
WORKERS: 0
2025-01-20 12:08:49,236 Attention!!!
2025-01-20 12:08:49,236 Loaded 302 parameters!
2025-01-20 12:08:49,236 Over!!!
2025-01-20 12:08:52,972 Epoch: [0/20] Iter:[0/283], Time: 3.53, lr: [0.0002], Loss: 4.571925, Acc:0.169162, Semantic loss: 0.610578, BCE loss: 3.725549, SB loss: 0.235798
2025-01-20 12:09:00,675 Epoch: [0/20] Iter:[10/283], Time: 1.01, lr: [0.00019968195068662426], Loss: 3.572978, Acc:0.234740, Semantic loss: 0.499326, BCE loss: 2.886013, SB loss: 0.187639
2025-01-20 12:09:08,514 Epoch: [0/20] Iter:[20/283], Time: 0.90, lr: [0.0001993638450763219], Loss: 2.988889, Acc:0.273954, Semantic loss: 0.418206, BCE loss: 2.413670, SB loss: 0.157013
2025-01-20 12:09:16,203 Epoch: [0/20] Iter:[30/283], Time: 0.86, lr: [0.0001990456830592841], Loss: 2.708509, Acc:0.288492, Semantic loss: 0.378149, BCE loss: 2.188865, SB loss: 0.141495
2025-01-20 12:09:24,035 Epoch: [0/20] Iter:[40/283], Time: 0.84, lr: [0.0001987274645252924], Loss: 2.499149, Acc:0.302492, Semantic loss: 0.349090, BCE loss: 2.021393, SB loss: 0.128666
2025-01-20 12:09:31,778 Epoch: [0/20] Iter:[50/283], Time: 0.83, lr: [0.0001984091893637165], Loss: 2.369823, Acc:0.315520, Semantic loss: 0.325331, BCE loss: 1.925982, SB loss: 0.118510
2025-01-20 12:09:39,658 Epoch: [0/20] Iter:[60/283], Time: 0.82, lr: [0.0001980908574635119], Loss: 2.329916, Acc:0.327077, Semantic loss: 0.309724, BCE loss: 1.909363, SB loss: 0.110829
2025-01-20 12:09:47,256 Epoch: [0/20] Iter:[70/283], Time: 0.81, lr: [0.00019777246871321763], Loss: 2.259397, Acc:0.336970, Semantic loss: 0.296943, BCE loss: 1.857010, SB loss: 0.105443
2025-01-20 12:09:54,803 Epoch: [0/20] Iter:[80/283], Time: 0.81, lr: [0.00019745402300095402], Loss: 2.180902, Acc:0.348605, Semantic loss: 0.285558, BCE loss: 1.795015, SB loss: 0.100330
2025-01-20 12:10:02,509 Epoch: [0/20] Iter:[90/283], Time: 0.80, lr: [0.0001971355202144202], Loss: 2.101679, Acc:0.357518, Semantic loss: 0.277092, BCE loss: 1.728551, SB loss: 0.096036
2025-01-20 12:10:10,073 Epoch: [0/20] Iter:[100/283], Time: 0.80, lr: [0.00019681696024089203], Loss: 2.064269, Acc:0.368130, Semantic loss: 0.266702, BCE loss: 1.705219, SB loss: 0.092348
2025-01-20 12:10:17,400 Epoch: [0/20] Iter:[110/283], Time: 0.79, lr: [0.00019649834296721935], Loss: 2.012602, Acc:0.376532, Semantic loss: 0.257949, BCE loss: 1.665163, SB loss: 0.089489
2025-01-20 12:10:24,936 Epoch: [0/20] Iter:[120/283], Time: 0.79, lr: [0.00019617966827982408], Loss: 1.963004, Acc:0.380513, Semantic loss: 0.252233, BCE loss: 1.623287, SB loss: 0.087484
2025-01-20 12:10:32,392 Epoch: [0/20] Iter:[130/283], Time: 0.79, lr: [0.00019586093606469736], Loss: 1.923463, Acc:0.386641, Semantic loss: 0.245785, BCE loss: 1.592340, SB loss: 0.085338
2025-01-20 12:10:39,404 Epoch: [0/20] Iter:[140/283], Time: 0.78, lr: [0.00019554214620739745], Loss: 1.887497, Acc:0.390251, Semantic loss: 0.242085, BCE loss: 1.561984, SB loss: 0.083429
2025-01-20 12:10:46,523 Epoch: [0/20] Iter:[150/283], Time: 0.77, lr: [0.0001952232985930472], Loss: 1.863162, Acc:0.394058, Semantic loss: 0.238657, BCE loss: 1.542686, SB loss: 0.081818
2025-01-20 12:10:53,588 Epoch: [0/20] Iter:[160/283], Time: 0.77, lr: [0.00019490439310633145], Loss: 1.835068, Acc:0.400019, Semantic loss: 0.233950, BCE loss: 1.520920, SB loss: 0.080198
2025-01-20 12:11:00,698 Epoch: [0/20] Iter:[170/283], Time: 0.77, lr: [0.00019458542963149495], Loss: 1.813940, Acc:0.406195, Semantic loss: 0.229327, BCE loss: 1.505912, SB loss: 0.078701
