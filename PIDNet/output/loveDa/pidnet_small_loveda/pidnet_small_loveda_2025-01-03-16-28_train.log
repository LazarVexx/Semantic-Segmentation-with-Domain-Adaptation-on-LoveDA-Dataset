2025-01-03 16:28:52,933 Namespace(cfg='configs/loveDa/pidnet_small_loveda.yaml', seed=304, opts=['GPUS', '[0]', 'TRAIN.BATCH_SIZE_PER_GPU', '6'])
2025-01-03 16:28:52,933 AUTO_RESUME: False
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  DATASET: loveDa
  EXTRA_TRAIN_SET: 
  NUM_CLASSES: 8
  ROOT: data/
  TEST_SET: list/loveDa/val.lst
  TRAIN_SET: list/loveDa/train.lst
GPUS: (0,)
LOG_DIR: log
LOSS:
  BALANCE_WEIGHTS: [0.4, 1.0]
  CLASS_BALANCE: False
  OHEMKEEP: 131072
  OHEMTHRES: 0.9
  SB_WEIGHTS: 1.0
  USE_OHEM: True
MODEL:
  ALIGN_CORNERS: True
  NAME: pidnet_small
  NUM_OUTPUTS: 2
  PRETRAINED: pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar
OUTPUT_DIR: output
PIN_MEMORY: True
PRINT_FREQ: 10
TEST:
  BASE_SIZE: 2048
  BATCH_SIZE_PER_GPU: 6
  FLIP_TEST: False
  IMAGE_SIZE: [1024, 1024]
  MODEL_FILE: 
  MULTI_SCALE: False
  OUTPUT_INDEX: 1
TRAIN:
  BASE_SIZE: 2048
  BATCH_SIZE_PER_GPU: 6
  BEGIN_EPOCH: 0
  END_EPOCH: 20
  EXTRA_EPOCH: 0
  EXTRA_LR: 0.001
  FLIP: True
  IGNORE_LABEL: 255
  IMAGE_SIZE: [1024, 1024]
  LR: 0.01
  MOMENTUM: 0.9
  MULTI_SCALE: True
  NESTEROV: False
  OPTIMIZER: sgd
  RESUME: False
  SCALE_FACTOR: 16
  SHUFFLE: True
  WD: 0.0005
WORKERS: 6
2025-01-03 16:28:53,127 Attention!!!
2025-01-03 16:28:53,128 Loaded 302 parameters!
2025-01-03 16:28:53,128 Over!!!
2025-01-03 16:29:14,300 Epoch: [0/20] Iter:[0/227], Time: 19.66, lr: [0.01], Loss: 1.907729, Acc:0.155125, Semantic loss: 0.000000, BCE loss: 1.907729, SB loss: 0.000000
2025-01-03 16:29:21,236 Epoch: [0/20] Iter:[10/227], Time: 2.39, lr: [0.009980174026451818], Loss: 1.868759, Acc:0.085394, Semantic loss: 0.000000, BCE loss: 1.868759, SB loss: 0.000000
2025-01-03 16:29:28,108 Epoch: [0/20] Iter:[20/227], Time: 1.58, lr: [0.009960343675822199], Loss: 1.505879, Acc:0.079321, Semantic loss: 0.000000, BCE loss: 1.505879, SB loss: 0.000000
2025-01-03 16:29:34,932 Epoch: [0/20] Iter:[30/227], Time: 1.29, lr: [0.009940508937457754], Loss: 1.382156, Acc:0.075235, Semantic loss: 0.000000, BCE loss: 1.382156, SB loss: 0.000000
2025-01-03 16:29:41,872 Epoch: [0/20] Iter:[40/227], Time: 1.14, lr: [0.009920669800655492], Loss: 1.334110, Acc:0.072281, Semantic loss: 0.000000, BCE loss: 1.334110, SB loss: 0.000000
2025-01-03 16:29:48,789 Epoch: [0/20] Iter:[50/227], Time: 1.06, lr: [0.009900826254662456], Loss: 1.296533, Acc:0.074171, Semantic loss: 0.000000, BCE loss: 1.296533, SB loss: 0.000000
2025-01-03 16:29:55,646 Epoch: [0/20] Iter:[60/227], Time: 0.99, lr: [0.009880978288675405], Loss: 1.277583, Acc:0.074107, Semantic loss: 0.000000, BCE loss: 1.277583, SB loss: 0.000000
2025-01-03 16:30:02,592 Epoch: [0/20] Iter:[70/227], Time: 0.95, lr: [0.009861125891840445], Loss: 1.262890, Acc:0.077309, Semantic loss: 0.000000, BCE loss: 1.262890, SB loss: 0.000000
2025-01-03 16:30:09,560 Epoch: [0/20] Iter:[80/227], Time: 0.92, lr: [0.009841269053252683], Loss: 1.269728, Acc:0.077509, Semantic loss: 0.000000, BCE loss: 1.269728, SB loss: 0.000000
2025-01-03 16:30:16,479 Epoch: [0/20] Iter:[90/227], Time: 0.90, lr: [0.00982140776195588], Loss: 1.246482, Acc:0.076255, Semantic loss: 0.000000, BCE loss: 1.246482, SB loss: 0.000000
2025-01-03 16:30:23,328 Epoch: [0/20] Iter:[100/227], Time: 0.87, lr: [0.009801542006942082], Loss: 1.237931, Acc:0.075798, Semantic loss: 0.000000, BCE loss: 1.237931, SB loss: 0.000000
2025-01-03 16:30:30,216 Epoch: [0/20] Iter:[110/227], Time: 0.86, lr: [0.009781671777151266], Loss: 1.230002, Acc:0.074630, Semantic loss: 0.000000, BCE loss: 1.230002, SB loss: 0.000000
2025-01-03 16:30:37,068 Epoch: [0/20] Iter:[120/227], Time: 0.84, lr: [0.009761797061470977], Loss: 1.227201, Acc:0.075112, Semantic loss: 0.000000, BCE loss: 1.227201, SB loss: 0.000000
2025-01-03 16:30:43,937 Epoch: [0/20] Iter:[130/227], Time: 0.83, lr: [0.009741917848735952], Loss: 1.218352, Acc:0.074671, Semantic loss: 0.000000, BCE loss: 1.218352, SB loss: 0.000000
2025-01-03 16:30:50,758 Epoch: [0/20] Iter:[140/227], Time: 0.82, lr: [0.009722034127727758], Loss: 1.211105, Acc:0.073993, Semantic loss: 0.000000, BCE loss: 1.211104, SB loss: 0.000000
2025-01-03 16:30:57,566 Epoch: [0/20] Iter:[150/227], Time: 0.81, lr: [0.009702145887174411], Loss: 1.200468, Acc:0.074379, Semantic loss: 0.000000, BCE loss: 1.200468, SB loss: 0.000000
2025-01-03 16:31:04,526 Epoch: [0/20] Iter:[160/227], Time: 0.80, lr: [0.009682253115750003], Loss: 1.197911, Acc:0.074520, Semantic loss: 0.000000, BCE loss: 1.197911, SB loss: 0.000000
2025-01-03 16:31:11,446 Epoch: [0/20] Iter:[170/227], Time: 0.80, lr: [0.009662355802074312], Loss: 1.197019, Acc:0.074166, Semantic loss: 0.000000, BCE loss: 1.197019, SB loss: 0.000000
2025-01-03 16:31:18,310 Epoch: [0/20] Iter:[180/227], Time: 0.79, lr: [0.00964245393471243], Loss: 1.194467, Acc:0.074430, Semantic loss: 0.000000, BCE loss: 1.194467, SB loss: 0.000000
2025-01-03 16:31:25,174 Epoch: [0/20] Iter:[190/227], Time: 0.79, lr: [0.009622547502174356], Loss: 1.188204, Acc:0.074041, Semantic loss: 0.000000, BCE loss: 1.188204, SB loss: 0.000000
2025-01-03 16:31:32,022 Epoch: [0/20] Iter:[200/227], Time: 0.78, lr: [0.009602636492914622], Loss: 1.184008, Acc:0.074295, Semantic loss: 0.000000, BCE loss: 1.184008, SB loss: 0.000000
2025-01-03 16:31:38,914 Epoch: [0/20] Iter:[210/227], Time: 0.78, lr: [0.009582720895331883], Loss: 1.176798, Acc:0.074750, Semantic loss: 0.000000, BCE loss: 1.176798, SB loss: 0.000000
2025-01-03 16:31:45,613 Epoch: [0/20] Iter:[220/227], Time: 0.77, lr: [0.009562800697768528], Loss: 1.174945, Acc:0.074561, Semantic loss: 0.000000, BCE loss: 1.174945, SB loss: 0.000000
2025-01-03 16:34:30,266 0 [0.01077162 0.40929273 0.         0.00102689 0.         0.01241016
 0.01250972 0.01005378] 0.05700811282618835
2025-01-03 16:34:30,267 1 [0.01791491 0.01558175 0.0338864  0.01958659 0.09983893 0.02161461
 0.00524814 0.00242617] 0.02701218765821347
2025-01-03 16:34:30,272 => saving checkpoint to output\loveDa\pidnet_small_lovedacheckpoint.pth.tar
2025-01-03 16:34:30,539 Loss: 1.052, MeanIU:  0.0270, Best_mIoU:  0.0270
2025-01-03 16:34:30,540 [0.01791491 0.01558175 0.0338864  0.01958659 0.09983893 0.02161461
 0.00524814 0.00242617]
2025-01-03 16:34:46,729 Epoch: [1/20] Iter:[0/227], Time: 15.75, lr: [0.009548853816214998], Loss: 1.405017, Acc:0.081811, Semantic loss: 0.000000, BCE loss: 1.405017, SB loss: 0.000000
2025-01-03 16:34:53,461 Epoch: [1/20] Iter:[10/227], Time: 2.06, lr: [0.009528925771769746], Loss: 1.179689, Acc:0.070414, Semantic loss: 0.000000, BCE loss: 1.179689, SB loss: 0.000000
2025-01-03 16:35:00,037 Epoch: [1/20] Iter:[20/227], Time: 1.39, lr: [0.009508993095584064], Loss: 1.173816, Acc:0.074851, Semantic loss: 0.000000, BCE loss: 1.173816, SB loss: 0.000000
2025-01-03 16:35:06,862 Epoch: [1/20] Iter:[30/227], Time: 1.16, lr: [0.009489055775788591], Loss: 1.194112, Acc:0.079765, Semantic loss: 0.000000, BCE loss: 1.194112, SB loss: 0.000000
2025-01-03 16:35:13,581 Epoch: [1/20] Iter:[40/227], Time: 1.04, lr: [0.009469113800455762], Loss: 1.200346, Acc:0.080468, Semantic loss: 0.000000, BCE loss: 1.200346, SB loss: 0.000000
2025-01-03 16:35:20,357 Epoch: [1/20] Iter:[50/227], Time: 0.97, lr: [0.009449167157599386], Loss: 1.192900, Acc:0.079177, Semantic loss: 0.000000, BCE loss: 1.192900, SB loss: 0.000000
2025-01-03 16:35:27,156 Epoch: [1/20] Iter:[60/227], Time: 0.92, lr: [0.00942921583517422], Loss: 1.183724, Acc:0.079687, Semantic loss: 0.000000, BCE loss: 1.183724, SB loss: 0.000000
2025-01-03 16:35:33,953 Epoch: [1/20] Iter:[70/227], Time: 0.89, lr: [0.009409259821075532], Loss: 1.187087, Acc:0.081127, Semantic loss: 0.000000, BCE loss: 1.187087, SB loss: 0.000000
2025-01-03 16:35:40,851 Epoch: [1/20] Iter:[80/227], Time: 0.86, lr: [0.009389299103138684], Loss: 1.165593, Acc:0.078547, Semantic loss: 0.000000, BCE loss: 1.165593, SB loss: 0.000000
2025-01-03 16:35:47,744 Epoch: [1/20] Iter:[90/227], Time: 0.85, lr: [0.00936933366913867], Loss: 1.156267, Acc:0.077751, Semantic loss: 0.000000, BCE loss: 1.156267, SB loss: 0.000000
2025-01-03 16:35:54,472 Epoch: [1/20] Iter:[100/227], Time: 0.83, lr: [0.009349363506789691], Loss: 1.160381, Acc:0.077669, Semantic loss: 0.000000, BCE loss: 1.160381, SB loss: 0.000000
2025-01-03 16:36:01,305 Epoch: [1/20] Iter:[110/227], Time: 0.82, lr: [0.009329388603744703], Loss: 1.153185, Acc:0.077818, Semantic loss: 0.000000, BCE loss: 1.153185, SB loss: 0.000000
2025-01-03 16:36:08,078 Epoch: [1/20] Iter:[120/227], Time: 0.80, lr: [0.009309408947594957], Loss: 1.154500, Acc:0.077323, Semantic loss: 0.000000, BCE loss: 1.154500, SB loss: 0.000000
2025-01-03 16:36:15,009 Epoch: [1/20] Iter:[130/227], Time: 0.80, lr: [0.009289424525869554], Loss: 1.163209, Acc:0.077247, Semantic loss: 0.000000, BCE loss: 1.163209, SB loss: 0.000000
2025-01-03 16:36:21,851 Epoch: [1/20] Iter:[140/227], Time: 0.79, lr: [0.009269435326034976], Loss: 1.166775, Acc:0.077437, Semantic loss: 0.000000, BCE loss: 1.166775, SB loss: 0.000000
2025-01-03 16:36:28,572 Epoch: [1/20] Iter:[150/227], Time: 0.78, lr: [0.00924944133549463], Loss: 1.162838, Acc:0.077749, Semantic loss: 0.000000, BCE loss: 1.162838, SB loss: 0.000000
2025-01-03 16:36:35,400 Epoch: [1/20] Iter:[160/227], Time: 0.77, lr: [0.009229442541588362], Loss: 1.159573, Acc:0.078024, Semantic loss: 0.000000, BCE loss: 1.159573, SB loss: 0.000000
2025-01-03 16:36:42,170 Epoch: [1/20] Iter:[170/227], Time: 0.77, lr: [0.009209438931592004], Loss: 1.167620, Acc:0.077965, Semantic loss: 0.000000, BCE loss: 1.167620, SB loss: 0.000000
2025-01-03 16:36:48,854 Epoch: [1/20] Iter:[180/227], Time: 0.76, lr: [0.009189430492716878], Loss: 1.155703, Acc:0.077425, Semantic loss: 0.000000, BCE loss: 1.155703, SB loss: 0.000000
2025-01-03 16:36:55,696 Epoch: [1/20] Iter:[190/227], Time: 0.76, lr: [0.009169417212109319], Loss: 1.158077, Acc:0.077633, Semantic loss: 0.000000, BCE loss: 1.158077, SB loss: 0.000000
2025-01-03 16:37:02,427 Epoch: [1/20] Iter:[200/227], Time: 0.75, lr: [0.009149399076850187], Loss: 1.165394, Acc:0.076919, Semantic loss: 0.000000, BCE loss: 1.165394, SB loss: 0.000000
2025-01-03 16:37:09,273 Epoch: [1/20] Iter:[210/227], Time: 0.75, lr: [0.009129376073954367], Loss: 1.163126, Acc:0.076676, Semantic loss: 0.000000, BCE loss: 1.163126, SB loss: 0.000000
2025-01-03 16:37:15,882 Epoch: [1/20] Iter:[220/227], Time: 0.75, lr: [0.009109348190370282], Loss: 1.164218, Acc:0.076286, Semantic loss: 0.000000, BCE loss: 1.164217, SB loss: 0.000000
2025-01-03 16:40:01,196 0 [1.07877760e-02 4.10014709e-01 0.00000000e+00 4.13192925e-03
 1.05905252e-06 1.24094683e-02 1.14725151e-02 4.63592026e-03] 0.05668167215673818
2025-01-03 16:40:01,196 1 [0.01975773 0.0123196  0.00298653 0.02582561 0.07475381 0.02622577
 0.00782701 0.00325012] 0.02161827217802259
2025-01-03 16:40:01,202 => saving checkpoint to output\loveDa\pidnet_small_lovedacheckpoint.pth.tar
2025-01-03 16:40:01,318 Loss: 1.052, MeanIU:  0.0216, Best_mIoU:  0.0270
2025-01-03 16:40:01,318 [0.01975773 0.0123196  0.00298653 0.02582561 0.07475381 0.02622577
 0.00782701 0.00325012]
2025-01-03 16:40:17,372 Epoch: [2/20] Iter:[0/227], Time: 15.79, lr: [0.009095325760829623], Loss: 1.862667, Acc:0.131570, Semantic loss: 0.000000, BCE loss: 1.862666, SB loss: 0.000000
2025-01-03 16:40:23,960 Epoch: [2/20] Iter:[10/227], Time: 2.03, lr: [0.00907528954993229], Loss: 1.181852, Acc:0.070245, Semantic loss: 0.000000, BCE loss: 1.181852, SB loss: 0.000000
2025-01-03 16:40:30,761 Epoch: [2/20] Iter:[20/227], Time: 1.39, lr: [0.009055248422771453], Loss: 1.183626, Acc:0.067591, Semantic loss: 0.000000, BCE loss: 1.183626, SB loss: 0.000000
2025-01-03 16:40:37,584 Epoch: [2/20] Iter:[30/227], Time: 1.16, lr: [0.009035202366045183], Loss: 1.136856, Acc:0.070206, Semantic loss: 0.000000, BCE loss: 1.136856, SB loss: 0.000000
2025-01-03 16:40:44,379 Epoch: [2/20] Iter:[40/227], Time: 1.04, lr: [0.009015151366382665], Loss: 1.185638, Acc:0.072599, Semantic loss: 0.000000, BCE loss: 1.185638, SB loss: 0.000000
2025-01-03 16:40:51,130 Epoch: [2/20] Iter:[50/227], Time: 0.97, lr: [0.00899509541034368], Loss: 1.239469, Acc:0.074775, Semantic loss: 0.000000, BCE loss: 1.239469, SB loss: 0.000000
2025-01-03 16:40:57,900 Epoch: [2/20] Iter:[60/227], Time: 0.92, lr: [0.008975034484418066], Loss: 1.205630, Acc:0.073867, Semantic loss: 0.000000, BCE loss: 1.205630, SB loss: 0.000000
2025-01-03 16:41:04,789 Epoch: [2/20] Iter:[70/227], Time: 0.89, lr: [0.008954968575025186], Loss: 1.179331, Acc:0.074780, Semantic loss: 0.000000, BCE loss: 1.179331, SB loss: 0.000000
2025-01-03 16:41:11,528 Epoch: [2/20] Iter:[80/227], Time: 0.86, lr: [0.008934897668513376], Loss: 1.163613, Acc:0.075109, Semantic loss: 0.000000, BCE loss: 1.163613, SB loss: 0.000000
2025-01-03 16:41:18,396 Epoch: [2/20] Iter:[90/227], Time: 0.84, lr: [0.008914821751159398], Loss: 1.195833, Acc:0.075050, Semantic loss: 0.000000, BCE loss: 1.195833, SB loss: 0.000000
2025-01-03 16:41:25,126 Epoch: [2/20] Iter:[100/227], Time: 0.83, lr: [0.00889474080916789], Loss: 1.191471, Acc:0.075243, Semantic loss: 0.000000, BCE loss: 1.191471, SB loss: 0.000000
2025-01-03 16:41:31,941 Epoch: [2/20] Iter:[110/227], Time: 0.81, lr: [0.0088746548286708], Loss: 1.190747, Acc:0.075624, Semantic loss: 0.000000, BCE loss: 1.190747, SB loss: 0.000000
2025-01-03 16:41:38,714 Epoch: [2/20] Iter:[120/227], Time: 0.80, lr: [0.008854563795726814], Loss: 1.167818, Acc:0.075298, Semantic loss: 0.000000, BCE loss: 1.167818, SB loss: 0.000000
2025-01-03 16:41:45,608 Epoch: [2/20] Iter:[130/227], Time: 0.79, lr: [0.008834467696320793], Loss: 1.168103, Acc:0.075619, Semantic loss: 0.000000, BCE loss: 1.168103, SB loss: 0.000000
2025-01-03 16:41:52,348 Epoch: [2/20] Iter:[140/227], Time: 0.79, lr: [0.008814366516363192], Loss: 1.160852, Acc:0.076294, Semantic loss: 0.000000, BCE loss: 1.160852, SB loss: 0.000000
2025-01-03 16:41:59,203 Epoch: [2/20] Iter:[150/227], Time: 0.78, lr: [0.008794260241689474], Loss: 1.168390, Acc:0.076763, Semantic loss: 0.000000, BCE loss: 1.168390, SB loss: 0.000000
2025-01-03 16:42:06,026 Epoch: [2/20] Iter:[160/227], Time: 0.77, lr: [0.008774148858059518], Loss: 1.174843, Acc:0.076851, Semantic loss: 0.000000, BCE loss: 1.174843, SB loss: 0.000000
2025-01-03 16:42:12,938 Epoch: [2/20] Iter:[170/227], Time: 0.77, lr: [0.00875403235115702], Loss: 1.179133, Acc:0.077069, Semantic loss: 0.000000, BCE loss: 1.179133, SB loss: 0.000000
2025-01-03 16:42:19,733 Epoch: [2/20] Iter:[180/227], Time: 0.76, lr: [0.008733910706588898], Loss: 1.186359, Acc:0.077469, Semantic loss: 0.000000, BCE loss: 1.186359, SB loss: 0.000000
2025-01-03 16:42:26,525 Epoch: [2/20] Iter:[190/227], Time: 0.76, lr: [0.008713783909884674], Loss: 1.186528, Acc:0.078078, Semantic loss: 0.000000, BCE loss: 1.186528, SB loss: 0.000000
2025-01-03 16:42:33,379 Epoch: [2/20] Iter:[200/227], Time: 0.76, lr: [0.008693651946495864], Loss: 1.184058, Acc:0.078257, Semantic loss: 0.000000, BCE loss: 1.184058, SB loss: 0.000000
2025-01-03 16:42:40,175 Epoch: [2/20] Iter:[210/227], Time: 0.75, lr: [0.008673514801795358], Loss: 1.174935, Acc:0.078741, Semantic loss: 0.000000, BCE loss: 1.174935, SB loss: 0.000000
2025-01-03 16:42:46,744 Epoch: [2/20] Iter:[220/227], Time: 0.75, lr: [0.008653372461076773], Loss: 1.164187, Acc:0.078955, Semantic loss: 0.000000, BCE loss: 1.164187, SB loss: 0.000000
2025-01-03 16:45:31,898 0 [1.07830584e-02 4.10187144e-01 0.00000000e+00 5.41196773e-03
 2.11808965e-06 1.24110147e-02 1.14684930e-02 1.85651889e-03] 0.05651503939081073
2025-01-03 16:45:31,898 1 [0.01638071 0.05700991 0.01044269 0.01452359 0.11079723 0.02655023
 0.00507165 0.00109595] 0.03023399513687515
2025-01-03 16:45:31,904 => saving checkpoint to output\loveDa\pidnet_small_lovedacheckpoint.pth.tar
2025-01-03 16:45:32,082 Loss: 1.050, MeanIU:  0.0302, Best_mIoU:  0.0302
2025-01-03 16:45:32,082 [0.01638071 0.05700991 0.01044269 0.01452359 0.11079723 0.02655023
 0.00507165 0.00109595]
2025-01-03 16:45:48,191 Epoch: [3/20] Iter:[0/227], Time: 15.88, lr: [0.008639269723028191], Loss: 0.985388, Acc:0.106090, Semantic loss: 0.000000, BCE loss: 0.985388, SB loss: 0.000000
2025-01-03 16:45:54,481 Epoch: [3/20] Iter:[10/227], Time: 2.01, lr: [0.00861911851510129], Loss: 1.179363, Acc:0.080868, Semantic loss: 0.000000, BCE loss: 1.179363, SB loss: 0.000000
2025-01-03 16:46:01,011 Epoch: [3/20] Iter:[20/227], Time: 1.36, lr: [0.008598962071048205], Loss: 1.093130, Acc:0.079705, Semantic loss: 0.000000, BCE loss: 1.093130, SB loss: 0.000000
2025-01-03 16:46:07,704 Epoch: [3/20] Iter:[30/227], Time: 1.14, lr: [0.00857880037586372], Loss: 1.066932, Acc:0.081454, Semantic loss: 0.000000, BCE loss: 1.066932, SB loss: 0.000000
2025-01-03 16:46:14,537 Epoch: [3/20] Iter:[40/227], Time: 1.03, lr: [0.008558633414460315], Loss: 1.077868, Acc:0.084056, Semantic loss: 0.000000, BCE loss: 1.077868, SB loss: 0.000000
2025-01-03 16:46:21,408 Epoch: [3/20] Iter:[50/227], Time: 0.96, lr: [0.008538461171667492], Loss: 1.100022, Acc:0.083357, Semantic loss: 0.000000, BCE loss: 1.100022, SB loss: -0.000000
2025-01-03 16:46:28,183 Epoch: [3/20] Iter:[60/227], Time: 0.91, lr: [0.008518283632231104], Loss: 1.131029, Acc:0.080955, Semantic loss: 0.000000, BCE loss: 1.131029, SB loss: -0.000000
2025-01-03 16:46:35,057 Epoch: [3/20] Iter:[70/227], Time: 0.88, lr: [0.008498100780812675], Loss: 1.139366, Acc:0.081361, Semantic loss: 0.000000, BCE loss: 1.139366, SB loss: -0.000000
2025-01-03 16:46:41,815 Epoch: [3/20] Iter:[80/227], Time: 0.86, lr: [0.008477912601988699], Loss: 1.146467, Acc:0.081738, Semantic loss: 0.000000, BCE loss: 1.146467, SB loss: -0.000000
2025-01-03 16:46:48,640 Epoch: [3/20] Iter:[90/227], Time: 0.84, lr: [0.00845771908024996], Loss: 1.160100, Acc:0.080928, Semantic loss: 0.000000, BCE loss: 1.160100, SB loss: -0.000000
2025-01-03 16:46:55,420 Epoch: [3/20] Iter:[100/227], Time: 0.82, lr: [0.008437520200000803], Loss: 1.147914, Acc:0.081139, Semantic loss: 0.000000, BCE loss: 1.147914, SB loss: -0.000000
