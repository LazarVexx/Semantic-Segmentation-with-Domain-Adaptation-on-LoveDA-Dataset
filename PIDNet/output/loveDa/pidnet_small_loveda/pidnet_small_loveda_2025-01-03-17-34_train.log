2025-01-03 17:34:15,655 Namespace(cfg='configs/loveDa/pidnet_small_loveda.yaml', seed=304, opts=['GPUS', '[0]', 'TRAIN.BATCH_SIZE_PER_GPU', '6'])
2025-01-03 17:34:15,655 AUTO_RESUME: False
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  DATASET: loveDa
  EXTRA_TRAIN_SET: 
  NUM_CLASSES: 8
  ROOT: data/
  TEST_SET: list/loveDa/val.lst
  TRAIN_SET: list/loveDa/train.lst
GPUS: (0,)
LOG_DIR: log
LOSS:
  BALANCE_WEIGHTS: [0.4, 1.0]
  CLASS_BALANCE: False
  OHEMKEEP: 131072
  OHEMTHRES: 0.9
  SB_WEIGHTS: 1.0
  USE_OHEM: True
MODEL:
  ALIGN_CORNERS: True
  NAME: pidnet_small
  NUM_OUTPUTS: 2
  PRETRAINED: pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar
OUTPUT_DIR: output
PIN_MEMORY: True
PRINT_FREQ: 10
TEST:
  BASE_SIZE: 2048
  BATCH_SIZE_PER_GPU: 6
  FLIP_TEST: False
  IMAGE_SIZE: [1024, 1024]
  MODEL_FILE: 
  MULTI_SCALE: False
  OUTPUT_INDEX: 1
TRAIN:
  BASE_SIZE: 2048
  BATCH_SIZE_PER_GPU: 6
  BEGIN_EPOCH: 0
  END_EPOCH: 20
  EXTRA_EPOCH: 0
  EXTRA_LR: 0.001
  FLIP: True
  IGNORE_LABEL: 0
  IMAGE_SIZE: [1024, 1024]
  LR: 0.01
  MOMENTUM: 0.9
  MULTI_SCALE: True
  NESTEROV: False
  OPTIMIZER: sgd
  RESUME: False
  SCALE_FACTOR: 16
  SHUFFLE: True
  WD: 0.0005
WORKERS: 6
2025-01-03 17:34:15,844 Attention!!!
2025-01-03 17:34:15,844 Loaded 302 parameters!
2025-01-03 17:34:15,844 Over!!!
2025-01-03 17:34:37,065 Epoch: [0/20] Iter:[0/227], Time: 19.72, lr: [0.01], Loss: 1.907734, Acc:0.155089, Semantic loss: 0.000000, BCE loss: 1.907735, SB loss: -0.000000
2025-01-03 17:34:44,870 Epoch: [0/20] Iter:[10/227], Time: 2.47, lr: [0.009980174026451818], Loss: 1.933172, Acc:0.094953, Semantic loss: 0.000000, BCE loss: 1.933172, SB loss: 0.000000
2025-01-03 17:34:52,320 Epoch: [0/20] Iter:[20/227], Time: 1.65, lr: [0.009960343675822199], Loss: 1.553137, Acc:0.090713, Semantic loss: 0.000000, BCE loss: 1.553137, SB loss: 0.000000
2025-01-03 17:35:00,010 Epoch: [0/20] Iter:[30/227], Time: 1.37, lr: [0.009940508937457754], Loss: 1.414151, Acc:0.084715, Semantic loss: 0.000000, BCE loss: 1.414151, SB loss: 0.000000
2025-01-03 17:35:07,688 Epoch: [0/20] Iter:[40/227], Time: 1.22, lr: [0.009920669800655492], Loss: 1.359904, Acc:0.079586, Semantic loss: 0.000000, BCE loss: 1.359904, SB loss: 0.000000
2025-01-03 17:35:15,350 Epoch: [0/20] Iter:[50/227], Time: 1.13, lr: [0.009900826254662456], Loss: 1.316359, Acc:0.079675, Semantic loss: 0.000000, BCE loss: 1.316359, SB loss: 0.000000
2025-01-03 17:35:22,826 Epoch: [0/20] Iter:[60/227], Time: 1.07, lr: [0.009880978288675405], Loss: 1.293340, Acc:0.076252, Semantic loss: 0.000000, BCE loss: 1.293340, SB loss: 0.000000
2025-01-03 17:35:30,469 Epoch: [0/20] Iter:[70/227], Time: 1.03, lr: [0.009861125891840445], Loss: 1.276618, Acc:0.077351, Semantic loss: 0.000000, BCE loss: 1.276618, SB loss: 0.000000
2025-01-03 17:35:38,264 Epoch: [0/20] Iter:[80/227], Time: 0.99, lr: [0.009841269053252683], Loss: 1.281197, Acc:0.076071, Semantic loss: 0.000000, BCE loss: 1.281197, SB loss: 0.000000
2025-01-03 17:35:45,955 Epoch: [0/20] Iter:[90/227], Time: 0.97, lr: [0.00982140776195588], Loss: 1.256228, Acc:0.074704, Semantic loss: 0.000000, BCE loss: 1.256228, SB loss: 0.000000
2025-01-03 17:35:53,605 Epoch: [0/20] Iter:[100/227], Time: 0.95, lr: [0.009801542006942082], Loss: 1.246624, Acc:0.073677, Semantic loss: 0.000000, BCE loss: 1.246624, SB loss: 0.000000
2025-01-03 17:36:01,250 Epoch: [0/20] Iter:[110/227], Time: 0.93, lr: [0.009781671777151266], Loss: 1.237571, Acc:0.072381, Semantic loss: 0.000000, BCE loss: 1.237571, SB loss: 0.000000
2025-01-03 17:36:08,870 Epoch: [0/20] Iter:[120/227], Time: 0.92, lr: [0.009761797061470977], Loss: 1.233911, Acc:0.072073, Semantic loss: 0.000000, BCE loss: 1.233911, SB loss: 0.000000
2025-01-03 17:36:16,547 Epoch: [0/20] Iter:[130/227], Time: 0.91, lr: [0.009741917848735952], Loss: 1.224410, Acc:0.071453, Semantic loss: 0.000000, BCE loss: 1.224410, SB loss: 0.000000
2025-01-03 17:36:24,256 Epoch: [0/20] Iter:[140/227], Time: 0.90, lr: [0.009722034127727758], Loss: 1.216791, Acc:0.070856, Semantic loss: 0.000000, BCE loss: 1.216791, SB loss: 0.000000
2025-01-03 17:36:31,871 Epoch: [0/20] Iter:[150/227], Time: 0.89, lr: [0.009702145887174411], Loss: 1.205734, Acc:0.070839, Semantic loss: 0.000000, BCE loss: 1.205734, SB loss: 0.000000
2025-01-03 17:36:39,558 Epoch: [0/20] Iter:[160/227], Time: 0.88, lr: [0.009682253115750003], Loss: 1.202791, Acc:0.070460, Semantic loss: 0.000000, BCE loss: 1.202791, SB loss: 0.000000
2025-01-03 17:36:47,246 Epoch: [0/20] Iter:[170/227], Time: 0.87, lr: [0.009662355802074312], Loss: 1.201393, Acc:0.070362, Semantic loss: 0.000000, BCE loss: 1.201393, SB loss: 0.000000
2025-01-03 17:36:55,016 Epoch: [0/20] Iter:[180/227], Time: 0.87, lr: [0.00964245393471243], Loss: 1.198548, Acc:0.070464, Semantic loss: 0.000000, BCE loss: 1.198548, SB loss: 0.000000
2025-01-03 17:37:02,696 Epoch: [0/20] Iter:[190/227], Time: 0.86, lr: [0.009622547502174356], Loss: 1.192054, Acc:0.070153, Semantic loss: 0.000000, BCE loss: 1.192054, SB loss: 0.000000
2025-01-03 17:37:10,275 Epoch: [0/20] Iter:[200/227], Time: 0.86, lr: [0.009602636492914622], Loss: 1.187656, Acc:0.070269, Semantic loss: 0.000000, BCE loss: 1.187656, SB loss: 0.000000
2025-01-03 17:37:17,907 Epoch: [0/20] Iter:[210/227], Time: 0.85, lr: [0.009582720895331883], Loss: 1.180125, Acc:0.070750, Semantic loss: 0.000000, BCE loss: 1.180125, SB loss: 0.000000
2025-01-03 17:37:25,511 Epoch: [0/20] Iter:[220/227], Time: 0.85, lr: [0.009562800697768528], Loss: 1.177939, Acc:0.070451, Semantic loss: 0.000000, BCE loss: 1.177938, SB loss: 0.000000
2025-01-03 17:40:06,751 0 [0.00000000e+00 4.16912725e-01 0.00000000e+00 3.44061833e-03
 1.05905282e-06 1.25411254e-02 1.15470474e-02 5.54826020e-03] 0.05624885438353283
2025-01-03 17:40:06,752 1 [0.         0.00877235 0.00637333 0.02495977 0.07662086 0.02669876
 0.01831584 0.00065904] 0.020299993519834247
2025-01-03 17:40:06,757 => saving checkpoint to output\loveDa\pidnet_small_lovedacheckpoint.pth.tar
2025-01-03 17:40:07,014 Loss: 1.057, MeanIU:  0.0203, Best_mIoU:  0.0203
2025-01-03 17:40:07,015 [0.         0.00877235 0.00637333 0.02495977 0.07662086 0.02669876
 0.01831584 0.00065904]
2025-01-03 17:40:23,493 Epoch: [1/20] Iter:[0/227], Time: 16.18, lr: [0.009548853816214998], Loss: 1.411065, Acc:0.079800, Semantic loss: 0.000000, BCE loss: 1.411065, SB loss: -0.000000
2025-01-03 17:40:30,419 Epoch: [1/20] Iter:[10/227], Time: 2.09, lr: [0.009528925771769746], Loss: 1.178397, Acc:0.067473, Semantic loss: 0.000000, BCE loss: 1.178397, SB loss: 0.000000
2025-01-03 17:40:37,137 Epoch: [1/20] Iter:[20/227], Time: 1.42, lr: [0.009508993095584064], Loss: 1.171400, Acc:0.071137, Semantic loss: 0.000000, BCE loss: 1.171399, SB loss: 0.000000
2025-01-03 17:40:44,085 Epoch: [1/20] Iter:[30/227], Time: 1.18, lr: [0.009489055775788591], Loss: 1.191416, Acc:0.077615, Semantic loss: 0.000000, BCE loss: 1.191416, SB loss: -0.000000
2025-01-03 17:40:50,970 Epoch: [1/20] Iter:[40/227], Time: 1.06, lr: [0.009469113800455762], Loss: 1.197784, Acc:0.079218, Semantic loss: 0.000000, BCE loss: 1.197784, SB loss: -0.000000
2025-01-03 17:40:58,096 Epoch: [1/20] Iter:[50/227], Time: 0.99, lr: [0.009449167157599386], Loss: 1.190419, Acc:0.077479, Semantic loss: 0.000000, BCE loss: 1.190419, SB loss: -0.000000
2025-01-03 17:41:05,071 Epoch: [1/20] Iter:[60/227], Time: 0.95, lr: [0.00942921583517422], Loss: 1.181635, Acc:0.078155, Semantic loss: 0.000000, BCE loss: 1.181635, SB loss: -0.000000
2025-01-03 17:41:12,568 Epoch: [1/20] Iter:[70/227], Time: 0.92, lr: [0.009409259821075532], Loss: 1.185208, Acc:0.078860, Semantic loss: 0.000000, BCE loss: 1.185208, SB loss: -0.000000
2025-01-03 17:41:19,972 Epoch: [1/20] Iter:[80/227], Time: 0.90, lr: [0.009389299103138684], Loss: 1.163921, Acc:0.076165, Semantic loss: 0.000000, BCE loss: 1.163921, SB loss: -0.000000
2025-01-03 17:41:27,271 Epoch: [1/20] Iter:[90/227], Time: 0.88, lr: [0.00936933366913867], Loss: 1.154930, Acc:0.075512, Semantic loss: 0.000000, BCE loss: 1.154930, SB loss: -0.000000
2025-01-03 17:41:34,211 Epoch: [1/20] Iter:[100/227], Time: 0.86, lr: [0.009349363506789691], Loss: 1.159197, Acc:0.075158, Semantic loss: 0.000000, BCE loss: 1.159197, SB loss: -0.000000
2025-01-03 17:41:41,666 Epoch: [1/20] Iter:[110/227], Time: 0.85, lr: [0.009329388603744703], Loss: 1.152099, Acc:0.075858, Semantic loss: 0.000000, BCE loss: 1.152099, SB loss: -0.000000
2025-01-03 17:41:48,746 Epoch: [1/20] Iter:[120/227], Time: 0.84, lr: [0.009309408947594957], Loss: 1.153543, Acc:0.075497, Semantic loss: 0.000000, BCE loss: 1.153543, SB loss: -0.000000
