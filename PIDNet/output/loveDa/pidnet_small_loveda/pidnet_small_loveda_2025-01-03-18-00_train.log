2025-01-03 18:00:54,139 Namespace(cfg='configs/loveDa/pidnet_small_loveda.yaml', seed=304, opts=['GPUS', '[0]', 'TRAIN.BATCH_SIZE_PER_GPU', '6'])
2025-01-03 18:00:54,139 AUTO_RESUME: False
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  DATASET: loveDa
  EXTRA_TRAIN_SET: 
  NUM_CLASSES: 8
  ROOT: data/
  TEST_SET: list/loveDa/val.lst
  TRAIN_SET: list/loveDa/train.lst
GPUS: (0,)
LOG_DIR: log
LOSS:
  BALANCE_WEIGHTS: [0.4, 1.0]
  CLASS_BALANCE: False
  OHEMKEEP: 131072
  OHEMTHRES: 0.9
  SB_WEIGHTS: 1.0
  USE_OHEM: True
MODEL:
  ALIGN_CORNERS: True
  NAME: pidnet_small
  NUM_OUTPUTS: 2
  PRETRAINED: pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar
OUTPUT_DIR: output
PIN_MEMORY: True
PRINT_FREQ: 10
TEST:
  BASE_SIZE: 1024
  BATCH_SIZE_PER_GPU: 6
  FLIP_TEST: False
  IMAGE_SIZE: [1024, 1024]
  MODEL_FILE: 
  MULTI_SCALE: False
  OUTPUT_INDEX: 1
TRAIN:
  BASE_SIZE: 1024
  BATCH_SIZE_PER_GPU: 6
  BEGIN_EPOCH: 0
  END_EPOCH: 20
  EXTRA_EPOCH: 0
  EXTRA_LR: 0.001
  FLIP: True
  IGNORE_LABEL: 0
  IMAGE_SIZE: [1024, 1024]
  LR: 0.01
  MOMENTUM: 0.9
  MULTI_SCALE: True
  NESTEROV: False
  OPTIMIZER: sgd
  RESUME: False
  SCALE_FACTOR: 16
  SHUFFLE: True
  WD: 0.0005
WORKERS: 6
2025-01-03 18:00:54,388 Attention!!!
2025-01-03 18:00:54,389 Loaded 302 parameters!
2025-01-03 18:00:54,389 Over!!!
2025-01-03 18:01:15,989 Epoch: [0/20] Iter:[0/227], Time: 19.93, lr: [0.01], Loss: 2.237003, Acc:0.139881, Semantic loss: 0.000000, BCE loss: 2.237003, SB loss: 0.000000
2025-01-03 18:01:22,949 Epoch: [0/20] Iter:[10/227], Time: 2.41, lr: [0.009980174026451818], Loss: 1.707596, Acc:0.104636, Semantic loss: 0.000000, BCE loss: 1.707596, SB loss: -0.000000
2025-01-03 18:01:29,375 Epoch: [0/20] Iter:[20/227], Time: 1.57, lr: [0.009960343675822199], Loss: 1.380852, Acc:0.111728, Semantic loss: 0.000000, BCE loss: 1.380852, SB loss: -0.000000
2025-01-03 18:01:36,194 Epoch: [0/20] Iter:[30/227], Time: 1.28, lr: [0.009940508937457754], Loss: 1.231460, Acc:0.113974, Semantic loss: 0.000000, BCE loss: 1.231460, SB loss: -0.000000
2025-01-03 18:01:43,064 Epoch: [0/20] Iter:[40/227], Time: 1.14, lr: [0.009920669800655492], Loss: 1.183628, Acc:0.116515, Semantic loss: 0.000000, BCE loss: 1.183628, SB loss: -0.000000
2025-01-03 18:01:49,558 Epoch: [0/20] Iter:[50/227], Time: 1.04, lr: [0.009900826254662456], Loss: 1.139142, Acc:0.118192, Semantic loss: 0.000000, BCE loss: 1.139142, SB loss: -0.000000
2025-01-03 18:01:55,860 Epoch: [0/20] Iter:[60/227], Time: 0.98, lr: [0.009880978288675405], Loss: 1.118187, Acc:0.116306, Semantic loss: 0.000000, BCE loss: 1.118187, SB loss: -0.000000
2025-01-03 18:02:02,288 Epoch: [0/20] Iter:[70/227], Time: 0.93, lr: [0.009861125891840445], Loss: 1.111390, Acc:0.116474, Semantic loss: 0.000000, BCE loss: 1.111390, SB loss: -0.000000
2025-01-03 18:02:08,926 Epoch: [0/20] Iter:[80/227], Time: 0.90, lr: [0.009841269053252683], Loss: 1.102718, Acc:0.116652, Semantic loss: 0.000000, BCE loss: 1.102718, SB loss: -0.000000
2025-01-03 18:02:15,328 Epoch: [0/20] Iter:[90/227], Time: 0.87, lr: [0.00982140776195588], Loss: 1.101942, Acc:0.116563, Semantic loss: 0.000000, BCE loss: 1.101942, SB loss: 0.000000
2025-01-03 18:02:21,732 Epoch: [0/20] Iter:[100/227], Time: 0.85, lr: [0.009801542006942082], Loss: 1.088934, Acc:0.116551, Semantic loss: 0.000000, BCE loss: 1.088934, SB loss: -0.000000
2025-01-03 18:02:28,270 Epoch: [0/20] Iter:[110/227], Time: 0.83, lr: [0.009781671777151266], Loss: 1.074536, Acc:0.115616, Semantic loss: 0.000000, BCE loss: 1.074536, SB loss: -0.000000
2025-01-03 18:02:34,756 Epoch: [0/20] Iter:[120/227], Time: 0.81, lr: [0.009761797061470977], Loss: 1.061258, Acc:0.116618, Semantic loss: 0.000000, BCE loss: 1.061258, SB loss: -0.000000
2025-01-03 18:02:41,380 Epoch: [0/20] Iter:[130/227], Time: 0.80, lr: [0.009741917848735952], Loss: 1.055341, Acc:0.116082, Semantic loss: 0.000000, BCE loss: 1.055341, SB loss: -0.000000
2025-01-03 18:02:47,703 Epoch: [0/20] Iter:[140/227], Time: 0.79, lr: [0.009722034127727758], Loss: 1.048338, Acc:0.114948, Semantic loss: 0.000000, BCE loss: 1.048338, SB loss: 0.000000
2025-01-03 18:02:54,103 Epoch: [0/20] Iter:[150/227], Time: 0.78, lr: [0.009702145887174411], Loss: 1.040069, Acc:0.115252, Semantic loss: 0.000000, BCE loss: 1.040069, SB loss: 0.000000
2025-01-03 18:03:00,583 Epoch: [0/20] Iter:[160/227], Time: 0.77, lr: [0.009682253115750003], Loss: 1.042019, Acc:0.115178, Semantic loss: 0.000000, BCE loss: 1.042019, SB loss: 0.000000
2025-01-03 18:03:07,380 Epoch: [0/20] Iter:[170/227], Time: 0.77, lr: [0.009662355802074312], Loss: 1.049328, Acc:0.114702, Semantic loss: 0.000000, BCE loss: 1.049328, SB loss: -0.000000
2025-01-03 18:03:13,880 Epoch: [0/20] Iter:[180/227], Time: 0.76, lr: [0.00964245393471243], Loss: 1.047127, Acc:0.114162, Semantic loss: 0.000000, BCE loss: 1.047127, SB loss: -0.000000
2025-01-03 18:03:20,284 Epoch: [0/20] Iter:[190/227], Time: 0.75, lr: [0.009622547502174356], Loss: 1.044390, Acc:0.114061, Semantic loss: 0.000000, BCE loss: 1.044390, SB loss: 0.000000
2025-01-03 18:03:26,814 Epoch: [0/20] Iter:[200/227], Time: 0.75, lr: [0.009602636492914622], Loss: 1.036559, Acc:0.114236, Semantic loss: 0.000000, BCE loss: 1.036559, SB loss: 0.000000
2025-01-03 18:03:33,376 Epoch: [0/20] Iter:[210/227], Time: 0.74, lr: [0.009582720895331883], Loss: 1.031317, Acc:0.114613, Semantic loss: 0.000000, BCE loss: 1.031317, SB loss: 0.000000
2025-01-03 18:03:39,716 Epoch: [0/20] Iter:[220/227], Time: 0.74, lr: [0.009562800697768528], Loss: 1.027068, Acc:0.114847, Semantic loss: 0.000000, BCE loss: 1.027068, SB loss: 0.000000
2025-01-03 18:06:22,982 0 [0.00000000e+00 2.46591718e-05 0.00000000e+00 1.03639794e-03
 0.00000000e+00 1.28590463e-02 1.20946845e-02 3.00143833e-01] 0.04076982759231808
2025-01-03 18:06:22,982 1 [0.00000000e+00 1.19414853e-04 7.03958398e-06 1.78888099e-03
 1.15814113e-01 1.62643041e-02 4.47484344e-03 2.15314559e-05] 0.01731126595544101
2025-01-03 18:06:22,988 => saving checkpoint to output\loveDa\pidnet_small_lovedacheckpoint.pth.tar
2025-01-03 18:06:23,238 Loss: 1.052, MeanIU:  0.0173, Best_mIoU:  0.0173
2025-01-03 18:06:23,239 [0.00000000e+00 1.19414853e-04 7.03958398e-06 1.78888099e-03
 1.15814113e-01 1.62643041e-02 4.47484344e-03 2.15314559e-05]
2025-01-03 18:06:38,957 Epoch: [1/20] Iter:[0/227], Time: 15.03, lr: [0.009548853816214998], Loss: 1.278094, Acc:0.119976, Semantic loss: 0.000000, BCE loss: 1.278094, SB loss: 0.000000
2025-01-03 18:06:47,680 Epoch: [1/20] Iter:[10/227], Time: 2.19, lr: [0.009528925771769746], Loss: 0.876581, Acc:0.108507, Semantic loss: 0.000000, BCE loss: 0.876581, SB loss: 0.000000
2025-01-03 18:06:55,774 Epoch: [1/20] Iter:[20/227], Time: 1.53, lr: [0.009508993095584064], Loss: 0.931104, Acc:0.106873, Semantic loss: 0.000000, BCE loss: 0.931104, SB loss: 0.000000
2025-01-03 18:07:03,807 Epoch: [1/20] Iter:[30/227], Time: 1.30, lr: [0.009489055775788591], Loss: 0.963253, Acc:0.111342, Semantic loss: 0.000000, BCE loss: 0.963253, SB loss: 0.000000
2025-01-03 18:07:11,892 Epoch: [1/20] Iter:[40/227], Time: 1.18, lr: [0.009469113800455762], Loss: 0.983444, Acc:0.107740, Semantic loss: 0.000000, BCE loss: 0.983444, SB loss: 0.000000
2025-01-03 18:07:19,963 Epoch: [1/20] Iter:[50/227], Time: 1.10, lr: [0.009449167157599386], Loss: 0.981673, Acc:0.106677, Semantic loss: 0.000000, BCE loss: 0.981672, SB loss: 0.000000
2025-01-03 18:07:27,974 Epoch: [1/20] Iter:[60/227], Time: 1.05, lr: [0.00942921583517422], Loss: 0.990949, Acc:0.106072, Semantic loss: 0.000000, BCE loss: 0.990949, SB loss: 0.000000
2025-01-03 18:07:35,989 Epoch: [1/20] Iter:[70/227], Time: 1.02, lr: [0.009409259821075532], Loss: 0.987327, Acc:0.106761, Semantic loss: 0.000000, BCE loss: 0.987326, SB loss: 0.000000
2025-01-03 18:07:44,066 Epoch: [1/20] Iter:[80/227], Time: 0.99, lr: [0.009389299103138684], Loss: 0.980434, Acc:0.105462, Semantic loss: 0.000000, BCE loss: 0.980434, SB loss: 0.000000
2025-01-03 18:07:53,206 Epoch: [1/20] Iter:[90/227], Time: 0.98, lr: [0.00936933366913867], Loss: 0.968930, Acc:0.105137, Semantic loss: 0.000000, BCE loss: 0.968930, SB loss: 0.000000
2025-01-03 18:08:01,344 Epoch: [1/20] Iter:[100/227], Time: 0.97, lr: [0.009349363506789691], Loss: 0.977882, Acc:0.104613, Semantic loss: 0.000000, BCE loss: 0.977882, SB loss: 0.000000
2025-01-03 18:08:09,430 Epoch: [1/20] Iter:[110/227], Time: 0.95, lr: [0.009329388603744703], Loss: 0.972385, Acc:0.103973, Semantic loss: 0.000000, BCE loss: 0.972385, SB loss: 0.000000
2025-01-03 18:08:17,506 Epoch: [1/20] Iter:[120/227], Time: 0.94, lr: [0.009309408947594957], Loss: 0.967894, Acc:0.103437, Semantic loss: 0.000000, BCE loss: 0.967894, SB loss: 0.000000
2025-01-03 18:08:25,593 Epoch: [1/20] Iter:[130/227], Time: 0.93, lr: [0.009289424525869554], Loss: nan, Acc:0.103103, Semantic loss: 0.000000, BCE loss: 0.973587, SB loss: nan
2025-01-03 18:08:34,326 Epoch: [1/20] Iter:[140/227], Time: 0.93, lr: [0.009269435326034976], Loss: nan, Acc:0.103157, Semantic loss: 0.000000, BCE loss: 0.980619, SB loss: nan
2025-01-03 18:08:42,408 Epoch: [1/20] Iter:[150/227], Time: 0.92, lr: [0.00924944133549463], Loss: nan, Acc:0.103966, Semantic loss: 0.000000, BCE loss: 0.981065, SB loss: nan
2025-01-03 18:08:50,457 Epoch: [1/20] Iter:[160/227], Time: 0.91, lr: [0.009229442541588362], Loss: nan, Acc:0.104365, Semantic loss: 0.000000, BCE loss: 0.978062, SB loss: nan
2025-01-03 18:08:58,561 Epoch: [1/20] Iter:[170/227], Time: 0.91, lr: [0.009209438931592004], Loss: nan, Acc:0.103684, Semantic loss: 0.000000, BCE loss: 0.981543, SB loss: nan
2025-01-03 18:09:06,643 Epoch: [1/20] Iter:[180/227], Time: 0.90, lr: [0.009189430492716878], Loss: nan, Acc:0.103578, Semantic loss: 0.000000, BCE loss: 0.975707, SB loss: nan
2025-01-03 18:09:14,672 Epoch: [1/20] Iter:[190/227], Time: 0.90, lr: [0.009169417212109319], Loss: nan, Acc:0.104046, Semantic loss: 0.000000, BCE loss: 0.977355, SB loss: nan
2025-01-03 18:09:23,343 Epoch: [1/20] Iter:[200/227], Time: 0.89, lr: [0.009149399076850187], Loss: nan, Acc:0.103285, Semantic loss: 0.000000, BCE loss: 0.987854, SB loss: nan
2025-01-03 18:09:31,416 Epoch: [1/20] Iter:[210/227], Time: 0.89, lr: [0.009129376073954367], Loss: nan, Acc:0.103660, Semantic loss: 0.000000, BCE loss: 0.991371, SB loss: nan
2025-01-03 18:09:39,426 Epoch: [1/20] Iter:[220/227], Time: 0.89, lr: [0.009109348190370282], Loss: nan, Acc:0.103404, Semantic loss: 0.000000, BCE loss: 0.994639, SB loss: nan
2025-01-03 18:09:44,588 NaN or Inf found in input tensor.
2025-01-03 18:12:51,326 0 [0.         0.41672974 0.         0.00542429 0.00092203 0.01287032
 0.01154772 0.00278079] 0.05628436001813921
2025-01-03 18:12:51,327 1 [0.         0.00117796 0.00453231 0.02621473 0.08748243 0.01026329
 0.00020354 0.00041132] 0.016285697054606706
2025-01-03 18:12:51,334 => saving checkpoint to output\loveDa\pidnet_small_lovedacheckpoint.pth.tar
2025-01-03 18:12:51,452 Loss: 1.054, MeanIU:  0.0163, Best_mIoU:  0.0173
2025-01-03 18:12:51,452 [0.         0.00117796 0.00453231 0.02621473 0.08748243 0.01026329
 0.00020354 0.00041132]
2025-01-03 18:13:08,241 Epoch: [2/20] Iter:[0/227], Time: 16.09, lr: [0.009095325760829623], Loss: 0.585020, Acc:0.087513, Semantic loss: 0.000000, BCE loss: 0.585020, SB loss: 0.000000
2025-01-03 18:13:16,354 Epoch: [2/20] Iter:[10/227], Time: 2.23, lr: [0.00907528954993229], Loss: nan, Acc:0.094665, Semantic loss: 0.000000, BCE loss: 0.956755, SB loss: nan
2025-01-03 18:13:24,602 Epoch: [2/20] Iter:[20/227], Time: 1.56, lr: [0.009055248422771453], Loss: nan, Acc:0.091844, Semantic loss: 0.000000, BCE loss: 0.996997, SB loss: nan
2025-01-03 18:13:32,788 Epoch: [2/20] Iter:[30/227], Time: 1.32, lr: [0.009035202366045183], Loss: nan, Acc:0.095373, Semantic loss: 0.000000, BCE loss: 1.004605, SB loss: nan
2025-01-03 18:13:41,014 Epoch: [2/20] Iter:[40/227], Time: 1.20, lr: [0.009015151366382665], Loss: nan, Acc:0.094819, Semantic loss: 0.000000, BCE loss: 1.043519, SB loss: nan
2025-01-03 18:13:49,189 Epoch: [2/20] Iter:[50/227], Time: 1.12, lr: [0.00899509541034368], Loss: nan, Acc:0.095922, Semantic loss: 0.000000, BCE loss: 1.069487, SB loss: nan
2025-01-03 18:13:57,371 Epoch: [2/20] Iter:[60/227], Time: 1.07, lr: [0.008975034484418066], Loss: nan, Acc:0.095221, Semantic loss: 0.000000, BCE loss: 1.040546, SB loss: nan
2025-01-03 18:14:05,535 Epoch: [2/20] Iter:[70/227], Time: 1.04, lr: [0.008954968575025186], Loss: nan, Acc:0.095865, Semantic loss: 0.000000, BCE loss: 1.020419, SB loss: nan
2025-01-03 18:14:13,730 Epoch: [2/20] Iter:[80/227], Time: 1.01, lr: [0.008934897668513376], Loss: nan, Acc:0.096558, Semantic loss: 0.000000, BCE loss: 1.019345, SB loss: nan
2025-01-03 18:14:21,890 Epoch: [2/20] Iter:[90/227], Time: 0.99, lr: [0.008914821751159398], Loss: nan, Acc:0.096897, Semantic loss: 0.000000, BCE loss: 1.034896, SB loss: nan
2025-01-03 18:14:30,027 Epoch: [2/20] Iter:[100/227], Time: 0.97, lr: [0.00889474080916789], Loss: nan, Acc:0.096755, Semantic loss: 0.000000, BCE loss: 1.027760, SB loss: nan
2025-01-03 18:14:38,432 Epoch: [2/20] Iter:[110/227], Time: 0.96, lr: [0.0088746548286708], Loss: nan, Acc:0.097510, Semantic loss: 0.000000, BCE loss: 1.026978, SB loss: nan
2025-01-03 18:14:46,640 Epoch: [2/20] Iter:[120/227], Time: 0.95, lr: [0.008854563795726814], Loss: nan, Acc:0.097896, Semantic loss: 0.000000, BCE loss: 1.019818, SB loss: nan
2025-01-03 18:14:54,822 Epoch: [2/20] Iter:[130/227], Time: 0.94, lr: [0.008834467696320793], Loss: nan, Acc:0.097719, Semantic loss: 0.000000, BCE loss: 1.017550, SB loss: nan
2025-01-03 18:15:02,944 Epoch: [2/20] Iter:[140/227], Time: 0.93, lr: [0.008814366516363192], Loss: nan, Acc:0.098282, Semantic loss: 0.000000, BCE loss: 1.006453, SB loss: nan
2025-01-03 18:15:11,147 Epoch: [2/20] Iter:[150/227], Time: 0.92, lr: [0.008794260241689474], Loss: nan, Acc:0.098471, Semantic loss: 0.000000, BCE loss: 1.013645, SB loss: nan
2025-01-03 18:15:19,408 Epoch: [2/20] Iter:[160/227], Time: 0.92, lr: [0.008774148858059518], Loss: nan, Acc:0.098548, Semantic loss: 0.000000, BCE loss: 1.014611, SB loss: nan
2025-01-03 18:15:27,650 Epoch: [2/20] Iter:[170/227], Time: 0.91, lr: [0.00875403235115702], Loss: nan, Acc:0.098398, Semantic loss: 0.000000, BCE loss: 1.013885, SB loss: nan
2025-01-03 18:15:35,788 Epoch: [2/20] Iter:[180/227], Time: 0.91, lr: [0.008733910706588898], Loss: nan, Acc:0.097848, Semantic loss: 0.000000, BCE loss: 1.016892, SB loss: nan
2025-01-03 18:15:44,031 Epoch: [2/20] Iter:[190/227], Time: 0.90, lr: [0.008713783909884674], Loss: nan, Acc:0.097460, Semantic loss: 0.000000, BCE loss: 1.017355, SB loss: nan
2025-01-03 18:15:52,155 Epoch: [2/20] Iter:[200/227], Time: 0.90, lr: [0.008693651946495864], Loss: nan, Acc:0.097174, Semantic loss: 0.000000, BCE loss: 1.014492, SB loss: nan
2025-01-03 18:16:00,189 Epoch: [2/20] Iter:[210/227], Time: 0.89, lr: [0.008673514801795358], Loss: nan, Acc:0.097753, Semantic loss: 0.000000, BCE loss: 1.010034, SB loss: nan
2025-01-03 18:16:08,138 Epoch: [2/20] Iter:[220/227], Time: 0.89, lr: [0.008653372461076773], Loss: nan, Acc:0.097842, Semantic loss: 0.000000, BCE loss: 1.001990, SB loss: nan
2025-01-03 18:16:13,392 NaN or Inf found in input tensor.
2025-01-03 18:19:18,936 0 [0.00000000e+00 4.16912712e-01 0.00000000e+00 5.42131634e-03
 1.05905282e-06 1.25414115e-02 1.15423596e-02 2.78259554e-03] 0.05615018171842487
2025-01-03 18:19:18,937 1 [0.         0.01050643 0.03310672 0.01735323 0.10209679 0.02587231
 0.01655392 0.01210207] 0.027198932920214157
2025-01-03 18:19:18,937 NaN or Inf found in input tensor.
2025-01-03 18:19:18,941 => saving checkpoint to output\loveDa\pidnet_small_lovedacheckpoint.pth.tar
2025-01-03 18:19:19,120 Loss: nan, MeanIU:  0.0272, Best_mIoU:  0.0272
2025-01-03 18:19:19,120 [0.         0.01050643 0.03310672 0.01735323 0.10209679 0.02587231
 0.01655392 0.01210207]
2025-01-03 18:19:35,765 Epoch: [3/20] Iter:[0/227], Time: 16.09, lr: [0.008639269723028191], Loss: nan, Acc:0.153394, Semantic loss: 0.000000, BCE loss: 0.989936, SB loss: nan
2025-01-03 18:19:44,537 Epoch: [3/20] Iter:[10/227], Time: 2.28, lr: [0.00861911851510129], Loss: nan, Acc:0.100629, Semantic loss: 0.000000, BCE loss: 1.013501, SB loss: nan
2025-01-03 18:19:52,544 Epoch: [3/20] Iter:[20/227], Time: 1.57, lr: [0.008598962071048205], Loss: nan, Acc:0.097665, Semantic loss: 0.000000, BCE loss: 0.926212, SB loss: nan
2025-01-03 18:20:00,583 Epoch: [3/20] Iter:[30/227], Time: 1.33, lr: [0.00857880037586372], Loss: nan, Acc:0.099854, Semantic loss: 0.000000, BCE loss: 0.903978, SB loss: nan
2025-01-03 18:20:08,580 Epoch: [3/20] Iter:[40/227], Time: 1.20, lr: [0.008558633414460315], Loss: nan, Acc:0.100166, Semantic loss: 0.000000, BCE loss: 0.913201, SB loss: nan
2025-01-03 18:20:16,832 Epoch: [3/20] Iter:[50/227], Time: 1.12, lr: [0.008538461171667492], Loss: nan, Acc:0.100802, Semantic loss: 0.000000, BCE loss: 0.954477, SB loss: nan
2025-01-03 18:20:24,909 Epoch: [3/20] Iter:[60/227], Time: 1.07, lr: [0.008518283632231104], Loss: nan, Acc:0.099234, Semantic loss: 0.000000, BCE loss: 0.973456, SB loss: nan
