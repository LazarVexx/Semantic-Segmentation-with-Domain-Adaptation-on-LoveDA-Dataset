2025-01-03 18:21:38,070 Namespace(cfg='configs/loveDa/pidnet_small_loveda.yaml', seed=304, opts=['GPUS', '[0]', 'TRAIN.BATCH_SIZE_PER_GPU', '6'])
2025-01-03 18:21:38,070 AUTO_RESUME: False
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  DATASET: loveDa
  EXTRA_TRAIN_SET: 
  NUM_CLASSES: 8
  ROOT: data/
  TEST_SET: list/loveDa/val.lst
  TRAIN_SET: list/loveDa/train.lst
GPUS: (0,)
LOG_DIR: log
LOSS:
  BALANCE_WEIGHTS: [0.4, 1.0]
  CLASS_BALANCE: False
  OHEMKEEP: 131072
  OHEMTHRES: 0.9
  SB_WEIGHTS: 1.0
  USE_OHEM: True
MODEL:
  ALIGN_CORNERS: True
  NAME: pidnet_small
  NUM_OUTPUTS: 2
  PRETRAINED: pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar
OUTPUT_DIR: output
PIN_MEMORY: True
PRINT_FREQ: 10
TEST:
  BASE_SIZE: 1024
  BATCH_SIZE_PER_GPU: 6
  FLIP_TEST: False
  IMAGE_SIZE: [1024, 1024]
  MODEL_FILE: 
  MULTI_SCALE: False
  OUTPUT_INDEX: 1
TRAIN:
  BASE_SIZE: 1024
  BATCH_SIZE_PER_GPU: 6
  BEGIN_EPOCH: 0
  END_EPOCH: 20
  EXTRA_EPOCH: 0
  EXTRA_LR: 0.001
  FLIP: True
  IGNORE_LABEL: 0
  IMAGE_SIZE: [1024, 1024]
  LR: 0.01
  MOMENTUM: 0.9
  MULTI_SCALE: True
  NESTEROV: False
  OPTIMIZER: sgd
  RESUME: False
  SCALE_FACTOR: 16
  SHUFFLE: True
  WD: 0.0005
WORKERS: 6
2025-01-03 18:21:38,253 Attention!!!
2025-01-03 18:21:38,253 Loaded 302 parameters!
2025-01-03 18:21:38,253 Over!!!
2025-01-03 18:21:58,302 Epoch: [0/20] Iter:[0/227], Time: 18.55, lr: [0.01], Loss: 2.237046, Acc:0.139805, Semantic loss: 0.000000, BCE loss: 2.237047, SB loss: -0.000001
2025-01-03 18:22:04,860 Epoch: [0/20] Iter:[10/227], Time: 2.26, lr: [0.009980174026451818], Loss: 1.746644, Acc:0.097022, Semantic loss: 0.000000, BCE loss: 1.746644, SB loss: 0.000000
2025-01-03 18:22:11,275 Epoch: [0/20] Iter:[20/227], Time: 1.49, lr: [0.009960343675822199], Loss: 1.410106, Acc:0.094106, Semantic loss: 0.000000, BCE loss: 1.410105, SB loss: 0.000000
2025-01-03 18:22:17,878 Epoch: [0/20] Iter:[30/227], Time: 1.22, lr: [0.009940508937457754], Loss: 1.255348, Acc:0.089760, Semantic loss: 0.000000, BCE loss: 1.255348, SB loss: 0.000000
2025-01-03 18:22:24,890 Epoch: [0/20] Iter:[40/227], Time: 1.09, lr: [0.009920669800655492], Loss: 1.201295, Acc:0.089180, Semantic loss: 0.000000, BCE loss: 1.201295, SB loss: 0.000000
2025-01-03 18:22:31,538 Epoch: [0/20] Iter:[50/227], Time: 1.01, lr: [0.009900826254662456], Loss: 1.152885, Acc:0.090386, Semantic loss: 0.000000, BCE loss: 1.152885, SB loss: 0.000000
2025-01-03 18:22:38,060 Epoch: [0/20] Iter:[60/227], Time: 0.95, lr: [0.009880978288675405], Loss: 1.128133, Acc:0.090789, Semantic loss: 0.000000, BCE loss: 1.128133, SB loss: 0.000000
2025-01-03 18:22:44,430 Epoch: [0/20] Iter:[70/227], Time: 0.91, lr: [0.009861125891840445], Loss: 1.120237, Acc:0.092529, Semantic loss: 0.000000, BCE loss: 1.120237, SB loss: 0.000000
2025-01-03 18:22:51,050 Epoch: [0/20] Iter:[80/227], Time: 0.88, lr: [0.009841269053252683], Loss: 1.110948, Acc:0.093335, Semantic loss: 0.000000, BCE loss: 1.110948, SB loss: 0.000000
2025-01-03 18:22:57,295 Epoch: [0/20] Iter:[90/227], Time: 0.85, lr: [0.00982140776195588], Loss: 1.110111, Acc:0.095050, Semantic loss: 0.000000, BCE loss: 1.110111, SB loss: 0.000000
2025-01-03 18:23:03,983 Epoch: [0/20] Iter:[100/227], Time: 0.83, lr: [0.009801542006942082], Loss: 1.096655, Acc:0.095749, Semantic loss: 0.000000, BCE loss: 1.096655, SB loss: 0.000000
2025-01-03 18:23:10,507 Epoch: [0/20] Iter:[110/227], Time: 0.81, lr: [0.009781671777151266], Loss: 1.081655, Acc:0.095743, Semantic loss: 0.000000, BCE loss: 1.081655, SB loss: 0.000000
2025-01-03 18:23:17,046 Epoch: [0/20] Iter:[120/227], Time: 0.80, lr: [0.009761797061470977], Loss: 1.067641, Acc:0.096467, Semantic loss: 0.000000, BCE loss: 1.067641, SB loss: 0.000000
2025-01-03 18:23:23,678 Epoch: [0/20] Iter:[130/227], Time: 0.79, lr: [0.009741917848735952], Loss: 1.060899, Acc:0.096158, Semantic loss: 0.000000, BCE loss: 1.060899, SB loss: 0.000000
2025-01-03 18:23:30,032 Epoch: [0/20] Iter:[140/227], Time: 0.78, lr: [0.009722034127727758], Loss: 1.053387, Acc:0.095933, Semantic loss: 0.000000, BCE loss: 1.053387, SB loss: 0.000000
2025-01-03 18:23:36,637 Epoch: [0/20] Iter:[150/227], Time: 0.77, lr: [0.009702145887174411], Loss: 1.044605, Acc:0.096551, Semantic loss: 0.000000, BCE loss: 1.044605, SB loss: 0.000000
2025-01-03 18:23:43,234 Epoch: [0/20] Iter:[160/227], Time: 0.77, lr: [0.009682253115750003], Loss: 1.046107, Acc:0.096532, Semantic loss: 0.000000, BCE loss: 1.046107, SB loss: 0.000000
2025-01-03 18:23:50,530 Epoch: [0/20] Iter:[170/227], Time: 0.76, lr: [0.009662355802074312], Loss: 1.052985, Acc:0.096908, Semantic loss: 0.000000, BCE loss: 1.052985, SB loss: 0.000000
2025-01-03 18:23:57,129 Epoch: [0/20] Iter:[180/227], Time: 0.76, lr: [0.00964245393471243], Loss: 1.050510, Acc:0.096787, Semantic loss: 0.000000, BCE loss: 1.050510, SB loss: 0.000000
2025-01-03 18:24:03,663 Epoch: [0/20] Iter:[190/227], Time: 0.75, lr: [0.009622547502174356], Loss: 1.047553, Acc:0.096790, Semantic loss: 0.000000, BCE loss: 1.047553, SB loss: 0.000000
2025-01-03 18:24:10,532 Epoch: [0/20] Iter:[200/227], Time: 0.75, lr: [0.009602636492914622], Loss: 1.039569, Acc:0.097043, Semantic loss: 0.000000, BCE loss: 1.039569, SB loss: 0.000000
2025-01-03 18:24:17,149 Epoch: [0/20] Iter:[210/227], Time: 0.74, lr: [0.009582720895331883], Loss: 1.034114, Acc:0.097351, Semantic loss: 0.000000, BCE loss: 1.034114, SB loss: 0.000000
2025-01-03 18:24:23,699 Epoch: [0/20] Iter:[220/227], Time: 0.74, lr: [0.009562800697768528], Loss: 1.029734, Acc:0.097333, Semantic loss: 0.000000, BCE loss: 1.029734, SB loss: 0.000000
2025-01-03 18:27:07,586 0 [0.00000000e+00 4.16912332e-01 0.00000000e+00 6.02712606e-03
 1.05905282e-06 1.25412099e-02 1.15435231e-02 1.85501908e-03] 0.056110033681829
2025-01-03 18:27:07,586 1 [0.         0.00713774 0.00396853 0.01546201 0.1125767  0.02413175
 0.0010079  0.0006809 ] 0.02062069217626209
2025-01-03 18:27:07,591 => saving checkpoint to output\loveDa\pidnet_small_lovedacheckpoint.pth.tar
2025-01-03 18:27:07,836 Loss: 1.049, MeanIU:  0.0206, Best_mIoU:  0.0206
2025-01-03 18:27:07,836 [0.         0.00713774 0.00396853 0.01546201 0.1125767  0.02413175
 0.0010079  0.0006809 ]
2025-01-03 18:27:23,515 Epoch: [1/20] Iter:[0/227], Time: 15.29, lr: [0.009548853816214998], Loss: 1.270606, Acc:0.087417, Semantic loss: 0.000000, BCE loss: 1.270606, SB loss: 0.000000
2025-01-03 18:27:30,602 Epoch: [1/20] Iter:[10/227], Time: 2.04, lr: [0.009528925771769746], Loss: 0.876536, Acc:0.093080, Semantic loss: 0.000000, BCE loss: 0.876536, SB loss: -0.000000
2025-01-03 18:27:37,751 Epoch: [1/20] Iter:[20/227], Time: 1.41, lr: [0.009508993095584064], Loss: 0.931413, Acc:0.096476, Semantic loss: 0.000000, BCE loss: 0.931413, SB loss: 0.000000
2025-01-03 18:27:44,875 Epoch: [1/20] Iter:[30/227], Time: 1.18, lr: [0.009489055775788591], Loss: 0.963197, Acc:0.101254, Semantic loss: 0.000000, BCE loss: 0.963197, SB loss: 0.000000
2025-01-03 18:27:52,030 Epoch: [1/20] Iter:[40/227], Time: 1.07, lr: [0.009469113800455762], Loss: 0.984147, Acc:0.099921, Semantic loss: 0.000000, BCE loss: 0.984147, SB loss: 0.000000
2025-01-03 18:27:59,167 Epoch: [1/20] Iter:[50/227], Time: 1.00, lr: [0.009449167157599386], Loss: 0.982417, Acc:0.099861, Semantic loss: 0.000000, BCE loss: 0.982417, SB loss: 0.000000
2025-01-03 18:28:06,300 Epoch: [1/20] Iter:[60/227], Time: 0.95, lr: [0.00942921583517422], Loss: 0.991323, Acc:0.099999, Semantic loss: 0.000000, BCE loss: 0.991323, SB loss: 0.000000
2025-01-03 18:28:13,493 Epoch: [1/20] Iter:[70/227], Time: 0.92, lr: [0.009409259821075532], Loss: nan, Acc:0.100990, Semantic loss: 0.000000, BCE loss: 0.987324, SB loss: nan
2025-01-03 18:28:20,672 Epoch: [1/20] Iter:[80/227], Time: 0.90, lr: [0.009389299103138684], Loss: nan, Acc:0.099384, Semantic loss: 0.000000, BCE loss: 0.980298, SB loss: nan
