2025-01-03 20:14:26,022 Namespace(cfg='configs/loveDa/pidnet_small_loveda.yaml', seed=304, opts=['GPUS', '[0]', 'TRAIN.BATCH_SIZE_PER_GPU', '6'])
2025-01-03 20:14:26,022 AUTO_RESUME: False
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  DATASET: loveDa
  EXTRA_TRAIN_SET: 
  NUM_CLASSES: 8
  ROOT: data/
  TEST_SET: list/loveDa/val.lst
  TRAIN_SET: list/loveDa/train.lst
GPUS: (0,)
LOG_DIR: log
LOSS:
  BALANCE_WEIGHTS: [0.4, 1.0]
  CLASS_BALANCE: False
  OHEMKEEP: 131072
  OHEMTHRES: 0.7
  SB_WEIGHTS: 0.5
  USE_OHEM: True
MODEL:
  ALIGN_CORNERS: True
  NAME: pidnet_small
  NUM_OUTPUTS: 2
  PRETRAINED: pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar
OUTPUT_DIR: output
PIN_MEMORY: True
PRINT_FREQ: 10
TEST:
  BASE_SIZE: 1024
  BATCH_SIZE_PER_GPU: 6
  FLIP_TEST: False
  IMAGE_SIZE: [1024, 1024]
  MODEL_FILE: 
  MULTI_SCALE: False
  OUTPUT_INDEX: 1
TRAIN:
  BASE_SIZE: 1024
  BATCH_SIZE_PER_GPU: 6
  BEGIN_EPOCH: 0
  END_EPOCH: 20
  EXTRA_EPOCH: 0
  EXTRA_LR: 0.001
  FLIP: True
  IGNORE_LABEL: 0
  IMAGE_SIZE: [1024, 1024]
  LR: 0.001
  MOMENTUM: 0.9
  MULTI_SCALE: True
  NESTEROV: False
  OPTIMIZER: sgd
  RESUME: False
  SCALE_FACTOR: 16
  SHUFFLE: True
  WD: 0.0005
WORKERS: 6
2025-01-03 20:14:26,179 Attention!!!
2025-01-03 20:14:26,179 Loaded 302 parameters!
2025-01-03 20:14:26,180 Over!!!
2025-01-03 20:14:46,756 Epoch: [0/20] Iter:[0/192], Time: 19.21, lr: [0.001], Loss: 2.769941, Acc:0.174582, Semantic loss: 0.000000, BCE loss: 2.769940, SB loss: 0.000001
2025-01-03 20:14:53,313 Epoch: [0/20] Iter:[10/192], Time: 2.32, lr: [0.0009976559445324194], Loss: 1.931287, Acc:0.155358, Semantic loss: 0.000000, BCE loss: 1.931287, SB loss: 0.000000
2025-01-03 20:14:59,684 Epoch: [0/20] Iter:[20/192], Time: 1.52, lr: [0.000995311276959276], Loss: 1.628409, Acc:0.149042, Semantic loss: 0.000000, BCE loss: 1.628409, SB loss: 0.000000
2025-01-03 20:15:06,216 Epoch: [0/20] Iter:[30/192], Time: 1.24, lr: [0.000992965995517728], Loss: 1.583004, Acc:0.152611, Semantic loss: 0.000000, BCE loss: 1.583004, SB loss: 0.000000
