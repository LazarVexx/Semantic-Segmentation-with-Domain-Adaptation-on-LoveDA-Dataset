2025-01-03 22:31:17,764 Namespace(cfg='configs/loveDa/pidnet_small_loveda.yaml', seed=304, opts=['GPUS', '[0]', 'TRAIN.BATCH_SIZE_PER_GPU', '6'])
2025-01-03 22:31:17,764 AUTO_RESUME: False
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  DATASET: loveDa
  EXTRA_TRAIN_SET: 
  NUM_CLASSES: 8
  ROOT: data/
  TEST_SET: list/loveDa/val.lst
  TRAIN_SET: list/loveDa/train.lst
GPUS: (0,)
LOG_DIR: log
LOSS:
  BALANCE_WEIGHTS: [0.4, 1.0]
  CLASS_BALANCE: False
  OHEMKEEP: 131072
  OHEMTHRES: 0.7
  SB_WEIGHTS: 0.5
  USE_OHEM: True
MODEL:
  ALIGN_CORNERS: True
  NAME: pidnet_small
  NUM_OUTPUTS: 2
  PRETRAINED: pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar
OUTPUT_DIR: output
PIN_MEMORY: True
PRINT_FREQ: 10
TEST:
  BASE_SIZE: 2048
  BATCH_SIZE_PER_GPU: 20
  FLIP_TEST: False
  IMAGE_SIZE: [1024, 1024]
  MODEL_FILE: 
  MULTI_SCALE: False
  OUTPUT_INDEX: 1
TRAIN:
  BASE_SIZE: 2048
  BATCH_SIZE_PER_GPU: 6
  BEGIN_EPOCH: 1
  END_EPOCH: 20
  EXTRA_EPOCH: 0
  EXTRA_LR: 0.001
  FLIP: True
  IGNORE_LABEL: 0
  IMAGE_SIZE: [1024, 1024]
  LR: 0.001
  MOMENTUM: 0.9
  MULTI_SCALE: True
  NESTEROV: False
  OPTIMIZER: sgd
  RESUME: False
  SCALE_FACTOR: 16
  SHUFFLE: True
  WD: 0.0005
WORKERS: 6
2025-01-03 22:31:17,919 Attention!!!
2025-01-03 22:31:17,919 Loaded 302 parameters!
2025-01-03 22:31:17,919 Over!!!
2025-01-03 22:31:57,435 Namespace(cfg='configs/loveDa/pidnet_small_loveda.yaml', seed=304, opts=['GPUS', '[0]', 'TRAIN.BATCH_SIZE_PER_GPU', '6'])
2025-01-03 22:31:57,436 AUTO_RESUME: False
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  DATASET: loveDa
  EXTRA_TRAIN_SET: 
  NUM_CLASSES: 8
  ROOT: data/
  TEST_SET: list/loveDa/val.lst
  TRAIN_SET: list/loveDa/train.lst
GPUS: (0,)
LOG_DIR: log
LOSS:
  BALANCE_WEIGHTS: [0.4, 1.0]
  CLASS_BALANCE: False
  OHEMKEEP: 131072
  OHEMTHRES: 0.7
  SB_WEIGHTS: 0.5
  USE_OHEM: True
MODEL:
  ALIGN_CORNERS: True
  NAME: pidnet_small
  NUM_OUTPUTS: 2
  PRETRAINED: pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar
OUTPUT_DIR: output
PIN_MEMORY: True
PRINT_FREQ: 10
TEST:
  BASE_SIZE: 2048
  BATCH_SIZE_PER_GPU: 20
  FLIP_TEST: False
  IMAGE_SIZE: [1024, 1024]
  MODEL_FILE: 
  MULTI_SCALE: False
  OUTPUT_INDEX: 1
TRAIN:
  BASE_SIZE: 2048
  BATCH_SIZE_PER_GPU: 6
  BEGIN_EPOCH: 1
  END_EPOCH: 20
  EXTRA_EPOCH: 0
  EXTRA_LR: 0.001
  FLIP: True
  IGNORE_LABEL: 0
  IMAGE_SIZE: [1024, 1024]
  LR: 0.001
  MOMENTUM: 0.9
  MULTI_SCALE: True
  NESTEROV: False
  OPTIMIZER: sgd
  RESUME: False
  SCALE_FACTOR: 16
  SHUFFLE: True
  WD: 0.0005
WORKERS: 0
2025-01-03 22:31:57,583 Attention!!!
2025-01-03 22:31:57,583 Loaded 302 parameters!
2025-01-03 22:31:57,583 Over!!!
2025-01-03 22:32:03,000 Epoch: [0/20] Iter:[0/192], Time: 4.10, lr: [0.001], Loss: 5.797045, Acc:0.132995, Semantic loss: 0.630270, BCE loss: 4.931381, SB loss: 0.235394
2025-01-03 22:32:13,560 Epoch: [0/20] Iter:[10/192], Time: 1.31, lr: [0.0009976559445324194], Loss: 4.429123, Acc:0.170966, Semantic loss: 0.609277, BCE loss: 3.593260, SB loss: 0.226587
2025-01-03 22:32:24,098 Epoch: [0/20] Iter:[20/192], Time: 1.19, lr: [0.000995311276959276], Loss: 4.010840, Acc:0.180011, Semantic loss: 0.595060, BCE loss: 3.195389, SB loss: 0.220391
2025-01-03 22:32:34,571 Epoch: [0/20] Iter:[30/192], Time: 1.14, lr: [0.000992965995517728], Loss: 3.745223, Acc:0.192929, Semantic loss: 0.578260, BCE loss: 2.955382, SB loss: 0.211581
2025-01-03 22:32:45,155 Epoch: [0/20] Iter:[40/192], Time: 1.12, lr: [0.0009906200984352155], Loss: 3.598925, Acc:0.209598, Semantic loss: 0.564021, BCE loss: 2.829023, SB loss: 0.205882
2025-01-03 22:32:55,713 Epoch: [0/20] Iter:[50/192], Time: 1.11, lr: [0.0009882735839293803], Loss: 3.430441, Acc:0.216474, Semantic loss: 0.554664, BCE loss: 2.675008, SB loss: 0.200768
2025-01-03 22:33:06,196 Epoch: [0/20] Iter:[60/192], Time: 1.10, lr: [0.000985926450207989], Loss: 3.323350, Acc:0.225082, Semantic loss: 0.545319, BCE loss: 2.582475, SB loss: 0.195556
2025-01-03 22:33:16,613 Epoch: [0/20] Iter:[70/192], Time: 1.09, lr: [0.0009835786954688485], Loss: 3.244320, Acc:0.235072, Semantic loss: 0.534872, BCE loss: 2.519108, SB loss: 0.190340
2025-01-03 22:33:26,900 Epoch: [0/20] Iter:[80/192], Time: 1.08, lr: [0.000981230317899726], Loss: 3.145162, Acc:0.244564, Semantic loss: 0.527664, BCE loss: 2.430385, SB loss: 0.187113
2025-01-03 22:33:37,485 Epoch: [0/20] Iter:[90/192], Time: 1.08, lr: [0.0009788813156782663], Loss: 3.094897, Acc:0.252561, Semantic loss: 0.520050, BCE loss: 2.391976, SB loss: 0.182871
2025-01-03 22:33:47,990 Epoch: [0/20] Iter:[100/192], Time: 1.08, lr: [0.0009765316869719068], Loss: 3.037330, Acc:0.258750, Semantic loss: 0.513295, BCE loss: 2.344362, SB loss: 0.179673
2025-01-03 22:33:58,504 Epoch: [0/20] Iter:[110/192], Time: 1.08, lr: [0.0009741814299377942], Loss: 2.972384, Acc:0.266249, Semantic loss: 0.504596, BCE loss: 2.291698, SB loss: 0.176090
2025-01-03 22:34:08,933 Epoch: [0/20] Iter:[120/192], Time: 1.07, lr: [0.0009718305427226986], Loss: 2.924389, Acc:0.270578, Semantic loss: 0.499604, BCE loss: 2.251705, SB loss: 0.173081
2025-01-03 22:34:19,175 Epoch: [0/20] Iter:[130/192], Time: 1.07, lr: [0.0009694790234629266], Loss: 2.869367, Acc:0.275673, Semantic loss: 0.492466, BCE loss: 2.206615, SB loss: 0.170285
2025-01-03 22:34:29,435 Epoch: [0/20] Iter:[140/192], Time: 1.07, lr: [0.0009671268702842339], Loss: 2.812093, Acc:0.283062, Semantic loss: 0.484769, BCE loss: 2.160146, SB loss: 0.167179
2025-01-03 22:34:39,516 Epoch: [0/20] Iter:[150/192], Time: 1.06, lr: [0.0009647740813017376], Loss: 2.783220, Acc:0.286792, Semantic loss: 0.481342, BCE loss: 2.136492, SB loss: 0.165385
2025-01-03 22:34:49,888 Epoch: [0/20] Iter:[160/192], Time: 1.06, lr: [0.0009624206546198262], Loss: 2.745278, Acc:0.290397, Semantic loss: 0.476543, BCE loss: 2.105499, SB loss: 0.163237
2025-01-03 22:35:00,351 Epoch: [0/20] Iter:[170/192], Time: 1.06, lr: [0.0009600665883320689], Loss: 2.714041, Acc:0.294322, Semantic loss: 0.471361, BCE loss: 2.081578, SB loss: 0.161102
2025-01-03 22:35:10,840 Epoch: [0/20] Iter:[180/192], Time: 1.06, lr: [0.0009577118805211255], Loss: 2.681056, Acc:0.297829, Semantic loss: 0.465503, BCE loss: 2.056637, SB loss: 0.158916
2025-01-03 22:35:21,180 Epoch: [0/20] Iter:[190/192], Time: 1.06, lr: [0.0009553565292586524], Loss: 2.641903, Acc:0.300837, Semantic loss: 0.460735, BCE loss: 2.023779, SB loss: 0.157388
2025-01-03 22:38:24,987 0 [0.         0.11151283 0.11483578 0.04215413 0.19437272 0.04543648
 0.11118925 0.03973088] 0.08240400889304714
2025-01-03 22:38:24,987 1 [0.         0.21281911 0.16584825 0.08020201 0.1663062  0.04800861
 0.10320546 0.01519539] 0.09894812897464048
2025-01-03 22:38:24,988 => saving checkpoint to output\loveDa\pidnet_small_lovedacheckpoint.pth.tar
2025-01-03 22:38:25,265 Loss: 2.270, MeanIU:  0.0989, Best_mIoU:  0.0989
2025-01-03 22:38:25,265 [0.         0.21281911 0.16584825 0.08020201 0.1663062  0.04800861
 0.10320546 0.01519539]
2025-01-03 22:38:26,339 Epoch: [1/20] Iter:[0/192], Time: 0.88, lr: [0.0009548853816214997], Loss: 2.568303, Acc:0.356639, Semantic loss: 0.370631, BCE loss: 2.086792, SB loss: 0.110880
2025-01-03 22:38:36,663 Epoch: [1/20] Iter:[10/192], Time: 1.02, lr: [0.0009525292556561478], Loss: 2.235260, Acc:0.355885, Semantic loss: 0.374936, BCE loss: 1.737057, SB loss: 0.123268
2025-01-03 22:38:47,106 Epoch: [1/20] Iter:[20/192], Time: 1.03, lr: [0.0009501724819577191], Loss: 2.139567, Acc:0.364126, Semantic loss: 0.368885, BCE loss: 1.649832, SB loss: 0.120850
2025-01-03 22:38:57,574 Epoch: [1/20] Iter:[30/192], Time: 1.04, lr: [0.0009478150585620286], Loss: 2.072224, Acc:0.374049, Semantic loss: 0.364059, BCE loss: 1.587448, SB loss: 0.120717
