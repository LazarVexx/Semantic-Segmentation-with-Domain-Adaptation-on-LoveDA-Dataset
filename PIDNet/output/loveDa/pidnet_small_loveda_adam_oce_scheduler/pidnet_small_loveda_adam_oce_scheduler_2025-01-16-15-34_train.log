2025-01-16 15:34:24,120 Namespace(cfg='configs/loveDa/pidnet_small_loveda_adam_oce_scheduler.yaml', seed=304, opts=['GPUS', '[0]', 'TRAIN.BATCH_SIZE_PER_GPU', '6'])
2025-01-16 15:34:24,121 AUTO_RESUME: False
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  DATASET: loveDa
  EXTRA_TRAIN_SET: 
  NUM_CLASSES: 8
  ROOT: data/
  SOURCE_DATASET: loveDA-Urban
  SOURCE_TEST_SET: list/loveDA-Urban/val.lst
  SOURCE_TRAIN_SET: list/loveDA-Urban/train.lst
  TARGET_DATASET: loveDA-Rural
  TARGET_SET: list/cityscapes/val.lst
  TARGET_TEST_SET: list/loveDA-Rural/val.lst
  TARGET_TRAIN_SET: list/loveDA-Rural/train.lst
  TEST_SET: list/loveDa/val.lst
  TRAIN_SET: list/loveDa/train.lst
GPUS: (0,)
LOG_DIR: log
LOSS:
  BALANCE_WEIGHTS: [0.4, 1.0]
  CLASS_BALANCE: False
  OHEMKEEP: 131072
  OHEMTHRES: 0.7
  SB_WEIGHTS: 0.5
  USE_DICE: False
  USE_FOCAL: False
  USE_OHEM: True
MODEL:
  ALIGN_CORNERS: True
  NAME: pidnet_small
  NUM_OUTPUTS: 2
  PRETRAINED: pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar
OUTPUT_DIR: output
PIN_MEMORY: True
PRINT_FREQ: 10
TEST:
  BASE_SIZE: 2048
  BATCH_SIZE_PER_GPU: 20
  FLIP_TEST: False
  IMAGE_SIZE: [1024, 1024]
  MODEL_FILE: 
  MULTI_SCALE: False
  OUTPUT_INDEX: 1
TRAIN:
  ADVERSARIAL: False
  AUG: False
  AUG1: True
  AUG2: False
  AUG3: False
  AUG4: False
  AUG_CHANCE: True
  BASE_SIZE: 1440
  BATCH_SIZE_PER_GPU: 6
  BEGIN_EPOCH: 1
  END_EPOCH: 20
  EVAL_INTERVAL: 1
  EXTRA_EPOCH: 0
  EXTRA_LR: 0.001
  FLIP: True
  GAN: Vanilla
  IGNORE_LABEL: 0
  IMAGE_SIZE: [240, 240]
  LAMBDA_ADVT1: 0.001
  LAMBDA_ADVT2: 0.001
  LR: 0.001
  LR_D1: 0.001
  LR_D2: 0.001
  MOMENTUM: 0.9
  MULTI_SCALE: True
  NESTEROV: False
  OPTIMIZER: adam
  RESUME: False
  SCALE_FACTOR: 16
  SCHEDULER: True
  SHUFFLE: True
  WD: 0.0005
WORKERS: 0
2025-01-16 15:34:24,284 Attention!!!
2025-01-16 15:34:24,284 Loaded 302 parameters!
2025-01-16 15:34:24,284 Over!!!
2025-01-16 15:34:27,857 Epoch: [0/20] Iter:[0/292], Time: 1.91, lr: [0.0002], Loss: 6.128951, Acc:0.191942, Semantic loss: 0.623779, BCE loss: 5.295149, SB loss: 0.210022, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:34:32,610 Epoch: [0/20] Iter:[10/292], Time: 0.61, lr: [0.00019969175441670646], Loss: 5.321043, Acc:0.210503, Semantic loss: 0.565043, BCE loss: 4.569542, SB loss: 0.186458, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:34:37,409 Epoch: [0/20] Iter:[20/292], Time: 0.55, lr: [0.00019938345595653812], Loss: 4.410263, Acc:0.238738, Semantic loss: 0.530011, BCE loss: 3.712936, SB loss: 0.167317, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:34:42,173 Epoch: [0/20] Iter:[30/292], Time: 0.52, lr: [0.00019907510451954731], Loss: 4.162234, Acc:0.244843, Semantic loss: 0.509791, BCE loss: 3.495727, SB loss: 0.156716, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:34:46,963 Epoch: [0/20] Iter:[40/292], Time: 0.51, lr: [0.00019876670000542487], Loss: 3.947273, Acc:0.243911, Semantic loss: 0.492689, BCE loss: 3.305539, SB loss: 0.149044, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:34:51,764 Epoch: [0/20] Iter:[50/292], Time: 0.51, lr: [0.00019845824231349852], Loss: 3.878542, Acc:0.249076, Semantic loss: 0.480296, BCE loss: 3.253785, SB loss: 0.144462, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:34:56,649 Epoch: [0/20] Iter:[60/292], Time: 0.50, lr: [0.0001981497313427308], Loss: 3.779444, Acc:0.264122, Semantic loss: 0.459082, BCE loss: 3.183698, SB loss: 0.136663, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:35:01,520 Epoch: [0/20] Iter:[70/292], Time: 0.50, lr: [0.00019784116699171706], Loss: 3.601788, Acc:0.273397, Semantic loss: 0.446488, BCE loss: 3.022295, SB loss: 0.133005, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:35:06,254 Epoch: [0/20] Iter:[80/292], Time: 0.50, lr: [0.0001975325491586837], Loss: 3.482886, Acc:0.278927, Semantic loss: 0.434174, BCE loss: 2.919139, SB loss: 0.129572, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:35:11,315 Epoch: [0/20] Iter:[90/292], Time: 0.50, lr: [0.00019722387774148586], Loss: 3.397026, Acc:0.286754, Semantic loss: 0.424292, BCE loss: 2.846391, SB loss: 0.126343, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:35:16,244 Epoch: [0/20] Iter:[100/292], Time: 0.50, lr: [0.00019691515263760577], Loss: 3.325622, Acc:0.294824, Semantic loss: 0.413850, BCE loss: 2.788554, SB loss: 0.123218, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:35:20,962 Epoch: [0/20] Iter:[110/292], Time: 0.50, lr: [0.00019660637374415042], Loss: 3.276028, Acc:0.302042, Semantic loss: 0.406675, BCE loss: 2.749100, SB loss: 0.120254, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:35:25,702 Epoch: [0/20] Iter:[120/292], Time: 0.49, lr: [0.00019629754095784978], Loss: 3.203989, Acc:0.307276, Semantic loss: 0.396702, BCE loss: 2.690273, SB loss: 0.117014, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:35:30,422 Epoch: [0/20] Iter:[130/292], Time: 0.49, lr: [0.00019598865417505453], Loss: 3.128384, Acc:0.308754, Semantic loss: 0.388793, BCE loss: 2.624782, SB loss: 0.114808, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:35:35,163 Epoch: [0/20] Iter:[140/292], Time: 0.49, lr: [0.00019567971329173425], Loss: 3.072898, Acc:0.314541, Semantic loss: 0.381693, BCE loss: 2.578463, SB loss: 0.112741, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:35:39,870 Epoch: [0/20] Iter:[150/292], Time: 0.49, lr: [0.0001953707182034751], Loss: 3.017301, Acc:0.319441, Semantic loss: 0.374359, BCE loss: 2.532570, SB loss: 0.110372, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:35:44,470 Epoch: [0/20] Iter:[160/292], Time: 0.49, lr: [0.00019506166880547797], Loss: 2.962394, Acc:0.326814, Semantic loss: 0.365724, BCE loss: 2.489189, SB loss: 0.107481, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:35:49,219 Epoch: [0/20] Iter:[170/292], Time: 0.49, lr: [0.0001947525649925561], Loss: 2.939574, Acc:0.328930, Semantic loss: 0.361192, BCE loss: 2.472018, SB loss: 0.106364, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:35:54,015 Epoch: [0/20] Iter:[180/292], Time: 0.49, lr: [0.00019444340665913324], Loss: 2.903032, Acc:0.334396, Semantic loss: 0.355259, BCE loss: 2.443155, SB loss: 0.104618, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:35:58,530 Epoch: [0/20] Iter:[190/292], Time: 0.48, lr: [0.00019413419369924132], Loss: 2.843422, Acc:0.339135, Semantic loss: 0.347689, BCE loss: 2.393189, SB loss: 0.102544, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:36:03,086 Epoch: [0/20] Iter:[200/292], Time: 0.48, lr: [0.00019382492600651845], Loss: 2.814879, Acc:0.343028, Semantic loss: 0.342703, BCE loss: 2.370845, SB loss: 0.101331, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:36:07,677 Epoch: [0/20] Iter:[210/292], Time: 0.48, lr: [0.00019351560347420662], Loss: 2.791490, Acc:0.346325, Semantic loss: 0.337467, BCE loss: 2.353913, SB loss: 0.100110, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:36:12,437 Epoch: [0/20] Iter:[220/292], Time: 0.48, lr: [0.0001932062259951495], Loss: 2.754523, Acc:0.349032, Semantic loss: 0.332695, BCE loss: 2.323197, SB loss: 0.098631, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:36:17,225 Epoch: [0/20] Iter:[230/292], Time: 0.48, lr: [0.00019289679346179048], Loss: 2.716978, Acc:0.351691, Semantic loss: 0.328814, BCE loss: 2.290897, SB loss: 0.097267, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:36:21,963 Epoch: [0/20] Iter:[240/292], Time: 0.48, lr: [0.0001925873057661702], Loss: 2.699371, Acc:0.354788, Semantic loss: 0.324841, BCE loss: 2.278082, SB loss: 0.096448, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:36:26,521 Epoch: [0/20] Iter:[250/292], Time: 0.48, lr: [0.0001922777627999244], Loss: 2.666434, Acc:0.357121, Semantic loss: 0.321696, BCE loss: 2.249492, SB loss: 0.095246, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:36:31,095 Epoch: [0/20] Iter:[260/292], Time: 0.48, lr: [0.00019196816445428175], Loss: 2.643640, Acc:0.360924, Semantic loss: 0.317489, BCE loss: 2.232068, SB loss: 0.094083, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:36:35,711 Epoch: [0/20] Iter:[270/292], Time: 0.48, lr: [0.00019165851062006144], Loss: 2.614623, Acc:0.364710, Semantic loss: 0.312792, BCE loss: 2.209150, SB loss: 0.092682, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:36:40,172 Epoch: [0/20] Iter:[280/292], Time: 0.48, lr: [0.00019134880118767112], Loss: 2.581450, Acc:0.367241, Semantic loss: 0.309088, BCE loss: 2.180733, SB loss: 0.091630, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:36:44,838 Epoch: [0/20] Iter:[290/292], Time: 0.48, lr: [0.00019103903604710435], Loss: 2.557555, Acc:0.369446, Semantic loss: 0.306364, BCE loss: 2.160217, SB loss: 0.090974, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
