2025-01-16 15:37:29,859 Namespace(cfg='configs/loveDa/pidnet_small_loveda_adam_oce_scheduler.yaml', seed=304, opts=['GPUS', '[0]', 'TRAIN.BATCH_SIZE_PER_GPU', '6'])
2025-01-16 15:37:29,860 AUTO_RESUME: False
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  DATASET: loveDa
  EXTRA_TRAIN_SET: 
  NUM_CLASSES: 8
  ROOT: data/
  SOURCE_DATASET: loveDA-Urban
  SOURCE_TEST_SET: list/loveDA-Urban/val.lst
  SOURCE_TRAIN_SET: list/loveDA-Urban/train.lst
  TARGET_DATASET: loveDA-Rural
  TARGET_SET: list/cityscapes/val.lst
  TARGET_TEST_SET: list/loveDA-Rural/val.lst
  TARGET_TRAIN_SET: list/loveDA-Rural/train.lst
  TEST_SET: list/loveDa/val.lst
  TRAIN_SET: list/loveDa/train.lst
GPUS: (0,)
LOG_DIR: log
LOSS:
  BALANCE_WEIGHTS: [0.4, 1.0]
  CLASS_BALANCE: False
  OHEMKEEP: 131072
  OHEMTHRES: 0.7
  SB_WEIGHTS: 0.5
  USE_DICE: False
  USE_FOCAL: False
  USE_OHEM: True
MODEL:
  ALIGN_CORNERS: True
  NAME: pidnet_small
  NUM_OUTPUTS: 2
  PRETRAINED: pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar
OUTPUT_DIR: output
PIN_MEMORY: True
PRINT_FREQ: 10
TEST:
  BASE_SIZE: 2048
  BATCH_SIZE_PER_GPU: 20
  FLIP_TEST: False
  IMAGE_SIZE: [1024, 1024]
  MODEL_FILE: 
  MULTI_SCALE: False
  OUTPUT_INDEX: 1
TRAIN:
  ADVERSARIAL: False
  AUG: False
  AUG1: True
  AUG2: False
  AUG3: False
  AUG4: False
  AUG_CHANCE: True
  BASE_SIZE: 1440
  BATCH_SIZE_PER_GPU: 6
  BEGIN_EPOCH: 1
  END_EPOCH: 20
  EVAL_INTERVAL: 1
  EXTRA_EPOCH: 0
  EXTRA_LR: 0.001
  FLIP: True
  GAN: Vanilla
  IGNORE_LABEL: 0
  IMAGE_SIZE: [240, 240]
  LAMBDA_ADVT1: 0.001
  LAMBDA_ADVT2: 0.001
  LR: 0.001
  LR_D1: 0.001
  LR_D2: 0.001
  MOMENTUM: 0.9
  MULTI_SCALE: True
  NESTEROV: False
  OPTIMIZER: adam
  RESUME: False
  SCALE_FACTOR: 16
  SCHEDULER: True
  SHUFFLE: True
  WD: 0.0005
WORKERS: 0
2025-01-16 15:37:30,073 Attention!!!
2025-01-16 15:37:30,073 Loaded 302 parameters!
2025-01-16 15:37:30,073 Over!!!
2025-01-16 15:37:33,724 Epoch: [0/20] Iter:[0/286], Time: 1.78, lr: [0.0002], Loss: 3.595226, Acc:0.108869, Semantic loss: 0.647459, BCE loss: 2.725625, SB loss: 0.222143, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:37:38,052 Epoch: [0/20] Iter:[10/286], Time: 0.55, lr: [0.00019968528716020792], Loss: 4.110330, Acc:0.173882, Semantic loss: 0.588934, BCE loss: 3.334666, SB loss: 0.186730, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:37:42,506 Epoch: [0/20] Iter:[20/286], Time: 0.50, lr: [0.00019937051919947566], Loss: 4.009900, Acc:0.212459, Semantic loss: 0.552552, BCE loss: 3.288020, SB loss: 0.169327, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:37:46,628 Epoch: [0/20] Iter:[30/286], Time: 0.47, lr: [0.00019905569601142006], Loss: 3.818236, Acc:0.230864, Semantic loss: 0.521304, BCE loss: 3.138720, SB loss: 0.158213, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:37:51,076 Epoch: [0/20] Iter:[40/286], Time: 0.47, lr: [0.00019874081748926526], Loss: 3.712330, Acc:0.237284, Semantic loss: 0.494704, BCE loss: 3.065387, SB loss: 0.152238, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:37:55,503 Epoch: [0/20] Iter:[50/286], Time: 0.46, lr: [0.00019842588352584058], Loss: 3.578271, Acc:0.257075, Semantic loss: 0.474020, BCE loss: 2.959363, SB loss: 0.144888, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:38:00,048 Epoch: [0/20] Iter:[60/286], Time: 0.46, lr: [0.00019811089401357843], Loss: 3.563603, Acc:0.265806, Semantic loss: 0.465635, BCE loss: 2.955253, SB loss: 0.142715, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:38:04,538 Epoch: [0/20] Iter:[70/286], Time: 0.46, lr: [0.00019779584884451205], Loss: 3.376038, Acc:0.271840, Semantic loss: 0.450706, BCE loss: 2.787248, SB loss: 0.138083, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:38:08,759 Epoch: [0/20] Iter:[80/286], Time: 0.45, lr: [0.00019748074791027339], Loss: 3.291894, Acc:0.280704, Semantic loss: 0.437026, BCE loss: 2.721276, SB loss: 0.133592, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:38:13,160 Epoch: [0/20] Iter:[90/286], Time: 0.45, lr: [0.00019716559110209074], Loss: 3.193082, Acc:0.283201, Semantic loss: 0.426017, BCE loss: 2.637668, SB loss: 0.129397, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:38:17,608 Epoch: [0/20] Iter:[100/286], Time: 0.45, lr: [0.00019685037831078682], Loss: 3.160721, Acc:0.288377, Semantic loss: 0.415952, BCE loss: 2.618270, SB loss: 0.126499, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:38:22,121 Epoch: [0/20] Iter:[110/286], Time: 0.45, lr: [0.00019653510942677625], Loss: 3.136876, Acc:0.289934, Semantic loss: 0.407231, BCE loss: 2.604988, SB loss: 0.124657, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:38:26,549 Epoch: [0/20] Iter:[120/286], Time: 0.45, lr: [0.00019621978434006338], Loss: 3.057317, Acc:0.296437, Semantic loss: 0.397530, BCE loss: 2.537899, SB loss: 0.121889, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:38:31,057 Epoch: [0/20] Iter:[130/286], Time: 0.45, lr: [0.00019590440294024007], Loss: 2.978093, Acc:0.302223, Semantic loss: 0.388122, BCE loss: 2.471332, SB loss: 0.118639, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:38:35,478 Epoch: [0/20] Iter:[140/286], Time: 0.45, lr: [0.00019558896511648338], Loss: 2.930393, Acc:0.310310, Semantic loss: 0.380501, BCE loss: 2.433793, SB loss: 0.116099, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:38:39,821 Epoch: [0/20] Iter:[150/286], Time: 0.45, lr: [0.00019527347075755326], Loss: 2.900154, Acc:0.315655, Semantic loss: 0.374326, BCE loss: 2.412400, SB loss: 0.113427, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:38:44,204 Epoch: [0/20] Iter:[160/286], Time: 0.45, lr: [0.00019495791975179016], Loss: 2.854036, Acc:0.319132, Semantic loss: 0.366438, BCE loss: 2.376386, SB loss: 0.111212, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:38:48,485 Epoch: [0/20] Iter:[170/286], Time: 0.45, lr: [0.0001946423119871129], Loss: 2.818882, Acc:0.323439, Semantic loss: 0.361505, BCE loss: 2.347596, SB loss: 0.109781, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:38:53,024 Epoch: [0/20] Iter:[180/286], Time: 0.45, lr: [0.000194326647351016], Loss: 2.776852, Acc:0.327505, Semantic loss: 0.354188, BCE loss: 2.315054, SB loss: 0.107611, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:38:57,333 Epoch: [0/20] Iter:[190/286], Time: 0.45, lr: [0.00019401092573056758], Loss: 2.731757, Acc:0.331681, Semantic loss: 0.349217, BCE loss: 2.276672, SB loss: 0.105868, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:39:01,647 Epoch: [0/20] Iter:[200/286], Time: 0.45, lr: [0.00019369514701240685], Loss: 2.703765, Acc:0.335189, Semantic loss: 0.344817, BCE loss: 2.254738, SB loss: 0.104210, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:39:06,038 Epoch: [0/20] Iter:[210/286], Time: 0.45, lr: [0.00019337931108274169], Loss: 2.678224, Acc:0.337848, Semantic loss: 0.338957, BCE loss: 2.236811, SB loss: 0.102455, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:39:10,414 Epoch: [0/20] Iter:[220/286], Time: 0.45, lr: [0.00019306341782734628], Loss: 2.643958, Acc:0.342533, Semantic loss: 0.333881, BCE loss: 2.209103, SB loss: 0.100975, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:39:15,006 Epoch: [0/20] Iter:[230/286], Time: 0.45, lr: [0.0001927474671315586], Loss: 2.621160, Acc:0.348178, Semantic loss: 0.329560, BCE loss: 2.192145, SB loss: 0.099456, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:39:19,397 Epoch: [0/20] Iter:[240/286], Time: 0.45, lr: [0.00019243145888027797], Loss: 2.590748, Acc:0.353575, Semantic loss: 0.324890, BCE loss: 2.167908, SB loss: 0.097949, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:39:23,735 Epoch: [0/20] Iter:[250/286], Time: 0.45, lr: [0.0001921153929579627], Loss: 2.562016, Acc:0.357088, Semantic loss: 0.320794, BCE loss: 2.144604, SB loss: 0.096618, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:39:28,114 Epoch: [0/20] Iter:[260/286], Time: 0.45, lr: [0.0001917992692486273], Loss: 2.541191, Acc:0.361478, Semantic loss: 0.316197, BCE loss: 2.129658, SB loss: 0.095335, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:39:32,536 Epoch: [0/20] Iter:[270/286], Time: 0.44, lr: [0.00019148308763584034], Loss: 2.526706, Acc:0.363492, Semantic loss: 0.313035, BCE loss: 2.119479, SB loss: 0.094192, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
2025-01-16 15:39:37,043 Epoch: [0/20] Iter:[280/286], Time: 0.45, lr: [0.00019116684800272153], Loss: 2.508894, Acc:0.365425, Semantic loss: 0.309912, BCE loss: 2.105770, SB loss: 0.093211, NumParams: 7718097.000000 M, FLOPs: 8.557687 GFLOPS
