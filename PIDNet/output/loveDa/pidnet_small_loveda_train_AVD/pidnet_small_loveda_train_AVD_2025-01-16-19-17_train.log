2025-01-16 19:17:12,845 Namespace(cfg='configs/loveDa/pidnet_small_loveda_train_AVD.yaml', seed=304, opts=['GPUS', '[0]', 'TRAIN.BATCH_SIZE_PER_GPU', '6'])
2025-01-16 19:17:12,845 AUTO_RESUME: False
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  DATASET: loveDa
  EXTRA_TRAIN_SET: 
  NUM_CLASSES: 8
  ROOT: data/
  SOURCE_DATASET: loveDA-Urban
  SOURCE_TEST_SET: list/loveDA-Urban/val.lst
  SOURCE_TRAIN_SET: list/loveDA-Urban/train.lst
  TARGET_DATASET: loveDA-Rural
  TARGET_SET: list/loveDa/target.lst
  TARGET_TEST_SET: list/loveDA-Rural/val.lst
  TARGET_TRAIN_SET: list/loveDA-Rural/train.lst
  TEST_SET: list/loveDa-Rural/val.lst
  TRAIN_SET: list/loveDa/train.lst
GPUS: (0,)
LOG_DIR: log
LOSS:
  BALANCE_WEIGHTS: [0.4, 1.0]
  CLASS_BALANCE: False
  OHEMKEEP: 131072
  OHEMTHRES: 0.9
  SB_WEIGHTS: 1.0
  USE_DICE: False
  USE_FOCAL: False
  USE_OHEM: True
MODEL:
  ALIGN_CORNERS: True
  NAME: pidnet_small
  NUM_OUTPUTS: 2
  PRETRAINED: pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar
OUTPUT_DIR: output
PIN_MEMORY: True
PRINT_FREQ: 10
TEST:
  BASE_SIZE: 2048
  BATCH_SIZE_PER_GPU: 6
  FLIP_TEST: False
  IMAGE_SIZE: [1024, 1024]
  MODEL_FILE: 
  MULTI_SCALE: False
  OUTPUT_INDEX: 1
TRAIN:
  ADVERSARIAL: True
  AUG: False
  AUG1: False
  AUG2: False
  AUG3: False
  AUG4: False
  AUG_CHANCE: False
  BASE_SIZE: 1440
  BATCH_SIZE_PER_GPU: 6
  BEGIN_EPOCH: 0
  END_EPOCH: 20
  EVAL_INTERVAL: 1
  EXTRA_EPOCH: 0
  EXTRA_LR: 0.001
  FLIP: True
  GAN: Vanilla
  IGNORE_LABEL: 255
  IMAGE_SIZE: [720, 720]
  LAMBDA_ADV: 0.001
  LR: 0.01
  LR_D1: 0.01
  MOMENTUM: 0.9
  MULTI_SCALE: True
  NESTEROV: False
  OPTIMIZER: sgd
  RESUME: False
  SCALE_FACTOR: 16
  SCHEDULER: False
  SHUFFLE: True
  WD: 0.0005
WORKERS: 0
2025-01-16 19:17:13,087 Attention!!!
2025-01-16 19:17:13,087 Loaded 302 parameters!
2025-01-16 19:17:13,087 Over!!!
2025-01-16 19:17:19,400 Epoch: [0/20] Iter:[0/192], Time: 6.10, lr: [0.01], Loss: 12.405970, Loss_D: 0.693161, Acc:0.161567, Semantic loss: 0.593688
2025-01-16 19:17:34,680 Epoch: [0/20] Iter:[10/192], Time: 13.64, lr: [0.009976559445324192], Loss: 690.575153, Loss_D: 425.121552, Acc:0.230709, Semantic loss: 0.509922
2025-01-16 19:17:50,587 Epoch: [0/20] Iter:[20/192], Time: 21.49, lr: [0.009953112769592761], Loss: 405.326472, Loss_D: 134.093857, Acc:0.276222, Semantic loss: 0.472231
2025-01-16 19:18:05,881 Epoch: [0/20] Iter:[30/192], Time: 29.28, lr: [0.009929659955177281], Loss: 296.386389, Loss_D: 32.403397, Acc:0.306371, Semantic loss: 0.447621
2025-01-16 19:18:21,372 Epoch: [0/20] Iter:[40/192], Time: 37.03, lr: [0.009906200984352154], Loss: 231.061844, Loss_D: 63.263058, Acc:0.331399, Semantic loss: 0.423941
2025-01-16 19:18:37,635 Epoch: [0/20] Iter:[50/192], Time: 44.87, lr: [0.009882735839293803], Loss: 191.355757, Loss_D: 40.759598, Acc:0.344419, Semantic loss: 0.398785
2025-01-16 19:18:52,544 Epoch: [0/20] Iter:[60/192], Time: 52.67, lr: [0.00985926450207989], Loss: 173.633328, Loss_D: 119.360413, Acc:0.352032, Semantic loss: 0.380363
2025-01-16 19:19:06,844 Epoch: [0/20] Iter:[70/192], Time: 60.33, lr: [0.009835786954688485], Loss: 160.302020, Loss_D: 62.700314, Acc:0.360494, Semantic loss: 0.365587
2025-01-16 19:19:20,696 Epoch: [0/20] Iter:[80/192], Time: 67.82, lr: [0.00981230317899726], Loss: 143.171178, Loss_D: 28.858805, Acc:0.370085, Semantic loss: 0.352221
2025-01-16 19:19:35,293 Epoch: [0/20] Iter:[90/192], Time: 75.24, lr: [0.009788813156782662], Loss: 129.897653, Loss_D: 13.363439, Acc:0.376630, Semantic loss: 0.339443
2025-01-16 19:19:49,970 Epoch: [0/20] Iter:[100/192], Time: 82.65, lr: [0.009765316869719067], Loss: 118.424955, Loss_D: 6.113063, Acc:0.382243, Semantic loss: 0.329585
2025-01-16 19:20:04,946 Epoch: [0/20] Iter:[110/192], Time: 90.04, lr: [0.009741814299377942], Loss: 108.354106, Loss_D: 2.811979, Acc:0.386726, Semantic loss: 0.321075
2025-01-16 19:20:19,374 Epoch: [0/20] Iter:[120/192], Time: 97.43, lr: [0.009718305427226986], Loss: 99.713625, Loss_D: 1.633478, Acc:0.392957, Semantic loss: 0.313134
2025-01-16 19:20:33,818 Epoch: [0/20] Iter:[130/192], Time: 104.80, lr: [0.009694790234629266], Loss: 92.315915, Loss_D: 1.118667, Acc:0.398806, Semantic loss: 0.305329
2025-01-16 19:20:48,397 Epoch: [0/20] Iter:[140/192], Time: 112.15, lr: [0.009671268702842338], Loss: 85.966066, Loss_D: 0.901096, Acc:0.402801, Semantic loss: 0.299650
2025-01-16 19:21:03,494 Epoch: [0/20] Iter:[150/192], Time: 119.51, lr: [0.009647740813017376], Loss: 80.450310, Loss_D: 0.715473, Acc:0.408813, Semantic loss: 0.292962
2025-01-16 19:21:17,897 Epoch: [0/20] Iter:[160/192], Time: 126.88, lr: [0.009624206546198262], Loss: 75.612784, Loss_D: 0.846486, Acc:0.413079, Semantic loss: 0.286743
2025-01-16 19:21:32,255 Epoch: [0/20] Iter:[170/192], Time: 134.22, lr: [0.009600665883320689], Loss: 71.339974, Loss_D: 0.678398, Acc:0.415621, Semantic loss: 0.281952
2025-01-16 19:21:46,577 Epoch: [0/20] Iter:[180/192], Time: 141.55, lr: [0.009577118805211254], Loss: 67.554240, Loss_D: 0.684231, Acc:0.420022, Semantic loss: 0.276943
2025-01-16 19:22:01,078 Epoch: [0/20] Iter:[190/192], Time: 148.85, lr: [0.009553565292586523], Loss: 64.156207, Loss_D: 0.807277, Acc:0.424121, Semantic loss: 0.272878
2025-01-16 19:25:25,366 0 [0.         0.33712487 0.08708129 0.04802835 0.24137856 0.04455738
 0.0442665  0.00182184] 0.10053234691642673
2025-01-16 19:25:25,366 1 [0.         0.32751249 0.09373077 0.03252316 0.07934013 0.0762279
 0.00777625 0.00057583] 0.0772108159262356
2025-01-16 19:25:25,367 => saving checkpoint to output\loveDa\pidnet_small_loveda_train_AVDcheckpoint.pth.tar
2025-01-16 19:25:25,549 Loss: 1.542, MeanIU:  0.0772, Best_mIoU:  0.0772
2025-01-16 19:25:25,549 [0.         0.32751249 0.09373077 0.03252316 0.07934013 0.0762279
 0.00777625 0.00057583]
2025-01-16 19:25:27,153 Epoch: [1/20] Iter:[0/192], Time: 1.50, lr: [0.009548853816214998], Loss: 1.717920, Loss_D: 0.693581, Acc:0.620112, Semantic loss: 0.167724
