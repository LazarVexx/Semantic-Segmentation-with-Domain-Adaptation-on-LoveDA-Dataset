2025-01-16 22:46:45,537 Namespace(cfg='configs/loveDa/pidnet_small_loveda_train_AVD.yaml', seed=304, opts=['GPUS', '[0]', 'TRAIN.BATCH_SIZE_PER_GPU', '6'])
2025-01-16 22:46:45,538 AUTO_RESUME: False
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  DATASET: loveDa
  EXTRA_TRAIN_SET: 
  NUM_CLASSES: 8
  ROOT: data/
  SOURCE_DATASET: loveDA-Urban
  SOURCE_TEST_SET: list/loveDA-Urban/val.lst
  SOURCE_TRAIN_SET: list/loveDA-Urban/train.lst
  TARGET_DATASET: loveDA-Rural
  TARGET_SET: list/loveDa/target.lst
  TARGET_TEST_SET: list/loveDA-Rural/val.lst
  TARGET_TRAIN_SET: list/loveDA-Rural/train.lst
  TEST_SET: list/loveDa-Rural/val.lst
  TRAIN_SET: list/loveDa/train.lst
GPUS: (0,)
LOG_DIR: log
LOSS:
  BALANCE_WEIGHTS: [0.4, 1.0]
  CLASS_BALANCE: False
  OHEMKEEP: 131072
  OHEMTHRES: 0.9
  SB_WEIGHTS: 1.0
  USE_DICE: False
  USE_FOCAL: False
  USE_OHEM: True
MODEL:
  ALIGN_CORNERS: True
  NAME: pidnet_small
  NUM_OUTPUTS: 3
  PRETRAINED: pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar
OUTPUT_DIR: output
PIN_MEMORY: True
PRINT_FREQ: 10
TEST:
  BASE_SIZE: 2048
  BATCH_SIZE_PER_GPU: 6
  FLIP_TEST: False
  IMAGE_SIZE: [1024, 1024]
  MODEL_FILE: 
  MULTI_SCALE: False
  OUTPUT_INDEX: 1
TRAIN:
  ADVERSARIAL: True
  AUG: False
  AUG1: False
  AUG2: False
  AUG3: False
  AUG4: False
  AUG_CHANCE: False
  BASE_SIZE: 1440
  BATCH_SIZE_PER_GPU: 6
  BEGIN_EPOCH: 0
  END_EPOCH: 20
  EVAL_INTERVAL: 1
  EXTRA_EPOCH: 0
  EXTRA_LR: 0.001
  FLIP: True
  GAN: LS
  IGNORE_LABEL: 255
  IMAGE_SIZE: [720, 720]
  LAMBDA_ADV1: 0.001
  LAMBDA_ADV2: 0.0001
  LR: 0.01
  LR_D1: 0.01
  LR_D2: 0.01
  MOMENTUM: 0.9
  MULTI_SCALE: True
  NESTEROV: False
  OPTIMIZER: sgd
  RESUME: False
  SCALE_FACTOR: 16
  SCHEDULER: False
  SHUFFLE: True
  WD: 0.0005
WORKERS: 0
2025-01-16 22:46:45,738 Attention!!!
2025-01-16 22:46:45,739 Loaded 302 parameters!
2025-01-16 22:46:45,739 Over!!!
2025-01-16 22:46:51,771 Epoch: [0/20] Iter:[0/192], Time: 5.83, lr: [0.01], Loss: 4.083586, Loss_D1: 0.986847, Loss_D2: 1.010613, Acc:0.150185, Semantic loss: 0.594664
2025-01-16 22:47:09,226 Epoch: [0/20] Iter:[10/192], Time: 14.41, lr: [0.009976559445324192], Loss: 3.810119, Loss_D1: 2182253.500000, Loss_D2: 435644.250000, Acc:0.199821, Semantic loss: 0.540414
2025-01-16 22:47:26,478 Epoch: [0/20] Iter:[20/192], Time: 23.06, lr: [0.009953112769592761], Loss: 3.227944, Loss_D1: 26243116.000000, Loss_D2: 19146804.000000, Acc:0.248480, Semantic loss: 0.492668
2025-01-16 22:47:43,187 Epoch: [0/20] Iter:[30/192], Time: 31.60, lr: [0.009929659955177281], Loss: 2.990968, Loss_D1: 62049904.000000, Loss_D2: 68558440.000000, Acc:0.283835, Semantic loss: 0.455515
2025-01-16 22:48:00,369 Epoch: [0/20] Iter:[40/192], Time: 40.11, lr: [0.009906200984352154], Loss: 2.818869, Loss_D1: 14108893.000000, Loss_D2: 2295.238037, Acc:0.310161, Semantic loss: 0.423615
2025-01-16 22:48:17,511 Epoch: [0/20] Iter:[50/192], Time: 48.67, lr: [0.009882735839293803], Loss: 2.684686, Loss_D1: 882788.187500, Loss_D2: 188131.125000, Acc:0.332695, Semantic loss: 0.403336
2025-01-16 22:48:34,130 Epoch: [0/20] Iter:[60/192], Time: 57.18, lr: [0.00985926450207989], Loss: 2.577307, Loss_D1: 302892.250000, Loss_D2: 284016.250000, Acc:0.341287, Semantic loss: 0.384035
2025-01-16 22:48:50,313 Epoch: [0/20] Iter:[70/192], Time: 65.58, lr: [0.009835786954688485], Loss: 2.505900, Loss_D1: 82031.640625, Loss_D2: 125006.812500, Acc:0.353805, Semantic loss: 0.367619
2025-01-16 22:49:06,358 Epoch: [0/20] Iter:[80/192], Time: 73.92, lr: [0.00981230317899726], Loss: 2.445018, Loss_D1: 53451.085938, Loss_D2: 49734.984375, Acc:0.362661, Semantic loss: 0.353128
2025-01-16 22:49:22,691 Epoch: [0/20] Iter:[90/192], Time: 82.19, lr: [0.009788813156782662], Loss: 2.371749, Loss_D1: 9590.761719, Loss_D2: 4021.585449, Acc:0.373281, Semantic loss: 0.339496
2025-01-16 22:49:38,914 Epoch: [0/20] Iter:[100/192], Time: 90.44, lr: [0.009765316869719067], Loss: 2.337257, Loss_D1: 10967.296875, Loss_D2: 26965.867188, Acc:0.383139, Semantic loss: 0.327852
2025-01-16 22:49:55,081 Epoch: [0/20] Iter:[110/192], Time: 98.67, lr: [0.009741814299377942], Loss: 2.293017, Loss_D1: 3828.344238, Loss_D2: 2899.731689, Acc:0.389817, Semantic loss: 0.319483
2025-01-16 22:50:11,473 Epoch: [0/20] Iter:[120/192], Time: 106.88, lr: [0.009718305427226986], Loss: 2.247806, Loss_D1: 2205.069092, Loss_D2: 4520.339355, Acc:0.394876, Semantic loss: 0.311096
2025-01-16 22:50:27,561 Epoch: [0/20] Iter:[130/192], Time: 115.06, lr: [0.009694790234629266], Loss: 2.211845, Loss_D1: 751.697266, Loss_D2: 1945.509033, Acc:0.399627, Semantic loss: 0.304074
2025-01-16 22:50:44,151 Epoch: [0/20] Iter:[140/192], Time: 123.26, lr: [0.009671268702842338], Loss: 2.175970, Loss_D1: 564.019226, Loss_D2: 542.965393, Acc:0.402021, Semantic loss: 0.298062
2025-01-16 22:51:00,864 Epoch: [0/20] Iter:[150/192], Time: 131.47, lr: [0.009647740813017376], Loss: 2.158132, Loss_D1: 457.633850, Loss_D2: 4190.493652, Acc:0.406285, Semantic loss: 0.293329
2025-01-16 22:51:17,572 Epoch: [0/20] Iter:[160/192], Time: 139.71, lr: [0.009624206546198262], Loss: 2.157541, Loss_D1: 270.916626, Loss_D2: 908.106079, Acc:0.410613, Semantic loss: 0.287572
2025-01-16 22:51:34,582 Epoch: [0/20] Iter:[170/192], Time: 147.96, lr: [0.009600665883320689], Loss: 2.130002, Loss_D1: 534.174866, Loss_D2: 410.318542, Acc:0.413578, Semantic loss: 0.283579
2025-01-16 22:51:51,597 Epoch: [0/20] Iter:[180/192], Time: 156.24, lr: [0.009577118805211254], Loss: 2.124965, Loss_D1: 372.952301, Loss_D2: 8032.923828, Acc:0.415671, Semantic loss: 0.279360
2025-01-16 22:52:08,480 Epoch: [0/20] Iter:[190/192], Time: 164.54, lr: [0.009553565292586523], Loss: 2.115394, Loss_D1: 262.731171, Loss_D2: 954.860657, Acc:0.420465, Semantic loss: 0.274154
2025-01-16 22:56:27,837 0 [0.         0.30038786 0.08779339 0.0268355  0.17674852 0.02002821
 0.05761294 0.00635033] 0.08446959339630014
2025-01-16 22:56:27,837 1 [0.         0.35127578 0.13725291 0.04539073 0.06131793 0.00152698
 0.03753035 0.00127486] 0.07944619216747191
2025-01-16 22:56:27,838 2 [0.         0.09431711 0.02963997 0.02691807 0.09392178 0.03296579
 0.0420257  0.11301242] 0.054100103100058035
2025-01-16 22:56:27,838 => saving checkpoint to output\loveDa\pidnet_small_loveda_train_AVDcheckpoint.pth.tar
2025-01-16 22:56:28,028 Loss: 1.457, MeanIU:  0.0541, Best_mIoU:  0.0541
2025-01-16 22:56:28,029 [0.         0.09431711 0.02963997 0.02691807 0.09392178 0.03296579
 0.0420257  0.11301242]
2025-01-16 22:56:29,685 Epoch: [1/20] Iter:[0/192], Time: 1.29, lr: [0.009548853816214998], Loss: 1.591499, Loss_D1: 272.488190, Loss_D2: 33158.527344, Acc:0.447952, Semantic loss: 0.157242
