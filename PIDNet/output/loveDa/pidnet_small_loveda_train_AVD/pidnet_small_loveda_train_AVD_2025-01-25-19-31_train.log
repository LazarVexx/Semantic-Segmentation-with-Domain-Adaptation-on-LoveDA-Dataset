2025-01-25 19:31:35,690 Namespace(cfg='configs/loveDa/pidnet_small_loveda_train_AVD.yaml', seed=304, opts=['GPUS', '[0]', 'TRAIN.BATCH_SIZE_PER_GPU', '6'])
2025-01-25 19:31:35,690 AUTO_RESUME: False
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  DATASET: loveDa
  EXTRA_TRAIN_SET: 
  NUM_CLASSES: 8
  ROOT: data/
  SOURCE_DATASET: loveDA-Urban
  SOURCE_TEST_SET: list/loveDA-Urban/val.lst
  SOURCE_TRAIN_SET: list/loveDA-Urban/train.lst
  TARGET_DATASET: loveDA-Rural
  TARGET_SET: list/loveDa-Rural/train.lst
  TARGET_TEST_SET: list/loveDA-Rural/val.lst
  TARGET_TRAIN_SET: list/loveDA-Rural/train.lst
  TEST_SET: list/loveDa-Rural/val.lst
  TRAIN_SET: list/loveDa/train.lst
GPUS: (0,)
LOG_DIR: log
LOSS:
  BALANCE_WEIGHTS: [0.4, 1.0]
  CLASS_BALANCE: False
  OHEMKEEP: 131072
  OHEMTHRES: 0.7
  SB_WEIGHTS: 0.5
  USE_DICE: False
  USE_FOCAL: False
  USE_OHEM: True
MODEL:
  ALIGN_CORNERS: True
  NAME: pidnet_small
  NUM_OUTPUTS: 2
  PRETRAINED: pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar
OUTPUT_DIR: output
PIN_MEMORY: True
PRINT_FREQ: 10
TEST:
  BASE_SIZE: 1024
  BATCH_SIZE_PER_GPU: 6
  FLIP_TEST: False
  IMAGE_SIZE: [1024, 1024]
  MODEL_FILE: 
  MULTI_SCALE: False
  OUTPUT_INDEX: 1
TRAIN:
  ADVERSARIAL: True
  AUG: True
  AUG1: False
  AUG2: True
  AUG3: True
  AUG4: False
  AUG_CHANCE: True
  BASE_SIZE: 720
  BATCH_SIZE_PER_GPU: 6
  BEGIN_EPOCH: 0
  D1: False
  END_EPOCH: 20
  EVAL_INTERVAL: 1
  EXTRA_EPOCH: 0
  EXTRA_LR: 0.001
  FLIP: True
  GAN: Vanilla
  IGNORE_LABEL: 0
  IMAGE_SIZE: [720, 720]
  LAMBDA_ADV1: 0.001
  LAMBDA_ADV2: 0.0002
  LR: 0.001
  LR_D1: 0.0001
  LR_D2: 0.0001
  MOMENTUM: 0.9
  MULTI_SCALE: True
  NESTEROV: False
  OPTIMIZER: adam
  RESUME: False
  SCALE_FACTOR: 16
  SCHEDULER: True
  SHUFFLE: True
  WD: 0.0005
WORKERS: 0
2025-01-25 19:31:35,898 Attention!!!
2025-01-25 19:31:35,898 Loaded 302 parameters!
2025-01-25 19:31:35,898 Over!!!
2025-01-25 19:31:42,113 Epoch: [0/20] Iter:[0/291], Time: 5.98, lr: [0.0002], Loss: 5.800584, Loss_D1: 0.693144, Loss_D2: 0.693264, Acc:0.132449, Semantic loss: 0.651724
2025-01-25 19:32:01,702 Epoch: [0/20] Iter:[10/291], Time: 2.33, lr: [0.0001996906950624248], Loss: 3.684671, Loss_D1: 0.691885, Loss_D2: 0.693465, Acc:0.218691, Semantic loss: 0.494176
2025-01-25 19:32:19,276 Epoch: [0/20] Iter:[20/291], Time: 2.06, lr: [0.00019938133688359008], Loss: 3.222534, Loss_D1: 0.692277, Loss_D2: 0.691281, Acc:0.252627, Semantic loss: 0.434716
2025-01-25 19:32:36,801 Epoch: [0/20] Iter:[30/291], Time: 1.96, lr: [0.00019907192536251225], Loss: 2.857924, Loss_D1: 0.688931, Loss_D2: 0.692345, Acc:0.276268, Semantic loss: 0.398802
2025-01-25 19:32:54,236 Epoch: [0/20] Iter:[40/291], Time: 1.91, lr: [0.00019876246039784136], Loss: 2.662507, Loss_D1: 0.696264, Loss_D2: 0.692282, Acc:0.296069, Semantic loss: 0.368359
2025-01-25 19:33:11,843 Epoch: [0/20] Iter:[50/291], Time: 1.88, lr: [0.0001984529418878593], Loss: 2.512240, Loss_D1: 0.676698, Loss_D2: 0.691765, Acc:0.311022, Semantic loss: 0.346910
2025-01-25 19:33:29,323 Epoch: [0/20] Iter:[60/291], Time: 1.86, lr: [0.00019814336973047764], Loss: 2.368818, Loss_D1: 0.688152, Loss_D2: 0.693719, Acc:0.325080, Semantic loss: 0.326136
2025-01-25 19:33:46,832 Epoch: [0/20] Iter:[70/291], Time: 1.84, lr: [0.00019783374382323577], Loss: 2.301358, Loss_D1: 0.705943, Loss_D2: 0.692728, Acc:0.334959, Semantic loss: 0.312118
2025-01-25 19:34:04,533 Epoch: [0/20] Iter:[80/291], Time: 1.83, lr: [0.00019752406406329883], Loss: 2.225148, Loss_D1: 0.705020, Loss_D2: 0.693085, Acc:0.346964, Semantic loss: 0.297195
2025-01-25 19:34:22,227 Epoch: [0/20] Iter:[90/291], Time: 1.83, lr: [0.00019721433034745566], Loss: 2.135658, Loss_D1: 0.691549, Loss_D2: 0.694008, Acc:0.358998, Semantic loss: 0.285019
2025-01-25 19:34:39,777 Epoch: [0/20] Iter:[100/291], Time: 1.82, lr: [0.00019690454257211687], Loss: 2.092832, Loss_D1: 0.697325, Loss_D2: 0.689604, Acc:0.368698, Semantic loss: 0.277455
2025-01-25 19:34:57,504 Epoch: [0/20] Iter:[110/291], Time: 1.81, lr: [0.00019659470063331273], Loss: 2.039259, Loss_D1: 0.698833, Loss_D2: 0.695285, Acc:0.376495, Semantic loss: 0.267812
2025-01-25 19:35:14,907 Epoch: [0/20] Iter:[120/291], Time: 1.81, lr: [0.00019628480442669102], Loss: 1.987985, Loss_D1: 0.674934, Loss_D2: 0.696181, Acc:0.379811, Semantic loss: 0.260035
2025-01-25 19:35:32,673 Epoch: [0/20] Iter:[130/291], Time: 1.81, lr: [0.0001959748538475151], Loss: 1.960442, Loss_D1: 0.680285, Loss_D2: 0.693706, Acc:0.388206, Semantic loss: 0.253891
2025-01-25 19:35:50,309 Epoch: [0/20] Iter:[140/291], Time: 1.80, lr: [0.0001956648487906617], Loss: 1.927004, Loss_D1: 0.637530, Loss_D2: 0.690251, Acc:0.390613, Semantic loss: 0.249989
2025-01-25 19:36:07,771 Epoch: [0/20] Iter:[150/291], Time: 1.80, lr: [0.0001953547891506189], Loss: 1.894311, Loss_D1: 0.705539, Loss_D2: 0.693554, Acc:0.393722, Semantic loss: 0.244525
2025-01-25 19:36:25,203 Epoch: [0/20] Iter:[160/291], Time: 1.80, lr: [0.00019504467482148394], Loss: 1.888926, Loss_D1: 0.674006, Loss_D2: 0.693838, Acc:0.397375, Semantic loss: 0.241635
2025-01-25 19:36:43,005 Epoch: [0/20] Iter:[170/291], Time: 1.79, lr: [0.00019473450569696107], Loss: 1.865946, Loss_D1: 0.682162, Loss_D2: 0.694147, Acc:0.400196, Semantic loss: 0.237234
2025-01-25 19:37:00,333 Epoch: [0/20] Iter:[180/291], Time: 1.79, lr: [0.00019442428167035952], Loss: 1.844977, Loss_D1: 0.691613, Loss_D2: 0.693219, Acc:0.403253, Semantic loss: 0.234353
2025-01-25 19:37:17,800 Epoch: [0/20] Iter:[190/291], Time: 1.79, lr: [0.00019411400263459106], Loss: 1.825323, Loss_D1: 0.647686, Loss_D2: 0.692971, Acc:0.409929, Semantic loss: 0.230549
2025-01-25 19:37:35,312 Epoch: [0/20] Iter:[200/291], Time: 1.79, lr: [0.0001938036684821682], Loss: 1.820661, Loss_D1: 0.684941, Loss_D2: 0.692763, Acc:0.414962, Semantic loss: 0.228552
2025-01-25 19:37:53,019 Epoch: [0/20] Iter:[210/291], Time: 1.79, lr: [0.00019349327910520156], Loss: 1.805246, Loss_D1: 0.664810, Loss_D2: 0.693680, Acc:0.417642, Semantic loss: 0.225179
2025-01-25 19:38:10,618 Epoch: [0/20] Iter:[220/291], Time: 1.79, lr: [0.000193182834395398], Loss: 1.796459, Loss_D1: 0.723379, Loss_D2: 0.692480, Acc:0.420437, Semantic loss: 0.223631
2025-01-25 19:38:28,083 Epoch: [0/20] Iter:[230/291], Time: 1.78, lr: [0.0001928723342440582], Loss: 1.782777, Loss_D1: 0.647963, Loss_D2: 0.693419, Acc:0.421594, Semantic loss: 0.221465
2025-01-25 19:38:45,486 Epoch: [0/20] Iter:[240/291], Time: 1.78, lr: [0.00019256177854207442], Loss: 1.762399, Loss_D1: 0.700120, Loss_D2: 0.693077, Acc:0.423255, Semantic loss: 0.219361
2025-01-25 19:39:03,042 Epoch: [0/20] Iter:[250/291], Time: 1.78, lr: [0.00019225116717992832], Loss: 1.749972, Loss_D1: 0.680016, Loss_D2: 0.693118, Acc:0.426877, Semantic loss: 0.216833
2025-01-25 19:39:20,702 Epoch: [0/20] Iter:[260/291], Time: 1.78, lr: [0.00019194050004768857], Loss: 1.735302, Loss_D1: 0.632716, Loss_D2: 0.693249, Acc:0.428774, Semantic loss: 0.214825
2025-01-25 19:39:38,142 Epoch: [0/20] Iter:[270/291], Time: 1.78, lr: [0.00019162977703500862], Loss: 1.725658, Loss_D1: 0.627734, Loss_D2: 0.692826, Acc:0.431032, Semantic loss: 0.213079
2025-01-25 19:39:55,501 Epoch: [0/20] Iter:[280/291], Time: 1.78, lr: [0.00019131899803112435], Loss: 1.711761, Loss_D1: 0.623167, Loss_D2: 0.692801, Acc:0.431867, Semantic loss: 0.210679
2025-01-25 19:40:13,093 Epoch: [0/20] Iter:[290/291], Time: 1.78, lr: [0.00019100816292485175], Loss: 1.701468, Loss_D1: 0.652624, Loss_D2: 0.691996, Acc:0.432269, Semantic loss: 0.209066
2025-01-25 19:45:41,379 0 [0.         0.43966384 0.13037656 0.05440665 0.1440909  0.14550368
 0.05509141 0.00360407] 0.13896244309573635
2025-01-25 19:45:41,380 1 [0.00000000e+00 4.58614996e-01 1.20310987e-01 1.30133482e-01
 2.22524467e-01 1.26652555e-01 1.01208079e-02 4.01796267e-04] 0.15267987025003094
2025-01-25 19:45:41,381 => saving checkpoint to output\loveDa\pidnet_small_loveda_train_AVDcheckpoint.pth.tar
2025-01-25 19:45:41,626 Loss: 1.278, MeanIU:  0.1527, Best_mIoU:  0.1527
2025-01-25 19:45:41,626 [0.00000000e+00 4.58614996e-01 1.20310987e-01 1.30133482e-01
 2.22524467e-01 1.26652555e-01 1.01208079e-02 4.01796267e-04]
2025-01-25 19:45:43,358 Epoch: [1/20] Iter:[0/291], Time: 1.73, lr: [0.0003819541526485999], Loss: 2.135898, Loss_D1: 0.638017, Loss_D2: 0.693117, Acc:0.595873, Semantic loss: 0.138937
2025-01-25 19:46:03,663 Epoch: [1/20] Iter:[10/291], Time: 2.00, lr: [0.0003813323587529572], Loss: 1.306377, Loss_D1: 0.642407, Loss_D2: 0.694755, Acc:0.472823, Semantic loss: 0.157655
