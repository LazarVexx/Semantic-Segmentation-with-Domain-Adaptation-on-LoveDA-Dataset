2025-01-25 21:08:34,348 Namespace(cfg='configs/loveDa/pidnet_small_loveda_train_AVD.yaml', seed=304, opts=['GPUS', '[0]', 'TRAIN.BATCH_SIZE_PER_GPU', '6'])
2025-01-25 21:08:34,349 AUTO_RESUME: False
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  DATASET: loveDa
  EXTRA_TRAIN_SET: 
  NUM_CLASSES: 8
  ROOT: data/
  SOURCE_DATASET: loveDA-Urban
  SOURCE_TEST_SET: list/loveDA-Urban/val.lst
  SOURCE_TRAIN_SET: list/loveDA-Urban/train.lst
  TARGET_DATASET: loveDA-Rural
  TARGET_SET: list/loveDa-Rural/train.lst
  TARGET_TEST_SET: list/loveDA-Rural/val.lst
  TARGET_TRAIN_SET: list/loveDA-Rural/train.lst
  TEST_SET: list/loveDa-Rural/val.lst
  TRAIN_SET: list/loveDa/train.lst
GPUS: (0,)
LOG_DIR: log
LOSS:
  BALANCE_WEIGHTS: [0.4, 1.0]
  CLASS_BALANCE: False
  OHEMKEEP: 131072
  OHEMTHRES: 0.7
  SB_WEIGHTS: 0.5
  USE_DICE: False
  USE_FOCAL: False
  USE_OHEM: True
MODEL:
  ALIGN_CORNERS: True
  NAME: pidnet_small
  NUM_OUTPUTS: 2
  PRETRAINED: pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar
OUTPUT_DIR: output
PIN_MEMORY: True
PRINT_FREQ: 10
TEST:
  BASE_SIZE: 1024
  BATCH_SIZE_PER_GPU: 6
  FLIP_TEST: False
  IMAGE_SIZE: [1024, 1024]
  MODEL_FILE: 
  MULTI_SCALE: False
  OUTPUT_INDEX: 1
TRAIN:
  ADVERSARIAL: True
  AUG: True
  AUG1: False
  AUG2: True
  AUG3: True
  AUG4: False
  AUG_CHANCE: True
  BASE_SIZE: 720
  BATCH_SIZE_PER_GPU: 6
  BEGIN_EPOCH: 0
  D1: False
  END_EPOCH: 20
  EVAL_INTERVAL: 1
  EXTRA_EPOCH: 0
  EXTRA_LR: 0.001
  FLIP: True
  GAN: Vanilla
  IGNORE_LABEL: 0
  IMAGE_SIZE: [720, 720]
  LAMBDA_ADV1: 0.001
  LAMBDA_ADV2: 0.0002
  LR: 0.001
  LR_D1: 0.0001
  LR_D2: 0.0001
  MOMENTUM: 0.9
  MULTI_SCALE: True
  NESTEROV: False
  OPTIMIZER: adam
  RESUME: False
  SCALE_FACTOR: 16
  SCHEDULER: True
  SHUFFLE: True
  WD: 0.0005
WORKERS: 0
2025-01-25 21:08:34,622 Attention!!!
2025-01-25 21:08:34,622 Loaded 302 parameters!
2025-01-25 21:08:34,622 Over!!!
2025-01-25 21:08:43,110 Epoch: [0/20] Iter:[0/288], Time: 8.18, lr: [0.0002], Loss: 5.699933, Loss_D1: 0.693147, Loss_D2: 0.693264, Acc:0.122089, Semantic loss: 0.685400
2025-01-25 21:09:18,389 Epoch: [0/20] Iter:[10/288], Time: 3.95, lr: [0.00019968747285597994], Loss: 3.503087, Loss_D1: 0.693597, Loss_D2: 0.693459, Acc:0.222293, Semantic loss: 0.503134
2025-01-25 21:09:52,651 Epoch: [0/20] Iter:[20/288], Time: 3.70, lr: [0.0001993748913546578], Loss: 2.969734, Loss_D1: 0.693834, Loss_D2: 0.691361, Acc:0.278837, Semantic loss: 0.430352
2025-01-25 21:10:23,218 Epoch: [0/20] Iter:[30/288], Time: 3.49, lr: [0.00019906225539185522], Loss: 2.699288, Loss_D1: 0.688133, Loss_D2: 0.692299, Acc:0.301542, Semantic loss: 0.386774
2025-01-25 21:10:54,705 Epoch: [0/20] Iter:[40/288], Time: 3.41, lr: [0.00019874956486301223], Loss: 2.462956, Loss_D1: 0.693094, Loss_D2: 0.692647, Acc:0.310851, Semantic loss: 0.361850
2025-01-25 21:11:24,987 Epoch: [0/20] Iter:[50/288], Time: 3.34, lr: [0.00019843681966318484], Loss: 2.323070, Loss_D1: 0.692704, Loss_D2: 0.692207, Acc:0.329975, Semantic loss: 0.340458
2025-01-25 21:11:54,571 Epoch: [0/20] Iter:[60/288], Time: 3.27, lr: [0.00019812401968704308], Loss: 2.196673, Loss_D1: 0.692443, Loss_D2: 0.693762, Acc:0.335795, Semantic loss: 0.319380
2025-01-25 21:12:24,899 Epoch: [0/20] Iter:[70/288], Time: 3.24, lr: [0.0001978111648288689], Loss: 2.102105, Loss_D1: 0.691746, Loss_D2: 0.692863, Acc:0.345496, Semantic loss: 0.301522
2025-01-25 21:12:59,091 Epoch: [0/20] Iter:[80/288], Time: 3.26, lr: [0.000197498254982554], Loss: 2.052903, Loss_D1: 0.692484, Loss_D2: 0.693098, Acc:0.357685, Semantic loss: 0.288472
2025-01-25 21:13:31,146 Epoch: [0/20] Iter:[90/288], Time: 3.26, lr: [0.0001971852900415978], Loss: 2.006983, Loss_D1: 0.707995, Loss_D2: 0.693685, Acc:0.369728, Semantic loss: 0.275278
2025-01-25 21:14:04,118 Epoch: [0/20] Iter:[100/288], Time: 3.26, lr: [0.00019687226989910522], Loss: 1.957567, Loss_D1: 0.694005, Loss_D2: 0.690568, Acc:0.377767, Semantic loss: 0.265575
2025-01-25 21:14:33,213 Epoch: [0/20] Iter:[110/288], Time: 3.23, lr: [0.00019655919444778455], Loss: 1.903834, Loss_D1: 0.700867, Loss_D2: 0.694637, Acc:0.382338, Semantic loss: 0.257135
2025-01-25 21:15:08,263 Epoch: [0/20] Iter:[120/288], Time: 3.25, lr: [0.0001962460635799452], Loss: 1.866561, Loss_D1: 0.699952, Loss_D2: 0.695359, Acc:0.388825, Semantic loss: 0.250024
2025-01-25 21:15:41,361 Epoch: [0/20] Iter:[130/288], Time: 3.26, lr: [0.00019593287718749566], Loss: 1.841631, Loss_D1: 0.705464, Loss_D2: 0.693394, Acc:0.395390, Semantic loss: 0.244489
2025-01-25 21:16:14,509 Epoch: [0/20] Iter:[140/288], Time: 3.26, lr: [0.0001956196351619411], Loss: 1.825569, Loss_D1: 0.688724, Loss_D2: 0.691276, Acc:0.399245, Semantic loss: 0.240075
2025-01-25 21:16:50,288 Epoch: [0/20] Iter:[150/288], Time: 3.28, lr: [0.00019530633739438136], Loss: 1.792588, Loss_D1: 0.673113, Loss_D2: 0.693462, Acc:0.400319, Semantic loss: 0.235628
2025-01-25 21:17:22,289 Epoch: [0/20] Iter:[160/288], Time: 3.28, lr: [0.00019499298377550846], Loss: 1.780158, Loss_D1: 0.689155, Loss_D2: 0.693455, Acc:0.403154, Semantic loss: 0.232908
