2025-01-25 23:00:30,271 Namespace(cfg='configs/loveDa/pidnet_small_loveda_train_AVD.yaml', seed=304, opts=['GPUS', '[0]', 'TRAIN.BATCH_SIZE_PER_GPU', '6'])
2025-01-25 23:00:30,272 AUTO_RESUME: False
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  DATASET: loveDa
  EXTRA_TRAIN_SET: 
  NUM_CLASSES: 8
  ROOT: data/
  SOURCE_DATASET: loveDA-Urban
  SOURCE_TEST_SET: list/loveDA-Urban/val.lst
  SOURCE_TRAIN_SET: list/loveDA-Urban/train.lst
  TARGET_DATASET: loveDA-Rural
  TARGET_SET: list/loveDa-Rural/train.lst
  TARGET_TEST_SET: list/loveDA-Rural/val.lst
  TARGET_TRAIN_SET: list/loveDA-Rural/train.lst
  TEST_SET: list/loveDa-Rural/val.lst
  TRAIN_SET: list/loveDa/train.lst
GPUS: (0,)
LOG_DIR: log
LOSS:
  BALANCE_WEIGHTS: [0.4, 1.0]
  CLASS_BALANCE: False
  OHEMKEEP: 131072
  OHEMTHRES: 0.7
  SB_WEIGHTS: 0.5
  USE_DICE: False
  USE_FOCAL: False
  USE_OHEM: True
MODEL:
  ALIGN_CORNERS: True
  NAME: pidnet_small
  NUM_OUTPUTS: 2
  PRETRAINED: pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar
OUTPUT_DIR: output
PIN_MEMORY: True
PRINT_FREQ: 10
TEST:
  BASE_SIZE: 1024
  BATCH_SIZE_PER_GPU: 6
  FLIP_TEST: False
  IMAGE_SIZE: [1024, 1024]
  MODEL_FILE: 
  MULTI_SCALE: False
  OUTPUT_INDEX: 1
TRAIN:
  ADVERSARIAL: True
  AUG: True
  AUG1: False
  AUG2: True
  AUG3: True
  AUG4: False
  AUG_CHANCE: True
  BASE_SIZE: 720
  BATCH_SIZE_PER_GPU: 6
  BEGIN_EPOCH: 0
  D1: False
  END_EPOCH: 20
  EVAL_INTERVAL: 1
  EXTRA_EPOCH: 0
  EXTRA_LR: 0.001
  FLIP: True
  GAN: Vanilla
  IGNORE_LABEL: 0
  IMAGE_SIZE: [720, 720]
  LAMBDA_ADV1: 0.001
  LAMBDA_ADV2: 0.0002
  LR: 0.001
  LR_D1: 0.0001
  LR_D2: 0.0001
  MOMENTUM: 0.9
  MULTI_SCALE: True
  NESTEROV: False
  OPTIMIZER: adam
  RESUME: True
  SCALE_FACTOR: 16
  SCHEDULER: True
  SHUFFLE: True
  WD: 0.0005
WORKERS: 0
2025-01-25 23:00:30,678 Attention!!!
2025-01-25 23:00:30,678 Loaded 302 parameters!
2025-01-25 23:00:30,678 Over!!!
2025-01-25 23:00:31,164 => loaded checkpoint (epoch 3)
2025-01-25 23:00:38,225 Epoch: [3/20] Iter:[0/292], Time: 7.03, lr: [0.0006911415778422553], Loss: 1.219064, Loss_D1: 0.693132, Loss_D2: 0.693226, Acc:0.573961, Semantic loss: 0.139294
2025-01-25 23:00:57,849 Epoch: [3/20] Iter:[10/292], Time: 2.43, lr: [0.0006898883745379924], Loss: 1.405571, Loss_D1: 0.692771, Loss_D2: 0.693359, Acc:0.505656, Semantic loss: 0.142369
2025-01-25 23:01:15,614 Epoch: [3/20] Iter:[20/292], Time: 2.12, lr: [0.0006886349182400495], Loss: 1.377171, Loss_D1: 0.684494, Loss_D2: 0.691966, Acc:0.492508, Semantic loss: 0.145913
2025-01-25 23:01:33,495 Epoch: [3/20] Iter:[30/292], Time: 2.01, lr: [0.0006873812083854784], Loss: 1.355858, Loss_D1: 0.685258, Loss_D2: 0.692790, Acc:0.495422, Semantic loss: 0.145844
2025-01-25 23:01:51,128 Epoch: [3/20] Iter:[40/292], Time: 1.95, lr: [0.0006861272444089348], Loss: 1.380625, Loss_D1: 0.683718, Loss_D2: 0.693136, Acc:0.489407, Semantic loss: 0.149926
2025-01-25 23:02:08,848 Epoch: [3/20] Iter:[50/292], Time: 1.92, lr: [0.0006848730257426629], Loss: 1.382611, Loss_D1: 0.690976, Loss_D2: 0.692299, Acc:0.488012, Semantic loss: 0.152224
2025-01-25 23:02:26,186 Epoch: [3/20] Iter:[60/292], Time: 1.89, lr: [0.0006836185518164803], Loss: 1.355532, Loss_D1: 0.686795, Loss_D2: 0.693531, Acc:0.485068, Semantic loss: 0.150482
2025-01-25 23:02:43,784 Epoch: [3/20] Iter:[70/292], Time: 1.87, lr: [0.0006823638220577629], Loss: 1.368802, Loss_D1: 0.701655, Loss_D2: 0.692910, Acc:0.484544, Semantic loss: 0.151315
2025-01-25 23:03:01,314 Epoch: [3/20] Iter:[80/292], Time: 1.85, lr: [0.0006811088358914289], Loss: 1.353457, Loss_D1: 0.693894, Loss_D2: 0.693057, Acc:0.488112, Semantic loss: 0.150628
2025-01-25 23:03:18,752 Epoch: [3/20] Iter:[90/292], Time: 1.84, lr: [0.000679853592739924], Loss: 1.352166, Loss_D1: 0.694976, Loss_D2: 0.693624, Acc:0.487485, Semantic loss: 0.151808
2025-01-25 23:03:36,280 Epoch: [3/20] Iter:[100/292], Time: 1.83, lr: [0.0006785980920232047], Loss: 1.357916, Loss_D1: 0.692178, Loss_D2: 0.689765, Acc:0.486272, Semantic loss: 0.152379
2025-01-25 23:03:53,599 Epoch: [3/20] Iter:[110/292], Time: 1.82, lr: [0.0006773423331587233], Loss: 1.353317, Loss_D1: 0.693876, Loss_D2: 0.695322, Acc:0.487343, Semantic loss: 0.150753
2025-01-25 23:04:11,117 Epoch: [3/20] Iter:[120/292], Time: 1.82, lr: [0.0006760863155614114], Loss: 1.342201, Loss_D1: 0.679259, Loss_D2: 0.695055, Acc:0.486744, Semantic loss: 0.150159
2025-01-25 23:04:28,809 Epoch: [3/20] Iter:[130/292], Time: 1.81, lr: [0.000674830038643664], Loss: 1.353565, Loss_D1: 0.639488, Loss_D2: 0.693879, Acc:0.488558, Semantic loss: 0.150090
2025-01-25 23:04:46,275 Epoch: [3/20] Iter:[140/292], Time: 1.81, lr: [0.0006735735018153228], Loss: 1.350257, Loss_D1: 0.700253, Loss_D2: 0.692560, Acc:0.488432, Semantic loss: 0.149780
2025-01-25 23:05:03,640 Epoch: [3/20] Iter:[150/292], Time: 1.80, lr: [0.0006723167044836607], Loss: 1.344861, Loss_D1: 0.662378, Loss_D2: 0.693171, Acc:0.488238, Semantic loss: 0.149215
2025-01-25 23:05:21,388 Epoch: [3/20] Iter:[160/292], Time: 1.80, lr: [0.0006710596460533643], Loss: 1.355092, Loss_D1: 0.644255, Loss_D2: 0.693468, Acc:0.491730, Semantic loss: 0.149165
2025-01-25 23:05:38,976 Epoch: [3/20] Iter:[170/292], Time: 1.80, lr: [0.0006698023259265178], Loss: 1.342588, Loss_D1: 0.682513, Loss_D2: 0.693528, Acc:0.489526, Semantic loss: 0.149336
2025-01-25 23:05:56,504 Epoch: [3/20] Iter:[180/292], Time: 1.80, lr: [0.0006685447435025854], Loss: 1.348775, Loss_D1: 0.694253, Loss_D2: 0.693185, Acc:0.492029, Semantic loss: 0.148825
2025-01-25 23:06:13,853 Epoch: [3/20] Iter:[190/292], Time: 1.79, lr: [0.0006672868981783959], Loss: 1.346116, Loss_D1: 0.674626, Loss_D2: 0.693356, Acc:0.493303, Semantic loss: 0.148417
2025-01-25 23:06:31,420 Epoch: [3/20] Iter:[200/292], Time: 1.79, lr: [0.0006660287893481237], Loss: 1.355253, Loss_D1: 0.657488, Loss_D2: 0.692789, Acc:0.495087, Semantic loss: 0.148249
2025-01-25 23:06:48,920 Epoch: [3/20] Iter:[210/292], Time: 1.79, lr: [0.0006647704164032727], Loss: 1.353123, Loss_D1: 0.661667, Loss_D2: 0.695417, Acc:0.497224, Semantic loss: 0.147566
2025-01-25 23:07:06,471 Epoch: [3/20] Iter:[220/292], Time: 1.79, lr: [0.0006635117787326587], Loss: 1.360227, Loss_D1: 0.668022, Loss_D2: 0.691531, Acc:0.499244, Semantic loss: 0.147287
2025-01-25 23:07:24,289 Epoch: [3/20] Iter:[230/292], Time: 1.79, lr: [0.0006622528757223915], Loss: 1.361315, Loss_D1: 0.700645, Loss_D2: 0.693763, Acc:0.499871, Semantic loss: 0.146755
2025-01-25 23:07:41,746 Epoch: [3/20] Iter:[240/292], Time: 1.79, lr: [0.0006609937067558576], Loss: 1.364520, Loss_D1: 0.685118, Loss_D2: 0.693147, Acc:0.501600, Semantic loss: 0.146323
2025-01-25 23:07:59,097 Epoch: [3/20] Iter:[250/292], Time: 1.78, lr: [0.0006597342712137018], Loss: 1.366618, Loss_D1: 0.645261, Loss_D2: 0.693001, Acc:0.502217, Semantic loss: 0.146373
2025-01-25 23:08:16,949 Epoch: [3/20] Iter:[260/292], Time: 1.78, lr: [0.0006584745684738101], Loss: 1.362316, Loss_D1: 0.651264, Loss_D2: 0.693180, Acc:0.503159, Semantic loss: 0.145944
2025-01-25 23:08:34,644 Epoch: [3/20] Iter:[270/292], Time: 1.78, lr: [0.00065721459791129], Loss: 1.362489, Loss_D1: 0.678532, Loss_D2: 0.693058, Acc:0.503790, Semantic loss: 0.146059
2025-01-25 23:08:52,056 Epoch: [3/20] Iter:[280/292], Time: 1.78, lr: [0.0006559543588984539], Loss: 1.355646, Loss_D1: 0.678552, Loss_D2: 0.693336, Acc:0.502730, Semantic loss: 0.146058
2025-01-25 23:09:09,727 Epoch: [3/20] Iter:[290/292], Time: 1.78, lr: [0.0006546938508047993], Loss: 1.357697, Loss_D1: 0.678004, Loss_D2: 0.693061, Acc:0.503074, Semantic loss: 0.145790
2025-01-25 23:12:33,555 0 [0.         0.42239193 0.17618557 0.12036378 0.28282574 0.14307595
 0.20427012 0.0006411 ] 0.19282202616242022
2025-01-25 23:12:33,556 1 [0.         0.46289517 0.17376946 0.17099198 0.31836808 0.03476033
 0.09745572 0.00311078] 0.18019307360416273
2025-01-25 23:12:33,557 => saving checkpoint to output\loveDa\pidnet_small_loveda_train_AVDcheckpoint.pth.tar
2025-01-25 23:12:33,744 Loss: 1.270, MeanIU:  0.1802, Best_mIoU:  0.1988
2025-01-25 23:12:33,744 [0.         0.46289517 0.17376946 0.17099198 0.31836808 0.03476033
 0.09745572 0.00311078]
2025-01-25 23:12:35,521 Epoch: [4/20] Iter:[0/292], Time: 1.77, lr: [0.0008180521460508585], Loss: 1.161100, Loss_D1: 0.697384, Loss_D2: 0.693149, Acc:0.425040, Semantic loss: 0.156942
2025-01-25 23:12:53,184 Epoch: [4/20] Iter:[10/292], Time: 1.77, lr: [0.0008164761062672454], Loss: 1.281831, Loss_D1: 0.708138, Loss_D2: 0.693411, Acc:0.515607, Semantic loss: 0.143262
2025-01-25 23:13:11,210 Epoch: [4/20] Iter:[20/292], Time: 1.78, lr: [0.0008148997283862292], Loss: 1.309018, Loss_D1: 0.661814, Loss_D2: 0.693432, Acc:0.487874, Semantic loss: 0.147250
2025-01-25 23:13:28,995 Epoch: [4/20] Iter:[30/292], Time: 1.78, lr: [0.0008133230116082655], Loss: 1.271388, Loss_D1: 0.649407, Loss_D2: 0.693052, Acc:0.480882, Semantic loss: 0.148214
2025-01-25 23:13:46,739 Epoch: [4/20] Iter:[40/292], Time: 1.78, lr: [0.0008117459551301937], Loss: 1.288509, Loss_D1: 0.703909, Loss_D2: 0.693218, Acc:0.495071, Semantic loss: 0.148169
2025-01-25 23:14:04,358 Epoch: [4/20] Iter:[50/292], Time: 1.78, lr: [0.0008101685581452108], Loss: 1.307716, Loss_D1: 0.642055, Loss_D2: 0.693446, Acc:0.488918, Semantic loss: 0.148922
2025-01-25 23:14:21,806 Epoch: [4/20] Iter:[60/292], Time: 1.77, lr: [0.000808590819842848], Loss: 1.330931, Loss_D1: 0.716274, Loss_D2: 0.695114, Acc:0.489036, Semantic loss: 0.148768
2025-01-25 23:14:39,736 Epoch: [4/20] Iter:[70/292], Time: 1.77, lr: [0.0008070127394089456], Loss: 1.356474, Loss_D1: 0.713431, Loss_D2: 0.692162, Acc:0.492727, Semantic loss: 0.150492
2025-01-25 23:14:57,241 Epoch: [4/20] Iter:[80/292], Time: 1.77, lr: [0.0008054343160256287], Loss: 1.371180, Loss_D1: 0.696388, Loss_D2: 0.691819, Acc:0.497046, Semantic loss: 0.149837
2025-01-25 23:15:14,696 Epoch: [4/20] Iter:[90/292], Time: 1.77, lr: [0.0008038555488712811], Loss: 1.372906, Loss_D1: 0.697852, Loss_D2: 0.694733, Acc:0.495378, Semantic loss: 0.149270
2025-01-25 23:15:31,908 Epoch: [4/20] Iter:[100/292], Time: 1.76, lr: [0.0008022764371205209], Loss: 1.369504, Loss_D1: 0.687190, Loss_D2: 0.688382, Acc:0.492253, Semantic loss: 0.148514
2025-01-25 23:15:49,395 Epoch: [4/20] Iter:[110/292], Time: 1.76, lr: [0.0008006969799441747], Loss: 1.372045, Loss_D1: 0.690622, Loss_D2: 0.694133, Acc:0.493126, Semantic loss: 0.147190
2025-01-25 23:16:06,846 Epoch: [4/20] Iter:[120/292], Time: 1.76, lr: [0.0007991171765092516], Loss: 1.367111, Loss_D1: 0.659338, Loss_D2: 0.692891, Acc:0.495217, Semantic loss: 0.146842
2025-01-25 23:16:24,309 Epoch: [4/20] Iter:[130/292], Time: 1.76, lr: [0.0007975370259789175], Loss: 1.364568, Loss_D1: 0.651685, Loss_D2: 0.692897, Acc:0.496712, Semantic loss: 0.145728
2025-01-25 23:16:41,811 Epoch: [4/20] Iter:[140/292], Time: 1.76, lr: [0.0007959565275124689], Loss: 1.346835, Loss_D1: 0.699122, Loss_D2: 0.693248, Acc:0.492563, Semantic loss: 0.145946
2025-01-25 23:16:59,056 Epoch: [4/20] Iter:[150/292], Time: 1.76, lr: [0.0007943756802653058], Loss: 1.349174, Loss_D1: 0.677400, Loss_D2: 0.693177, Acc:0.491487, Semantic loss: 0.146110
2025-01-25 23:17:16,524 Epoch: [4/20] Iter:[160/292], Time: 1.76, lr: [0.0007927944833889061], Loss: 1.357979, Loss_D1: 0.684329, Loss_D2: 0.693249, Acc:0.493100, Semantic loss: 0.146220
2025-01-25 23:17:33,826 Epoch: [4/20] Iter:[170/292], Time: 1.75, lr: [0.0007912129360307977], Loss: 1.355935, Loss_D1: 0.669812, Loss_D2: 0.693413, Acc:0.493526, Semantic loss: 0.145857
2025-01-25 23:17:51,180 Epoch: [4/20] Iter:[180/292], Time: 1.75, lr: [0.0007896310373345315], Loss: 1.360636, Loss_D1: 0.691758, Loss_D2: 0.691271, Acc:0.494991, Semantic loss: 0.145248
2025-01-25 23:18:08,402 Epoch: [4/20] Iter:[190/292], Time: 1.75, lr: [0.000788048786439654], Loss: 1.349140, Loss_D1: 0.679438, Loss_D2: 0.693646, Acc:0.492915, Semantic loss: 0.145500
2025-01-25 23:18:25,841 Epoch: [4/20] Iter:[200/292], Time: 1.75, lr: [0.0007864661824816803], Loss: 1.343574, Loss_D1: 0.682601, Loss_D2: 0.698758, Acc:0.488112, Semantic loss: 0.146515
2025-01-25 23:18:43,179 Epoch: [4/20] Iter:[210/292], Time: 1.75, lr: [0.0007848832245920646], Loss: 1.345450, Loss_D1: 0.600240, Loss_D2: 0.692686, Acc:0.487928, Semantic loss: 0.146474
2025-01-25 23:19:00,549 Epoch: [4/20] Iter:[220/292], Time: 1.75, lr: [0.0007832999118981735], Loss: 1.351179, Loss_D1: 0.671217, Loss_D2: 0.693790, Acc:0.487558, Semantic loss: 0.147081
2025-01-25 23:19:17,808 Epoch: [4/20] Iter:[230/292], Time: 1.75, lr: [0.0007817162435232569], Loss: 1.345579, Loss_D1: 0.681207, Loss_D2: 0.693089, Acc:0.485966, Semantic loss: 0.147131
2025-01-25 23:19:35,042 Epoch: [4/20] Iter:[240/292], Time: 1.75, lr: [0.000780132218586419], Loss: 1.341548, Loss_D1: 0.676011, Loss_D2: 0.693267, Acc:0.483705, Semantic loss: 0.147425
2025-01-25 23:19:52,476 Epoch: [4/20] Iter:[250/292], Time: 1.75, lr: [0.00077854783620259], Loss: 1.340946, Loss_D1: 0.690349, Loss_D2: 0.693496, Acc:0.483458, Semantic loss: 0.147605
2025-01-25 23:20:10,023 Epoch: [4/20] Iter:[260/292], Time: 1.75, lr: [0.0007769630954824961], Loss: 1.341467, Loss_D1: 0.638008, Loss_D2: 0.693151, Acc:0.482454, Semantic loss: 0.147800
2025-01-25 23:20:27,454 Epoch: [4/20] Iter:[270/292], Time: 1.75, lr: [0.0007753779955326305], Loss: 1.343588, Loss_D1: 0.690678, Loss_D2: 0.693188, Acc:0.482758, Semantic loss: 0.147360
2025-01-25 23:20:44,803 Epoch: [4/20] Iter:[280/292], Time: 1.75, lr: [0.000773792535455223], Loss: 1.349639, Loss_D1: 0.643209, Loss_D2: 0.692712, Acc:0.483211, Semantic loss: 0.147336
2025-01-25 23:21:02,045 Epoch: [4/20] Iter:[290/292], Time: 1.75, lr: [0.000772206714348211], Loss: 1.349649, Loss_D1: 0.670888, Loss_D2: 0.693869, Acc:0.482855, Semantic loss: 0.147400
2025-01-25 23:24:25,025 0 [0.00000000e+00 4.54317559e-01 1.47719040e-01 8.60629646e-02
 2.57500349e-01 1.12975324e-01 5.52469926e-02 2.08262940e-04] 0.15914721326425885
2025-01-25 23:24:25,026 1 [0.00000000e+00 4.55941115e-01 1.29093054e-01 1.17396247e-01
 2.84370177e-01 3.88728289e-02 4.46344796e-02 7.04415031e-05] 0.15291119184618937
2025-01-25 23:24:25,026 => saving checkpoint to output\loveDa\pidnet_small_loveda_train_AVDcheckpoint.pth.tar
2025-01-25 23:24:25,194 Loss: 1.307, MeanIU:  0.1529, Best_mIoU:  0.1988
2025-01-25 23:24:25,194 [0.00000000e+00 4.55941115e-01 1.29093054e-01 1.17396247e-01
 2.84370177e-01 3.88728289e-02 4.46344796e-02 7.04415031e-05]
2025-01-25 23:24:27,180 Epoch: [5/20] Iter:[0/292], Time: 1.98, lr: [0.0005894329565052108], Loss: 1.505241, Loss_D1: 0.674519, Loss_D2: 0.693511, Acc:0.374495, Semantic loss: 0.171025
2025-01-25 23:24:44,438 Epoch: [5/20] Iter:[10/292], Time: 1.75, lr: [0.0005882216545193853], Loss: 1.304303, Loss_D1: 0.674729, Loss_D2: 0.693018, Acc:0.471724, Semantic loss: 0.145538
2025-01-25 23:25:01,897 Epoch: [5/20] Iter:[20/292], Time: 1.75, lr: [0.0005870100753157794], Loss: 1.430634, Loss_D1: 0.666317, Loss_D2: 0.693044, Acc:0.502968, Semantic loss: 0.143223
2025-01-25 23:25:19,288 Epoch: [5/20] Iter:[30/292], Time: 1.74, lr: [0.0005857982181949093], Loss: 1.401897, Loss_D1: 0.677246, Loss_D2: 0.693449, Acc:0.505962, Semantic loss: 0.142518
2025-01-25 23:25:36,785 Epoch: [5/20] Iter:[40/292], Time: 1.75, lr: [0.0005845860824539137], Loss: 1.422503, Loss_D1: 0.682193, Loss_D2: 0.693186, Acc:0.503213, Semantic loss: 0.144218
2025-01-25 23:25:54,124 Epoch: [5/20] Iter:[50/292], Time: 1.74, lr: [0.0005833736673865297], Loss: 1.401080, Loss_D1: 0.679246, Loss_D2: 0.693159, Acc:0.499131, Semantic loss: 0.143489
2025-01-25 23:26:11,421 Epoch: [5/20] Iter:[60/292], Time: 1.74, lr: [0.0005821609722830691], Loss: 1.374381, Loss_D1: 0.634924, Loss_D2: 0.693172, Acc:0.503101, Semantic loss: 0.143274
2025-01-25 23:26:28,747 Epoch: [5/20] Iter:[70/292], Time: 1.74, lr: [0.0005809479964303931], Loss: 1.360979, Loss_D1: 0.641163, Loss_D2: 0.693172, Acc:0.508316, Semantic loss: 0.142823
2025-01-25 23:26:46,045 Epoch: [5/20] Iter:[80/292], Time: 1.74, lr: [0.0005797347391118883], Loss: 1.339742, Loss_D1: 0.668246, Loss_D2: 0.693082, Acc:0.506178, Semantic loss: 0.142530
2025-01-25 23:27:03,544 Epoch: [5/20] Iter:[90/292], Time: 1.74, lr: [0.0005785211996074404], Loss: 1.346774, Loss_D1: 0.665203, Loss_D2: 0.693433, Acc:0.508441, Semantic loss: 0.142150
2025-01-25 23:27:20,972 Epoch: [5/20] Iter:[100/292], Time: 1.74, lr: [0.0005773073771934105], Loss: 1.329549, Loss_D1: 0.618036, Loss_D2: 0.693108, Acc:0.502721, Semantic loss: 0.142916
2025-01-25 23:27:38,389 Epoch: [5/20] Iter:[110/292], Time: 1.74, lr: [0.0005760932711426078], Loss: 1.316416, Loss_D1: 0.701497, Loss_D2: 0.693132, Acc:0.499098, Semantic loss: 0.143029
2025-01-25 23:27:55,677 Epoch: [5/20] Iter:[120/292], Time: 1.74, lr: [0.0005748788807242656], Loss: 1.311314, Loss_D1: 0.647191, Loss_D2: 0.693188, Acc:0.497793, Semantic loss: 0.142744
2025-01-25 23:28:13,413 Epoch: [5/20] Iter:[130/292], Time: 1.74, lr: [0.0005736642052040137], Loss: 1.295311, Loss_D1: 0.664932, Loss_D2: 0.693104, Acc:0.493316, Semantic loss: 0.142462
2025-01-25 23:28:30,713 Epoch: [5/20] Iter:[140/292], Time: 1.74, lr: [0.0005724492438438531], Loss: 1.303291, Loss_D1: 0.656535, Loss_D2: 0.693035, Acc:0.495173, Semantic loss: 0.141895
2025-01-25 23:28:48,117 Epoch: [5/20] Iter:[150/292], Time: 1.74, lr: [0.0005712339959021294], Loss: 1.299856, Loss_D1: 0.691166, Loss_D2: 0.693325, Acc:0.496263, Semantic loss: 0.141758
2025-01-25 23:29:05,651 Epoch: [5/20] Iter:[160/292], Time: 1.74, lr: [0.0005700184606335053], Loss: 1.317309, Loss_D1: 0.669824, Loss_D2: 0.693095, Acc:0.496986, Semantic loss: 0.142096
2025-01-25 23:29:23,208 Epoch: [5/20] Iter:[170/292], Time: 1.74, lr: [0.0005688026372889345], Loss: 1.318978, Loss_D1: 0.652611, Loss_D2: 0.693115, Acc:0.497346, Semantic loss: 0.142263
2025-01-25 23:29:40,750 Epoch: [5/20] Iter:[180/292], Time: 1.74, lr: [0.0005675865251156336], Loss: 1.333456, Loss_D1: 0.651110, Loss_D2: 0.693156, Acc:0.499726, Semantic loss: 0.142689
2025-01-25 23:29:58,249 Epoch: [5/20] Iter:[190/292], Time: 1.74, lr: [0.0005663701233570548], Loss: 1.326115, Loss_D1: 0.682515, Loss_D2: 0.693087, Acc:0.498261, Semantic loss: 0.142677
2025-01-25 23:30:15,858 Epoch: [5/20] Iter:[200/292], Time: 1.74, lr: [0.0005651534312528583], Loss: 1.323563, Loss_D1: 0.677131, Loss_D2: 0.693238, Acc:0.496241, Semantic loss: 0.142804
2025-01-25 23:30:33,368 Epoch: [5/20] Iter:[210/292], Time: 1.74, lr: [0.0005639364480388839], Loss: 1.323849, Loss_D1: 0.688260, Loss_D2: 0.693215, Acc:0.496422, Semantic loss: 0.142815
2025-01-25 23:30:50,942 Epoch: [5/20] Iter:[220/292], Time: 1.75, lr: [0.0005627191729471222], Loss: 1.326827, Loss_D1: 0.686095, Loss_D2: 0.693161, Acc:0.498259, Semantic loss: 0.143127
2025-01-25 23:31:08,928 Epoch: [5/20] Iter:[230/292], Time: 1.75, lr: [0.0005615016052056872], Loss: 1.324023, Loss_D1: 0.705864, Loss_D2: 0.693115, Acc:0.498148, Semantic loss: 0.143199
2025-01-25 23:31:26,945 Epoch: [5/20] Iter:[240/292], Time: 1.75, lr: [0.0005602837440387858], Loss: 1.322001, Loss_D1: 0.695804, Loss_D2: 0.693168, Acc:0.499476, Semantic loss: 0.143184
2025-01-25 23:31:44,610 Epoch: [5/20] Iter:[250/292], Time: 1.75, lr: [0.0005590655886666893], Loss: 1.323719, Loss_D1: 0.712727, Loss_D2: 0.693420, Acc:0.499527, Semantic loss: 0.143601
2025-01-25 23:32:02,461 Epoch: [5/20] Iter:[260/292], Time: 1.75, lr: [0.000557847138305704], Loss: 1.326031, Loss_D1: 0.711439, Loss_D2: 0.693156, Acc:0.501317, Semantic loss: 0.143376
2025-01-25 23:32:20,680 Epoch: [5/20] Iter:[270/292], Time: 1.75, lr: [0.0005566283921681413], Loss: 1.328974, Loss_D1: 0.651093, Loss_D2: 0.693166, Acc:0.502280, Semantic loss: 0.143151
2025-01-25 23:32:38,383 Epoch: [5/20] Iter:[280/292], Time: 1.76, lr: [0.000555409349462287], Loss: 1.329985, Loss_D1: 0.687667, Loss_D2: 0.693145, Acc:0.502681, Semantic loss: 0.143457
2025-01-25 23:32:56,107 Epoch: [5/20] Iter:[290/292], Time: 1.76, lr: [0.0005541900093923714], Loss: 1.333947, Loss_D1: 0.670223, Loss_D2: 0.693044, Acc:0.503606, Semantic loss: 0.143030
2025-01-25 23:36:25,696 0 [0.         0.40117034 0.1897112  0.12108325 0.2412711  0.05322777
 0.14831967 0.00408771] 0.16555300520791594
2025-01-25 23:36:25,696 1 [0.         0.42201929 0.23759697 0.2285055  0.23063095 0.04001521
 0.17175851 0.04082743] 0.19590769502382005
2025-01-25 23:36:25,697 => saving checkpoint to output\loveDa\pidnet_small_loveda_train_AVDcheckpoint.pth.tar
2025-01-25 23:36:25,872 Loss: 1.258, MeanIU:  0.1959, Best_mIoU:  0.1988
2025-01-25 23:36:25,872 [0.         0.42201929 0.23759697 0.2285055  0.23063095 0.04001521
 0.17175851 0.04082743]
2025-01-25 23:36:27,774 Epoch: [6/20] Iter:[0/292], Time: 1.90, lr: [0.0003888283319560596], Loss: 1.397544, Loss_D1: 0.642472, Loss_D2: 0.693206, Acc:0.444290, Semantic loss: 0.132460
2025-01-25 23:36:45,262 Epoch: [6/20] Iter:[10/292], Time: 1.76, lr: [0.0003879721960980528], Loss: 1.418784, Loss_D1: 0.595588, Loss_D2: 0.693218, Acc:0.534969, Semantic loss: 0.139906
2025-01-25 23:37:02,999 Epoch: [6/20] Iter:[20/292], Time: 1.77, lr: [0.0003871158502739505], Loss: 1.411884, Loss_D1: 0.636915, Loss_D2: 0.692563, Acc:0.534704, Semantic loss: 0.139494
2025-01-25 23:37:20,883 Epoch: [6/20] Iter:[30/292], Time: 1.77, lr: [0.0003862592939159266], Loss: 1.391329, Loss_D1: 0.644362, Loss_D2: 0.696726, Acc:0.528885, Semantic loss: 0.139392
2025-01-25 23:37:38,637 Epoch: [6/20] Iter:[40/292], Time: 1.77, lr: [0.0003854025264532166], Loss: 1.382497, Loss_D1: 0.633549, Loss_D2: 0.692320, Acc:0.524074, Semantic loss: 0.138242
2025-01-25 23:37:56,486 Epoch: [6/20] Iter:[50/292], Time: 1.78, lr: [0.00038454554731209443], Loss: 1.363780, Loss_D1: 0.686086, Loss_D2: 0.701255, Acc:0.526044, Semantic loss: 0.138015
2025-01-25 23:38:14,139 Epoch: [6/20] Iter:[60/292], Time: 1.77, lr: [0.00038368835591584983], Loss: 1.354667, Loss_D1: 0.677088, Loss_D2: 0.673709, Acc:0.526415, Semantic loss: 0.137260
2025-01-25 23:38:31,919 Epoch: [6/20] Iter:[70/292], Time: 1.78, lr: [0.0003828309516847657], Loss: 1.373350, Loss_D1: 0.641558, Loss_D2: 0.691323, Acc:0.530479, Semantic loss: 0.137948
2025-01-25 23:38:49,641 Epoch: [6/20] Iter:[80/292], Time: 1.77, lr: [0.00038197333403609433], Loss: 1.370277, Loss_D1: 0.663482, Loss_D2: 0.692586, Acc:0.528272, Semantic loss: 0.138387
2025-01-25 23:39:07,308 Epoch: [6/20] Iter:[90/292], Time: 1.77, lr: [0.0003811155023840347], Loss: 1.371869, Loss_D1: 0.576851, Loss_D2: 0.688961, Acc:0.527006, Semantic loss: 0.137911
2025-01-25 23:39:24,984 Epoch: [6/20] Iter:[100/292], Time: 1.77, lr: [0.00038025745613970825], Loss: 1.376667, Loss_D1: 0.692901, Loss_D2: 0.691098, Acc:0.527841, Semantic loss: 0.138290
2025-01-25 23:39:42,563 Epoch: [6/20] Iter:[110/292], Time: 1.77, lr: [0.000379399194711135], Loss: 1.360694, Loss_D1: 0.639654, Loss_D2: 0.691611, Acc:0.525220, Semantic loss: 0.137995
2025-01-25 23:40:00,495 Epoch: [6/20] Iter:[120/292], Time: 1.77, lr: [0.0003785407175032095], Loss: 1.357791, Loss_D1: 0.671712, Loss_D2: 0.694259, Acc:0.524381, Semantic loss: 0.138481
2025-01-25 23:40:18,098 Epoch: [6/20] Iter:[130/292], Time: 1.77, lr: [0.0003776820239176765], Loss: 1.358108, Loss_D1: 0.599423, Loss_D2: 0.692551, Acc:0.525201, Semantic loss: 0.138391
2025-01-25 23:40:35,854 Epoch: [6/20] Iter:[140/292], Time: 1.77, lr: [0.0003768231133531063], Loss: 1.361771, Loss_D1: 0.651294, Loss_D2: 0.692939, Acc:0.525275, Semantic loss: 0.138209
2025-01-25 23:40:53,600 Epoch: [6/20] Iter:[150/292], Time: 1.77, lr: [0.00037596398520486923], Loss: 1.353706, Loss_D1: 0.671250, Loss_D2: 0.696871, Acc:0.526952, Semantic loss: 0.137685
2025-01-25 23:41:11,276 Epoch: [6/20] Iter:[160/292], Time: 1.77, lr: [0.00037510463886511144], Loss: 1.353658, Loss_D1: 0.667984, Loss_D2: 0.692952, Acc:0.526201, Semantic loss: 0.137466
2025-01-25 23:41:29,182 Epoch: [6/20] Iter:[170/292], Time: 1.77, lr: [0.00037424507372272843], Loss: 1.351412, Loss_D1: 0.639090, Loss_D2: 0.691881, Acc:0.526336, Semantic loss: 0.137523
2025-01-25 23:41:46,707 Epoch: [6/20] Iter:[180/292], Time: 1.77, lr: [0.0003733852891633403], Loss: 1.346978, Loss_D1: 0.690887, Loss_D2: 0.692177, Acc:0.527198, Semantic loss: 0.137694
2025-01-25 23:42:04,272 Epoch: [6/20] Iter:[190/292], Time: 1.77, lr: [0.0003725252845692651], Loss: 1.340775, Loss_D1: 0.616432, Loss_D2: 0.692537, Acc:0.526397, Semantic loss: 0.137864
2025-01-25 23:42:22,082 Epoch: [6/20] Iter:[200/292], Time: 1.77, lr: [0.00037166505931949265], Loss: 1.344784, Loss_D1: 0.648110, Loss_D2: 0.694899, Acc:0.526262, Semantic loss: 0.137664
2025-01-25 23:42:39,702 Epoch: [6/20] Iter:[210/292], Time: 1.77, lr: [0.0003708046127896582], Loss: 1.339608, Loss_D1: 0.754353, Loss_D2: 0.682071, Acc:0.525066, Semantic loss: 0.137520
2025-01-25 23:42:57,486 Epoch: [6/20] Iter:[220/292], Time: 1.77, lr: [0.00036994394435201544], Loss: 1.342046, Loss_D1: 0.626860, Loss_D2: 0.692977, Acc:0.524543, Semantic loss: 0.137596
2025-01-25 23:43:15,047 Epoch: [6/20] Iter:[230/292], Time: 1.77, lr: [0.00036908305337540965], Loss: 1.341123, Loss_D1: 0.649610, Loss_D2: 0.691083, Acc:0.523959, Semantic loss: 0.137474
2025-01-25 23:43:32,665 Epoch: [6/20] Iter:[240/292], Time: 1.77, lr: [0.00036822193922525], Loss: 1.333870, Loss_D1: 0.634654, Loss_D2: 0.692845, Acc:0.523201, Semantic loss: 0.137373
2025-01-25 23:43:50,146 Epoch: [6/20] Iter:[250/292], Time: 1.77, lr: [0.000367360601263482], Loss: 1.332569, Loss_D1: 0.652948, Loss_D2: 0.696813, Acc:0.523138, Semantic loss: 0.137393
2025-01-25 23:44:07,879 Epoch: [6/20] Iter:[260/292], Time: 1.77, lr: [0.00036649903884855946], Loss: 1.328743, Loss_D1: 0.643517, Loss_D2: 0.694234, Acc:0.522187, Semantic loss: 0.136977
2025-01-25 23:44:25,762 Epoch: [6/20] Iter:[270/292], Time: 1.77, lr: [0.0003656372513354164], Loss: 1.327190, Loss_D1: 0.683886, Loss_D2: 0.693664, Acc:0.522199, Semantic loss: 0.137277
2025-01-25 23:44:43,612 Epoch: [6/20] Iter:[280/292], Time: 1.77, lr: [0.00036477523807543823], Loss: 1.322453, Loss_D1: 0.643488, Loss_D2: 0.690123, Acc:0.522361, Semantic loss: 0.137255
2025-01-25 23:45:01,373 Epoch: [6/20] Iter:[290/292], Time: 1.77, lr: [0.0003639129984164331], Loss: 1.323964, Loss_D1: 0.665330, Loss_D2: 0.693145, Acc:0.521059, Semantic loss: 0.137320
2025-01-25 23:48:29,646 0 [0.         0.41787646 0.19972314 0.15747979 0.33263474 0.18974927
 0.16367388 0.00521772] 0.20947928396799914
2025-01-25 23:48:29,647 1 [0.00000000e+00 4.57498561e-01 3.06317758e-01 2.43359393e-01
 3.45710968e-01 1.78037935e-01 1.52139766e-01 3.79308287e-04] 0.24049195571499898
2025-01-25 23:48:29,647 => saving checkpoint to output\loveDa\pidnet_small_loveda_train_AVDcheckpoint.pth.tar
2025-01-25 23:48:29,877 Loss: 1.204, MeanIU:  0.2405, Best_mIoU:  0.2405
2025-01-25 23:48:29,877 [0.00000000e+00 4.57498561e-01 3.06317758e-01 2.43359393e-01
 3.45710968e-01 1.78037935e-01 1.52139766e-01 3.79308287e-04]
2025-01-25 23:48:31,770 Epoch: [7/20] Iter:[0/292], Time: 1.89, lr: [0.00023344764289821073], Loss: 1.847456, Loss_D1: 0.673709, Loss_D2: 0.696878, Acc:0.634716, Semantic loss: 0.123558
2025-01-25 23:48:49,482 Epoch: [7/20] Iter:[10/292], Time: 1.78, lr: [0.00023289408499614755], Loss: 1.394812, Loss_D1: 0.627739, Loss_D2: 0.695596, Acc:0.551058, Semantic loss: 0.134211
2025-01-25 23:49:07,289 Epoch: [7/20] Iter:[20/292], Time: 1.78, lr: [0.00023234038086278745], Loss: 1.422336, Loss_D1: 0.659952, Loss_D2: 0.692000, Acc:0.532500, Semantic loss: 0.142286
2025-01-25 23:49:25,052 Epoch: [7/20] Iter:[30/292], Time: 1.78, lr: [0.00023178653007208127], Loss: 1.402644, Loss_D1: 0.665392, Loss_D2: 0.692802, Acc:0.539287, Semantic loss: 0.138433
2025-01-25 23:49:42,862 Epoch: [7/20] Iter:[40/292], Time: 1.78, lr: [0.00023123253219560407], Loss: 1.408356, Loss_D1: 0.644566, Loss_D2: 0.691753, Acc:0.541168, Semantic loss: 0.137913
2025-01-25 23:50:00,283 Epoch: [7/20] Iter:[50/292], Time: 1.77, lr: [0.00023067838680253505], Loss: 1.374686, Loss_D1: 0.621979, Loss_D2: 0.692707, Acc:0.551101, Semantic loss: 0.134365
2025-01-25 23:50:17,872 Epoch: [7/20] Iter:[60/292], Time: 1.77, lr: [0.000230124093459638], Loss: 1.351500, Loss_D1: 0.671864, Loss_D2: 0.695152, Acc:0.538602, Semantic loss: 0.137049
2025-01-25 23:50:35,336 Epoch: [7/20] Iter:[70/292], Time: 1.77, lr: [0.00022956965173124116], Loss: 1.345147, Loss_D1: 0.641483, Loss_D2: 0.690030, Acc:0.533687, Semantic loss: 0.136223
2025-01-25 23:50:52,911 Epoch: [7/20] Iter:[80/292], Time: 1.77, lr: [0.00022901506117921683], Loss: 1.330909, Loss_D1: 0.631914, Loss_D2: 0.692633, Acc:0.531260, Semantic loss: 0.134701
2025-01-25 23:51:10,438 Epoch: [7/20] Iter:[90/292], Time: 1.76, lr: [0.00022846032136296108], Loss: 1.323151, Loss_D1: 0.636841, Loss_D2: 0.692469, Acc:0.531845, Semantic loss: 0.134921
2025-01-25 23:51:28,034 Epoch: [7/20] Iter:[100/292], Time: 1.76, lr: [0.0002279054318393731], Loss: 1.319985, Loss_D1: 0.672351, Loss_D2: 0.693212, Acc:0.530144, Semantic loss: 0.134916
2025-01-25 23:51:45,678 Epoch: [7/20] Iter:[110/292], Time: 1.76, lr: [0.00022735039216283391], Loss: 1.306711, Loss_D1: 0.640927, Loss_D2: 0.694092, Acc:0.527484, Semantic loss: 0.133906
2025-01-25 23:52:03,219 Epoch: [7/20] Iter:[120/292], Time: 1.76, lr: [0.0002267952018851855], Loss: 1.307522, Loss_D1: 0.615361, Loss_D2: 0.692296, Acc:0.529303, Semantic loss: 0.133304
2025-01-25 23:52:20,976 Epoch: [7/20] Iter:[130/292], Time: 1.76, lr: [0.00022623986055570917], Loss: 1.316790, Loss_D1: 0.649939, Loss_D2: 0.693815, Acc:0.531519, Semantic loss: 0.133602
2025-01-25 23:52:38,591 Epoch: [7/20] Iter:[140/292], Time: 1.76, lr: [0.0002256843677211041], Loss: 1.309772, Loss_D1: 0.607120, Loss_D2: 0.692928, Acc:0.532974, Semantic loss: 0.133964
2025-01-25 23:52:56,188 Epoch: [7/20] Iter:[150/292], Time: 1.76, lr: [0.00022512872292546545], Loss: 1.310048, Loss_D1: 0.608016, Loss_D2: 0.693061, Acc:0.533899, Semantic loss: 0.134046
2025-01-25 23:53:13,756 Epoch: [7/20] Iter:[160/292], Time: 1.76, lr: [0.00022457292571026198], Loss: 1.298888, Loss_D1: 0.659454, Loss_D2: 0.693033, Acc:0.531686, Semantic loss: 0.134315
2025-01-25 23:53:31,416 Epoch: [7/20] Iter:[170/292], Time: 1.76, lr: [0.00022401697561431368], Loss: 1.302850, Loss_D1: 0.667222, Loss_D2: 0.692983, Acc:0.533279, Semantic loss: 0.134111
2025-01-25 23:53:48,935 Epoch: [7/20] Iter:[180/292], Time: 1.76, lr: [0.0002234608721737695], Loss: 1.303331, Loss_D1: 0.652165, Loss_D2: 0.692993, Acc:0.535571, Semantic loss: 0.134250
2025-01-25 23:54:06,452 Epoch: [7/20] Iter:[190/292], Time: 1.76, lr: [0.00022290461492208393], Loss: 1.296979, Loss_D1: 0.657415, Loss_D2: 0.693048, Acc:0.535172, Semantic loss: 0.134415
2025-01-25 23:54:24,297 Epoch: [7/20] Iter:[200/292], Time: 1.76, lr: [0.0002223482033899944], Loss: 1.299938, Loss_D1: 0.633999, Loss_D2: 0.693130, Acc:0.534870, Semantic loss: 0.134549
2025-01-25 23:54:41,975 Epoch: [7/20] Iter:[210/292], Time: 1.76, lr: [0.00022179163710549723], Loss: 1.297829, Loss_D1: 0.665484, Loss_D2: 0.693197, Acc:0.533506, Semantic loss: 0.134154
2025-01-25 23:54:59,709 Epoch: [7/20] Iter:[220/292], Time: 1.76, lr: [0.00022123491559382434], Loss: 1.294074, Loss_D1: 0.672805, Loss_D2: 0.693151, Acc:0.533206, Semantic loss: 0.134122
2025-01-25 23:55:17,263 Epoch: [7/20] Iter:[230/292], Time: 1.76, lr: [0.00022067803837741922], Loss: 1.298127, Loss_D1: 0.593679, Loss_D2: 0.693164, Acc:0.534048, Semantic loss: 0.134416
2025-01-25 23:55:34,685 Epoch: [7/20] Iter:[240/292], Time: 1.76, lr: [0.00022012100497591268], Loss: 1.291911, Loss_D1: 0.652096, Loss_D2: 0.693385, Acc:0.532737, Semantic loss: 0.134466
2025-01-25 23:55:52,204 Epoch: [7/20] Iter:[250/292], Time: 1.76, lr: [0.00021956381490609826], Loss: 1.287314, Loss_D1: 0.736137, Loss_D2: 0.692953, Acc:0.531252, Semantic loss: 0.134635
2025-01-25 23:56:09,627 Epoch: [7/20] Iter:[260/292], Time: 1.76, lr: [0.00021900646768190736], Loss: 1.278114, Loss_D1: 0.631030, Loss_D2: 0.693803, Acc:0.529417, Semantic loss: 0.134789
2025-01-25 23:56:27,167 Epoch: [7/20] Iter:[270/292], Time: 1.76, lr: [0.0002184489628143843], Loss: 1.279939, Loss_D1: 0.676875, Loss_D2: 0.693482, Acc:0.530388, Semantic loss: 0.134565
2025-01-25 23:56:44,812 Epoch: [7/20] Iter:[280/292], Time: 1.76, lr: [0.00021789129981166096], Loss: 1.284192, Loss_D1: 0.691061, Loss_D2: 0.693403, Acc:0.531195, Semantic loss: 0.134286
2025-01-25 23:57:02,347 Epoch: [7/20] Iter:[290/292], Time: 1.76, lr: [0.000217333478178931], Loss: 1.280666, Loss_D1: 0.590407, Loss_D2: 0.693122, Acc:0.531264, Semantic loss: 0.133986
2025-01-26 00:00:30,286 0 [0.         0.43586625 0.13578627 0.10420624 0.29538237 0.08589268
 0.05090453 0.00451437] 0.15893609991687288
2025-01-26 00:00:30,286 1 [0.         0.45711205 0.11603612 0.15766745 0.31184898 0.06526213
 0.02197517 0.02949331] 0.16562788719437466
2025-01-26 00:00:30,287 => saving checkpoint to output\loveDa\pidnet_small_loveda_train_AVDcheckpoint.pth.tar
2025-01-26 00:00:30,453 Loss: 1.340, MeanIU:  0.1656, Best_mIoU:  0.2405
2025-01-26 00:00:30,454 [0.         0.45711205 0.11603612 0.15766745 0.31184898 0.06526213
 0.02197517 0.02949331]
2025-01-26 00:00:32,329 Epoch: [8/20] Iter:[0/292], Time: 1.87, lr: [0.00012663869083174783], Loss: 1.314035, Loss_D1: 0.613887, Loss_D2: 0.693138, Acc:0.514922, Semantic loss: 0.129886
2025-01-26 00:00:49,670 Epoch: [8/20] Iter:[10/292], Time: 1.75, lr: [0.00012631337375890777], Loss: 1.287325, Loss_D1: 0.630225, Loss_D2: 0.693307, Acc:0.535974, Semantic loss: 0.127758
2025-01-26 00:01:07,148 Epoch: [8/20] Iter:[20/292], Time: 1.75, lr: [0.00012598796356526137], Loss: 1.323378, Loss_D1: 0.667391, Loss_D2: 0.693081, Acc:0.542778, Semantic loss: 0.128970
2025-01-26 00:01:24,535 Epoch: [8/20] Iter:[30/292], Time: 1.74, lr: [0.00012566245995675616], Loss: 1.346201, Loss_D1: 0.622560, Loss_D2: 0.693037, Acc:0.537583, Semantic loss: 0.131752
2025-01-26 00:01:41,863 Epoch: [8/20] Iter:[40/292], Time: 1.74, lr: [0.00012533686263756192], Loss: 1.325651, Loss_D1: 0.579477, Loss_D2: 0.693186, Acc:0.541067, Semantic loss: 0.129674
2025-01-26 00:01:59,273 Epoch: [8/20] Iter:[50/292], Time: 1.74, lr: [0.00012501117131005475], Loss: 1.326343, Loss_D1: 0.638659, Loss_D2: 0.692696, Acc:0.538294, Semantic loss: 0.129941
2025-01-26 00:02:16,619 Epoch: [8/20] Iter:[60/292], Time: 1.74, lr: [0.00012468538567480094], Loss: 1.317971, Loss_D1: 0.641815, Loss_D2: 0.694182, Acc:0.540039, Semantic loss: 0.129743
2025-01-26 00:02:33,954 Epoch: [8/20] Iter:[70/292], Time: 1.74, lr: [0.00012435950543054068], Loss: 1.319288, Loss_D1: 0.662416, Loss_D2: 0.692892, Acc:0.538618, Semantic loss: 0.130233
2025-01-26 00:02:51,204 Epoch: [8/20] Iter:[80/292], Time: 1.74, lr: [0.00012403353027417162], Loss: 1.320642, Loss_D1: 0.628927, Loss_D2: 0.693215, Acc:0.540446, Semantic loss: 0.131694
2025-01-26 00:03:08,377 Epoch: [8/20] Iter:[90/292], Time: 1.74, lr: [0.00012370745990073205], Loss: 1.314468, Loss_D1: 0.601481, Loss_D2: 0.692937, Acc:0.541060, Semantic loss: 0.130598
2025-01-26 00:03:25,530 Epoch: [8/20] Iter:[100/292], Time: 1.73, lr: [0.00012338129400338426], Loss: 1.289018, Loss_D1: 0.597282, Loss_D2: 0.693182, Acc:0.537218, Semantic loss: 0.130262
2025-01-26 00:03:42,952 Epoch: [8/20] Iter:[110/292], Time: 1.73, lr: [0.00012305503227339723], Loss: 1.281783, Loss_D1: 0.659763, Loss_D2: 0.693389, Acc:0.537091, Semantic loss: 0.130601
2025-01-26 00:04:00,143 Epoch: [8/20] Iter:[120/292], Time: 1.73, lr: [0.00012272867440012945], Loss: 1.280221, Loss_D1: 0.666428, Loss_D2: 0.693319, Acc:0.541065, Semantic loss: 0.130449
2025-01-26 00:04:17,454 Epoch: [8/20] Iter:[130/292], Time: 1.73, lr: [0.00012240222007101127], Loss: 1.264550, Loss_D1: 0.643854, Loss_D2: 0.693305, Acc:0.537870, Semantic loss: 0.131033
2025-01-26 00:04:34,918 Epoch: [8/20] Iter:[140/292], Time: 1.73, lr: [0.00012207566897152737], Loss: 1.259919, Loss_D1: 0.594200, Loss_D2: 0.693153, Acc:0.538990, Semantic loss: 0.130343
2025-01-26 00:04:52,238 Epoch: [8/20] Iter:[150/292], Time: 1.73, lr: [0.0001217490207851988], Loss: 1.276615, Loss_D1: 0.626750, Loss_D2: 0.693029, Acc:0.540628, Semantic loss: 0.129775
2025-01-26 00:05:09,714 Epoch: [8/20] Iter:[160/292], Time: 1.73, lr: [0.00012142227519356472], Loss: 1.284190, Loss_D1: 0.600384, Loss_D2: 0.693126, Acc:0.541998, Semantic loss: 0.129458
2025-01-26 00:05:26,922 Epoch: [8/20] Iter:[170/292], Time: 1.73, lr: [0.00012109543187616403], Loss: 1.286450, Loss_D1: 0.610864, Loss_D2: 0.692948, Acc:0.541350, Semantic loss: 0.129547
2025-01-26 00:05:44,258 Epoch: [8/20] Iter:[180/292], Time: 1.73, lr: [0.00012076849051051687], Loss: 1.290064, Loss_D1: 0.730633, Loss_D2: 0.693208, Acc:0.542090, Semantic loss: 0.129425
2025-01-26 00:06:01,487 Epoch: [8/20] Iter:[190/292], Time: 1.73, lr: [0.0001204414507721057], Loss: 1.277220, Loss_D1: 0.693051, Loss_D2: 0.693033, Acc:0.541767, Semantic loss: 0.129494
2025-01-26 00:06:18,997 Epoch: [8/20] Iter:[200/292], Time: 1.73, lr: [0.00012011431233435633], Loss: 1.276947, Loss_D1: 0.615017, Loss_D2: 0.693147, Acc:0.541900, Semantic loss: 0.129526
2025-01-26 00:06:36,406 Epoch: [8/20] Iter:[210/292], Time: 1.73, lr: [0.00011978707486861856], Loss: 1.273274, Loss_D1: 0.587477, Loss_D2: 0.692985, Acc:0.542589, Semantic loss: 0.129729
2025-01-26 00:06:53,864 Epoch: [8/20] Iter:[220/292], Time: 1.73, lr: [0.00011945973804414659], Loss: 1.282677, Loss_D1: 0.622538, Loss_D2: 0.693056, Acc:0.543866, Semantic loss: 0.129665
2025-01-26 00:07:11,365 Epoch: [8/20] Iter:[230/292], Time: 1.74, lr: [0.0001191323015280793], Loss: 1.283109, Loss_D1: 0.625124, Loss_D2: 0.692992, Acc:0.543846, Semantic loss: 0.129366
2025-01-26 00:07:28,650 Epoch: [8/20] Iter:[240/292], Time: 1.74, lr: [0.00011880476498542022], Loss: 1.280581, Loss_D1: 0.615161, Loss_D2: 0.692995, Acc:0.545043, Semantic loss: 0.129396
2025-01-26 00:07:46,038 Epoch: [8/20] Iter:[250/292], Time: 1.74, lr: [0.00011847712807901728], Loss: 1.282066, Loss_D1: 0.715147, Loss_D2: 0.695377, Acc:0.546191, Semantic loss: 0.129632
2025-01-26 00:08:03,170 Epoch: [8/20] Iter:[260/292], Time: 1.73, lr: [0.00011814939046954214], Loss: 1.281102, Loss_D1: 0.602732, Loss_D2: 0.694248, Acc:0.545457, Semantic loss: 0.129383
2025-01-26 00:08:20,753 Epoch: [8/20] Iter:[270/292], Time: 1.74, lr: [0.0001178215518154695], Loss: 1.287945, Loss_D1: 0.654343, Loss_D2: 0.693094, Acc:0.547205, Semantic loss: 0.129393
2025-01-26 00:08:38,258 Epoch: [8/20] Iter:[280/292], Time: 1.74, lr: [0.00011749361177305598], Loss: 1.287206, Loss_D1: 0.624869, Loss_D2: 0.693158, Acc:0.547666, Semantic loss: 0.129203
2025-01-26 00:08:55,588 Epoch: [8/20] Iter:[290/292], Time: 1.74, lr: [0.00011716556999631894], Loss: 1.283795, Loss_D1: 0.595978, Loss_D2: 0.692969, Acc:0.548069, Semantic loss: 0.129026
2025-01-26 00:12:18,580 0 [0.         0.46671145 0.19606754 0.11813983 0.24799529 0.17707197
 0.06344859 0.02930593] 0.18553437235247103
2025-01-26 00:12:18,580 1 [0.         0.4980609  0.1949083  0.23246531 0.27538954 0.11906537
 0.02043521 0.20524454] 0.2207955958656139
2025-01-26 00:12:18,580 => saving checkpoint to output\loveDa\pidnet_small_loveda_train_AVDcheckpoint.pth.tar
2025-01-26 00:12:18,741 Loss: 1.243, MeanIU:  0.2208, Best_mIoU:  0.2405
2025-01-26 00:12:18,742 [0.         0.4980609  0.1949083  0.23246531 0.27538954 0.11906537
 0.02043521 0.20524454]
2025-01-26 00:12:20,491 Epoch: [9/20] Iter:[0/292], Time: 1.75, lr: [6.152102938411417e-05], Loss: 0.853610, Loss_D1: 0.703026, Loss_D2: 0.693108, Acc:0.431320, Semantic loss: 0.138267
2025-01-26 00:12:37,760 Epoch: [9/20] Iter:[10/292], Time: 1.73, lr: [6.134862105480479e-05], Loss: 1.116332, Loss_D1: 0.593681, Loss_D2: 0.693194, Acc:0.569555, Semantic loss: 0.121140
2025-01-26 00:12:55,202 Epoch: [9/20] Iter:[20/292], Time: 1.74, lr: [6.117615887304429e-05], Loss: 1.193383, Loss_D1: 0.604790, Loss_D2: 0.692866, Acc:0.557276, Semantic loss: 0.130437
2025-01-26 00:13:12,484 Epoch: [9/20] Iter:[30/292], Time: 1.73, lr: [6.100364265322126e-05], Loss: 1.185621, Loss_D1: 0.567168, Loss_D2: 0.693232, Acc:0.558925, Semantic loss: 0.128914
2025-01-26 00:13:29,851 Epoch: [9/20] Iter:[40/292], Time: 1.73, lr: [6.083107220849909e-05], Loss: 1.219518, Loss_D1: 0.632422, Loss_D2: 0.693556, Acc:0.562035, Semantic loss: 0.127673
2025-01-26 00:13:47,287 Epoch: [9/20] Iter:[50/292], Time: 1.74, lr: [6.0658447350804025e-05], Loss: 1.189346, Loss_D1: 0.539175, Loss_D2: 0.733566, Acc:0.559822, Semantic loss: 0.127451
2025-01-26 00:14:04,558 Epoch: [9/20] Iter:[60/292], Time: 1.73, lr: [6.048576789081308e-05], Loss: 1.207733, Loss_D1: 0.544182, Loss_D2: 0.680864, Acc:0.558350, Semantic loss: 0.128368
2025-01-26 00:14:21,839 Epoch: [9/20] Iter:[70/292], Time: 1.73, lr: [6.0313033637941665e-05], Loss: 1.177389, Loss_D1: 0.643134, Loss_D2: 0.697846, Acc:0.550053, Semantic loss: 0.128528
2025-01-26 00:14:39,366 Epoch: [9/20] Iter:[80/292], Time: 1.74, lr: [6.0140244400331235e-05], Loss: 1.206286, Loss_D1: 0.672535, Loss_D2: 0.694388, Acc:0.552865, Semantic loss: 0.130214
2025-01-26 00:14:56,609 Epoch: [9/20] Iter:[90/292], Time: 1.73, lr: [5.996739998483659e-05], Loss: 1.205807, Loss_D1: 0.659404, Loss_D2: 0.696318, Acc:0.551394, Semantic loss: 0.129680
2025-01-26 00:15:13,997 Epoch: [9/20] Iter:[100/292], Time: 1.74, lr: [5.97945001970131e-05], Loss: 1.212498, Loss_D1: 0.599900, Loss_D2: 0.693991, Acc:0.555995, Semantic loss: 0.129160
2025-01-26 00:15:31,472 Epoch: [9/20] Iter:[110/292], Time: 1.74, lr: [5.9621544841103885e-05], Loss: 1.228991, Loss_D1: 0.647188, Loss_D2: 0.694448, Acc:0.557504, Semantic loss: 0.128738
2025-01-26 00:15:48,897 Epoch: [9/20] Iter:[120/292], Time: 1.74, lr: [5.94485337200265e-05], Loss: 1.221307, Loss_D1: 0.576505, Loss_D2: 0.693640, Acc:0.555940, Semantic loss: 0.128369
2025-01-26 00:16:06,342 Epoch: [9/20] Iter:[130/292], Time: 1.74, lr: [5.927546663535984e-05], Loss: 1.231000, Loss_D1: 0.629745, Loss_D2: 0.693279, Acc:0.557895, Semantic loss: 0.128279
2025-01-26 00:16:23,547 Epoch: [9/20] Iter:[140/292], Time: 1.74, lr: [5.9102343387330504e-05], Loss: 1.236442, Loss_D1: 0.650945, Loss_D2: 0.692536, Acc:0.557531, Semantic loss: 0.127946
2025-01-26 00:16:40,916 Epoch: [9/20] Iter:[150/292], Time: 1.74, lr: [5.892916377479926e-05], Loss: 1.230902, Loss_D1: 0.638088, Loss_D2: 0.693779, Acc:0.555914, Semantic loss: 0.127564
2025-01-26 00:16:58,399 Epoch: [9/20] Iter:[160/292], Time: 1.74, lr: [5.8755927595247184e-05], Loss: 1.229915, Loss_D1: 0.663485, Loss_D2: 0.693207, Acc:0.554797, Semantic loss: 0.127085
2025-01-26 00:17:15,801 Epoch: [9/20] Iter:[170/292], Time: 1.74, lr: [5.858263464476163e-05], Loss: 1.230160, Loss_D1: 0.568246, Loss_D2: 0.692837, Acc:0.553543, Semantic loss: 0.126932
2025-01-26 00:17:33,261 Epoch: [9/20] Iter:[180/292], Time: 1.74, lr: [5.8409284718022036e-05], Loss: 1.230302, Loss_D1: 0.558157, Loss_D2: 0.695181, Acc:0.552799, Semantic loss: 0.126366
2025-01-26 00:17:50,503 Epoch: [9/20] Iter:[190/292], Time: 1.74, lr: [5.823587760828549e-05], Loss: 1.230864, Loss_D1: 0.583447, Loss_D2: 0.693112, Acc:0.552470, Semantic loss: 0.125990
2025-01-26 00:18:07,850 Epoch: [9/20] Iter:[200/292], Time: 1.74, lr: [5.806241310737221e-05], Loss: 1.239470, Loss_D1: 0.608441, Loss_D2: 0.693725, Acc:0.552751, Semantic loss: 0.126069
2025-01-26 00:18:25,299 Epoch: [9/20] Iter:[210/292], Time: 1.74, lr: [5.78888910056507e-05], Loss: 1.244193, Loss_D1: 0.597459, Loss_D2: 0.692992, Acc:0.553885, Semantic loss: 0.126566
2025-01-26 00:18:42,683 Epoch: [9/20] Iter:[220/292], Time: 1.74, lr: [5.771531109202277e-05], Loss: 1.246792, Loss_D1: 0.646102, Loss_D2: 0.693077, Acc:0.554098, Semantic loss: 0.126541
2025-01-26 00:19:00,025 Epoch: [9/20] Iter:[230/292], Time: 1.74, lr: [5.754167315390834e-05], Loss: 1.246192, Loss_D1: 0.606438, Loss_D2: 0.692999, Acc:0.554359, Semantic loss: 0.126439
2025-01-26 00:19:17,341 Epoch: [9/20] Iter:[240/292], Time: 1.74, lr: [5.736797697722999e-05], Loss: 1.243808, Loss_D1: 0.582634, Loss_D2: 0.693350, Acc:0.554663, Semantic loss: 0.126078
2025-01-26 00:19:34,695 Epoch: [9/20] Iter:[250/292], Time: 1.74, lr: [5.719422234639743e-05], Loss: 1.247409, Loss_D1: 0.620973, Loss_D2: 0.693160, Acc:0.555117, Semantic loss: 0.126440
2025-01-26 00:19:52,022 Epoch: [9/20] Iter:[260/292], Time: 1.74, lr: [5.702040904429161e-05], Loss: 1.251128, Loss_D1: 0.600858, Loss_D2: 0.694780, Acc:0.555661, Semantic loss: 0.126515
2025-01-26 00:20:09,373 Epoch: [9/20] Iter:[270/292], Time: 1.74, lr: [5.6846536852248614e-05], Loss: 1.250323, Loss_D1: 0.539868, Loss_D2: 0.693496, Acc:0.556259, Semantic loss: 0.126507
2025-01-26 00:20:26,878 Epoch: [9/20] Iter:[280/292], Time: 1.74, lr: [5.667260555004346e-05], Loss: 1.254459, Loss_D1: 0.532266, Loss_D2: 0.689274, Acc:0.556508, Semantic loss: 0.126389
2025-01-26 00:20:44,364 Epoch: [9/20] Iter:[290/292], Time: 1.74, lr: [5.649861491587356e-05], Loss: 1.249910, Loss_D1: 0.678369, Loss_D2: 0.692047, Acc:0.556644, Semantic loss: 0.126286
2025-01-26 00:24:07,227 0 [0.         0.46580668 0.20775322 0.12495171 0.33707496 0.14448927
 0.05332301 0.01902873] 0.19320394140487154
2025-01-26 00:24:07,228 1 [0.         0.52427971 0.22024068 0.29921014 0.39061413 0.08753056
 0.0262592  0.37290024] 0.27443352229129625
2025-01-26 00:24:07,228 => saving checkpoint to output\loveDa\pidnet_small_loveda_train_AVDcheckpoint.pth.tar
2025-01-26 00:24:07,490 Loss: 1.225, MeanIU:  0.2744, Best_mIoU:  0.2744
2025-01-26 00:24:07,490 [0.         0.52427971 0.22024068 0.29921014 0.39061413 0.08753056
 0.0262592  0.37290024]
2025-01-26 00:24:09,374 Epoch: [10/20] Iter:[0/292], Time: 1.88, lr: [2.6482039688098763e-05], Loss: 0.821738, Loss_D1: 0.584180, Loss_D2: 0.690906, Acc:0.371164, Semantic loss: 0.123814
2025-01-26 00:24:26,509 Epoch: [10/20] Iter:[10/292], Time: 1.73, lr: [2.6400402968956673e-05], Loss: 1.207050, Loss_D1: 0.635528, Loss_D2: 0.697488, Acc:0.533417, Semantic loss: 0.125324
2025-01-26 00:24:43,944 Epoch: [10/20] Iter:[20/292], Time: 1.74, lr: [2.631873819108041e-05], Loss: 1.298160, Loss_D1: 0.613981, Loss_D2: 0.703762, Acc:0.566350, Semantic loss: 0.125971
2025-01-26 00:25:01,279 Epoch: [10/20] Iter:[30/292], Time: 1.73, lr: [2.6237045248021523e-05], Loss: 1.286803, Loss_D1: 0.593639, Loss_D2: 0.669998, Acc:0.566985, Semantic loss: 0.123311
2025-01-26 00:25:18,688 Epoch: [10/20] Iter:[40/292], Time: 1.74, lr: [2.6155324032557906e-05], Loss: 1.272862, Loss_D1: 0.633322, Loss_D2: 0.690821, Acc:0.566960, Semantic loss: 0.124751
2025-01-26 00:25:36,109 Epoch: [10/20] Iter:[50/292], Time: 1.74, lr: [2.607357443668551e-05], Loss: 1.221011, Loss_D1: 0.635376, Loss_D2: 0.696872, Acc:0.561243, Semantic loss: 0.124409
2025-01-26 00:25:53,595 Epoch: [10/20] Iter:[60/292], Time: 1.74, lr: [2.5991796351609848e-05], Loss: 1.234643, Loss_D1: 0.595707, Loss_D2: 0.700021, Acc:0.566735, Semantic loss: 0.123723
2025-01-26 00:26:10,878 Epoch: [10/20] Iter:[70/292], Time: 1.74, lr: [2.590998966773747e-05], Loss: 1.213756, Loss_D1: 0.595715, Loss_D2: 0.692708, Acc:0.559734, Semantic loss: 0.123180
2025-01-26 00:26:28,219 Epoch: [10/20] Iter:[80/292], Time: 1.74, lr: [2.5828154274667217e-05], Loss: 1.224476, Loss_D1: 0.615960, Loss_D2: 0.692326, Acc:0.562273, Semantic loss: 0.124299
2025-01-26 00:26:45,644 Epoch: [10/20] Iter:[90/292], Time: 1.74, lr: [2.5746290061181468e-05], Loss: 1.220937, Loss_D1: 0.597995, Loss_D2: 0.702988, Acc:0.566224, Semantic loss: 0.124056
2025-01-26 00:27:02,811 Epoch: [10/20] Iter:[100/292], Time: 1.74, lr: [2.5664396915237138e-05], Loss: 1.222599, Loss_D1: 0.622651, Loss_D2: 0.696565, Acc:0.567943, Semantic loss: 0.124054
2025-01-26 00:27:20,178 Epoch: [10/20] Iter:[110/292], Time: 1.74, lr: [2.5582474723956637e-05], Loss: 1.234105, Loss_D1: 0.602030, Loss_D2: 0.689532, Acc:0.566607, Semantic loss: 0.125119
2025-01-26 00:27:37,365 Epoch: [10/20] Iter:[120/292], Time: 1.73, lr: [2.5500523373618654e-05], Loss: 1.229292, Loss_D1: 0.600173, Loss_D2: 0.696202, Acc:0.564249, Semantic loss: 0.125021
2025-01-26 00:27:54,782 Epoch: [10/20] Iter:[130/292], Time: 1.74, lr: [2.5418542749648792e-05], Loss: 1.216512, Loss_D1: 0.579966, Loss_D2: 0.693700, Acc:0.556048, Semantic loss: 0.124998
2025-01-26 00:28:12,188 Epoch: [10/20] Iter:[140/292], Time: 1.74, lr: [2.533653273661013e-05], Loss: 1.223464, Loss_D1: 0.608659, Loss_D2: 0.693405, Acc:0.558484, Semantic loss: 0.124316
2025-01-26 00:28:29,639 Epoch: [10/20] Iter:[150/292], Time: 1.74, lr: [2.5254493218193557e-05], Loss: 1.228737, Loss_D1: 0.540352, Loss_D2: 0.690851, Acc:0.560081, Semantic loss: 0.124439
2025-01-26 00:28:46,832 Epoch: [10/20] Iter:[160/292], Time: 1.74, lr: [2.5172424077208048e-05], Loss: 1.239502, Loss_D1: 0.576993, Loss_D2: 0.692042, Acc:0.562806, Semantic loss: 0.124432
2025-01-26 00:29:04,208 Epoch: [10/20] Iter:[170/292], Time: 1.74, lr: [2.5090325195570737e-05], Loss: 1.249051, Loss_D1: 0.608976, Loss_D2: 0.692638, Acc:0.564932, Semantic loss: 0.124585
2025-01-26 00:29:21,483 Epoch: [10/20] Iter:[180/292], Time: 1.73, lr: [2.500819645429685e-05], Loss: 1.246080, Loss_D1: 0.583208, Loss_D2: 0.689687, Acc:0.564205, Semantic loss: 0.124382
2025-01-26 00:29:38,822 Epoch: [10/20] Iter:[190/292], Time: 1.73, lr: [2.4926037733489535e-05], Loss: 1.246885, Loss_D1: 0.553826, Loss_D2: 0.693287, Acc:0.563974, Semantic loss: 0.124369
2025-01-26 00:29:56,129 Epoch: [10/20] Iter:[200/292], Time: 1.73, lr: [2.484384891232946e-05], Loss: 1.251846, Loss_D1: 0.623021, Loss_D2: 0.690592, Acc:0.565230, Semantic loss: 0.124508
2025-01-26 00:30:13,562 Epoch: [10/20] Iter:[210/292], Time: 1.73, lr: [2.4761629869064345e-05], Loss: 1.252709, Loss_D1: 0.497514, Loss_D2: 0.689792, Acc:0.566716, Semantic loss: 0.124366
2025-01-26 00:30:30,719 Epoch: [10/20] Iter:[220/292], Time: 1.73, lr: [2.467938048099823e-05], Loss: 1.248629, Loss_D1: 0.604917, Loss_D2: 0.691917, Acc:0.564531, Semantic loss: 0.124341
2025-01-26 00:30:48,035 Epoch: [10/20] Iter:[230/292], Time: 1.73, lr: [2.4597100624480704e-05], Loss: 1.254630, Loss_D1: 0.556505, Loss_D2: 0.691188, Acc:0.564659, Semantic loss: 0.124499
2025-01-26 00:31:05,133 Epoch: [10/20] Iter:[240/292], Time: 1.73, lr: [2.4514790174895834e-05], Loss: 1.251195, Loss_D1: 0.563726, Loss_D2: 0.691313, Acc:0.564520, Semantic loss: 0.124264
2025-01-26 00:31:22,397 Epoch: [10/20] Iter:[250/292], Time: 1.73, lr: [2.443244900665107e-05], Loss: 1.248207, Loss_D1: 0.561002, Loss_D2: 0.696099, Acc:0.564917, Semantic loss: 0.124028
2025-01-26 00:31:39,763 Epoch: [10/20] Iter:[260/292], Time: 1.73, lr: [2.4350076993165826e-05], Loss: 1.248962, Loss_D1: 0.584438, Loss_D2: 0.690648, Acc:0.564534, Semantic loss: 0.123892
2025-01-26 00:31:57,265 Epoch: [10/20] Iter:[270/292], Time: 1.73, lr: [2.4267674006860012e-05], Loss: 1.250190, Loss_D1: 0.572074, Loss_D2: 0.689052, Acc:0.564844, Semantic loss: 0.123748
2025-01-26 00:32:14,648 Epoch: [10/20] Iter:[280/292], Time: 1.73, lr: [2.418523991914235e-05], Loss: 1.251754, Loss_D1: 0.574747, Loss_D2: 0.694890, Acc:0.565412, Semantic loss: 0.123542
2025-01-26 00:32:32,044 Epoch: [10/20] Iter:[290/292], Time: 1.73, lr: [2.4102774600398442e-05], Loss: 1.252216, Loss_D1: 0.560325, Loss_D2: 0.693683, Acc:0.566653, Semantic loss: 0.123377
2025-01-26 00:35:56,734 0 [0.         0.46631118 0.20691585 0.12137929 0.30871579 0.15441691
 0.10369612 0.02104683] 0.19749742321293978
2025-01-26 00:35:56,735 1 [0.         0.50598537 0.2201872  0.26008471 0.35941393 0.118801
 0.05378655 0.30904691] 0.2610436687415699
2025-01-26 00:35:56,735 => saving checkpoint to output\loveDa\pidnet_small_loveda_train_AVDcheckpoint.pth.tar
2025-01-26 00:35:56,902 Loss: 1.254, MeanIU:  0.2610, Best_mIoU:  0.2744
2025-01-26 00:35:56,903 [0.         0.50598537 0.2201872  0.26008471 0.35941393 0.118801
 0.05378655 0.30904691]
2025-01-26 00:35:58,730 Epoch: [11/20] Iter:[0/292], Time: 1.82, lr: [9.985401711645102e-06], Loss: 0.734112, Loss_D1: 0.577747, Loss_D2: 0.689071, Acc:0.463589, Semantic loss: 0.097930
2025-01-26 00:36:16,338 Epoch: [11/20] Iter:[10/292], Time: 1.77, lr: [9.951198615146152e-06], Loss: 1.203395, Loss_D1: 0.688615, Loss_D2: 0.692766, Acc:0.582698, Semantic loss: 0.122087
2025-01-26 00:36:33,853 Epoch: [11/20] Iter:[20/292], Time: 1.76, lr: [9.916982451528415e-06], Loss: 1.180017, Loss_D1: 0.532586, Loss_D2: 0.696492, Acc:0.570939, Semantic loss: 0.119778
2025-01-26 00:36:51,326 Epoch: [11/20] Iter:[30/292], Time: 1.76, lr: [9.882753165666666e-06], Loss: 1.167291, Loss_D1: 0.605278, Loss_D2: 0.697354, Acc:0.564066, Semantic loss: 0.119126
2025-01-26 00:37:08,776 Epoch: [11/20] Iter:[40/292], Time: 1.75, lr: [9.84851070199002e-06], Loss: 1.169921, Loss_D1: 0.661917, Loss_D2: 0.690665, Acc:0.560779, Semantic loss: 0.120094
2025-01-26 00:37:26,053 Epoch: [11/20] Iter:[50/292], Time: 1.75, lr: [9.814255004476563e-06], Loss: 1.216342, Loss_D1: 0.552522, Loss_D2: 0.692926, Acc:0.564918, Semantic loss: 0.120062
2025-01-26 00:37:43,695 Epoch: [11/20] Iter:[60/292], Time: 1.75, lr: [9.77998601664796e-06], Loss: 1.245149, Loss_D1: 0.548149, Loss_D2: 0.692457, Acc:0.575065, Semantic loss: 0.120346
2025-01-26 00:38:01,133 Epoch: [11/20] Iter:[70/292], Time: 1.75, lr: [9.745703681563908e-06], Loss: 1.249641, Loss_D1: 0.595130, Loss_D2: 0.692664, Acc:0.573641, Semantic loss: 0.120124
2025-01-26 00:38:18,666 Epoch: [11/20] Iter:[80/292], Time: 1.75, lr: [9.711407941816573e-06], Loss: 1.269014, Loss_D1: 0.547336, Loss_D2: 0.692421, Acc:0.575617, Semantic loss: 0.121100
2025-01-26 00:38:36,568 Epoch: [11/20] Iter:[90/292], Time: 1.75, lr: [9.677098739524871e-06], Loss: 1.260489, Loss_D1: 0.558776, Loss_D2: 0.693123, Acc:0.579394, Semantic loss: 0.120999
2025-01-26 00:38:54,153 Epoch: [11/20] Iter:[100/292], Time: 1.75, lr: [9.64277601632871e-06], Loss: 1.275874, Loss_D1: 0.553138, Loss_D2: 0.693080, Acc:0.580731, Semantic loss: 0.120978
2025-01-26 00:39:11,578 Epoch: [11/20] Iter:[110/292], Time: 1.75, lr: [9.608439713383089e-06], Loss: 1.298725, Loss_D1: 0.575970, Loss_D2: 0.693093, Acc:0.580636, Semantic loss: 0.121730
2025-01-26 00:39:29,002 Epoch: [11/20] Iter:[120/292], Time: 1.75, lr: [9.574089771352148e-06], Loss: 1.281743, Loss_D1: 0.665139, Loss_D2: 0.693046, Acc:0.574346, Semantic loss: 0.121419
2025-01-26 00:39:46,836 Epoch: [11/20] Iter:[130/292], Time: 1.76, lr: [9.5397261304031e-06], Loss: 1.289696, Loss_D1: 0.538108, Loss_D2: 0.693297, Acc:0.577270, Semantic loss: 0.121416
2025-01-26 00:40:04,308 Epoch: [11/20] Iter:[140/292], Time: 1.75, lr: [9.505348730200041e-06], Loss: 1.279328, Loss_D1: 0.658109, Loss_D2: 0.692310, Acc:0.574447, Semantic loss: 0.121662
2025-01-26 00:40:21,681 Epoch: [11/20] Iter:[150/292], Time: 1.75, lr: [9.47095750989771e-06], Loss: 1.273902, Loss_D1: 0.573346, Loss_D2: 0.693282, Acc:0.570985, Semantic loss: 0.122132
2025-01-26 00:40:39,172 Epoch: [11/20] Iter:[160/292], Time: 1.75, lr: [9.436552408135086e-06], Loss: 1.271928, Loss_D1: 0.498508, Loss_D2: 0.692630, Acc:0.572267, Semantic loss: 0.122371
2025-01-26 00:40:56,497 Epoch: [11/20] Iter:[170/292], Time: 1.75, lr: [9.402133363028936e-06], Loss: 1.260972, Loss_D1: 0.687218, Loss_D2: 0.691796, Acc:0.570075, Semantic loss: 0.122229
2025-01-26 00:41:13,744 Epoch: [11/20] Iter:[180/292], Time: 1.75, lr: [9.3677003121672e-06], Loss: 1.256955, Loss_D1: 0.567713, Loss_D2: 0.693437, Acc:0.570563, Semantic loss: 0.121699
2025-01-26 00:41:31,107 Epoch: [11/20] Iter:[190/292], Time: 1.75, lr: [9.333253192602313e-06], Loss: 1.255946, Loss_D1: 0.587671, Loss_D2: 0.690272, Acc:0.570001, Semantic loss: 0.121923
2025-01-26 00:41:48,541 Epoch: [11/20] Iter:[200/292], Time: 1.75, lr: [9.298791940844394e-06], Loss: 1.259517, Loss_D1: 0.524445, Loss_D2: 0.696820, Acc:0.573298, Semantic loss: 0.121881
2025-01-26 00:42:05,923 Epoch: [11/20] Iter:[210/292], Time: 1.75, lr: [9.264316492854304e-06], Loss: 1.262340, Loss_D1: 0.545605, Loss_D2: 0.694038, Acc:0.574661, Semantic loss: 0.122060
2025-01-26 00:42:23,423 Epoch: [11/20] Iter:[220/292], Time: 1.75, lr: [9.22982678403662e-06], Loss: 1.260120, Loss_D1: 0.584039, Loss_D2: 0.691127, Acc:0.574842, Semantic loss: 0.122275
2025-01-26 00:42:40,769 Epoch: [11/20] Iter:[230/292], Time: 1.75, lr: [9.195322749232462e-06], Loss: 1.263735, Loss_D1: 0.618283, Loss_D2: 0.693885, Acc:0.576090, Semantic loss: 0.122518
2025-01-26 00:42:58,177 Epoch: [11/20] Iter:[240/292], Time: 1.75, lr: [9.16080432271221e-06], Loss: 1.252909, Loss_D1: 0.559290, Loss_D2: 0.692675, Acc:0.574370, Semantic loss: 0.122362
2025-01-26 00:43:15,356 Epoch: [11/20] Iter:[250/292], Time: 1.75, lr: [9.126271438168099e-06], Loss: 1.245487, Loss_D1: 0.580556, Loss_D2: 0.693841, Acc:0.571814, Semantic loss: 0.122435
2025-01-26 00:43:32,728 Epoch: [11/20] Iter:[260/292], Time: 1.75, lr: [9.091724028706669e-06], Loss: 1.244529, Loss_D1: 0.581687, Loss_D2: 0.692248, Acc:0.570286, Semantic loss: 0.122422
2025-01-26 00:43:49,954 Epoch: [11/20] Iter:[270/292], Time: 1.75, lr: [9.057162026841103e-06], Loss: 1.243671, Loss_D1: 0.577792, Loss_D2: 0.692229, Acc:0.570425, Semantic loss: 0.122175
2025-01-26 00:44:07,308 Epoch: [11/20] Iter:[280/292], Time: 1.75, lr: [9.022585364483425e-06], Loss: 1.245759, Loss_D1: 0.609045, Loss_D2: 0.693159, Acc:0.569499, Semantic loss: 0.122356
2025-01-26 00:44:24,880 Epoch: [11/20] Iter:[290/292], Time: 1.75, lr: [8.987993972936562e-06], Loss: 1.248530, Loss_D1: 0.618824, Loss_D2: 0.689881, Acc:0.569009, Semantic loss: 0.122552
2025-01-26 00:47:49,794 0 [0.         0.45887937 0.19343391 0.11445376 0.30519253 0.1565612
 0.08608872 0.01967684] 0.19061233112394044
2025-01-26 00:47:49,795 1 [0.         0.48177577 0.17087175 0.2624945  0.36542067 0.11782969
 0.04009486 0.29825613] 0.2481061952578559
2025-01-26 00:47:49,795 => saving checkpoint to output\loveDa\pidnet_small_loveda_train_AVDcheckpoint.pth.tar
2025-01-26 00:47:49,965 Loss: 1.241, MeanIU:  0.2481, Best_mIoU:  0.2744
2025-01-26 00:47:49,966 [0.         0.48177577 0.17087175 0.2624945  0.36542067 0.11782969
 0.04009486 0.29825613]
2025-01-26 00:47:51,880 Epoch: [12/20] Iter:[0/292], Time: 1.91, lr: [3.2761614503920024e-06], Loss: 2.062928, Loss_D1: 0.542988, Loss_D2: 0.693256, Acc:0.693714, Semantic loss: 0.123696
2025-01-26 00:48:09,139 Epoch: [12/20] Iter:[10/292], Time: 1.74, lr: [3.2635365471040507e-06], Loss: 1.249030, Loss_D1: 0.701860, Loss_D2: 0.692809, Acc:0.600919, Semantic loss: 0.117921
2025-01-26 00:48:26,722 Epoch: [12/20] Iter:[20/292], Time: 1.75, lr: [3.250906214900194e-06], Loss: 1.199666, Loss_D1: 0.507609, Loss_D2: 0.692517, Acc:0.592817, Semantic loss: 0.116643
2025-01-26 00:48:44,261 Epoch: [12/20] Iter:[30/292], Time: 1.75, lr: [3.238270427989696e-06], Loss: 1.212397, Loss_D1: 0.560171, Loss_D2: 0.691257, Acc:0.592828, Semantic loss: 0.117248
2025-01-26 00:49:01,949 Epoch: [12/20] Iter:[40/292], Time: 1.76, lr: [3.2256291603469053e-06], Loss: 1.239060, Loss_D1: 0.639111, Loss_D2: 0.695148, Acc:0.589097, Semantic loss: 0.121080
2025-01-26 00:49:19,354 Epoch: [12/20] Iter:[50/292], Time: 1.75, lr: [3.2129823857080708e-06], Loss: 1.252464, Loss_D1: 0.647604, Loss_D2: 0.692142, Acc:0.587290, Semantic loss: 0.120838
2025-01-26 00:49:36,681 Epoch: [12/20] Iter:[60/292], Time: 1.75, lr: [3.200330077568121e-06], Loss: 1.232561, Loss_D1: 0.651734, Loss_D2: 0.704500, Acc:0.583997, Semantic loss: 0.120513
2025-01-26 00:49:54,281 Epoch: [12/20] Iter:[70/292], Time: 1.75, lr: [3.187672209177374e-06], Loss: 1.238279, Loss_D1: 0.539347, Loss_D2: 0.681907, Acc:0.580682, Semantic loss: 0.123211
2025-01-26 00:50:11,909 Epoch: [12/20] Iter:[80/292], Time: 1.75, lr: [3.1750087535381895e-06], Loss: 1.233577, Loss_D1: 0.541347, Loss_D2: 0.700912, Acc:0.574888, Semantic loss: 0.123180
2025-01-26 00:50:29,397 Epoch: [12/20] Iter:[90/292], Time: 1.75, lr: [3.1623396834015625e-06], Loss: 1.214505, Loss_D1: 0.713633, Loss_D2: 0.699801, Acc:0.570351, Semantic loss: 0.123378
2025-01-26 00:50:46,903 Epoch: [12/20] Iter:[100/292], Time: 1.75, lr: [3.149664971263648e-06], Loss: 1.224039, Loss_D1: 0.634792, Loss_D2: 0.696014, Acc:0.571328, Semantic loss: 0.123409
2025-01-26 00:51:04,508 Epoch: [12/20] Iter:[110/292], Time: 1.75, lr: [3.136984589362236e-06], Loss: 1.234047, Loss_D1: 0.536904, Loss_D2: 0.691587, Acc:0.573314, Semantic loss: 0.122688
2025-01-26 00:51:22,055 Epoch: [12/20] Iter:[120/292], Time: 1.75, lr: [3.1242985096731433e-06], Loss: 1.236436, Loss_D1: 0.636773, Loss_D2: 0.693944, Acc:0.574915, Semantic loss: 0.122176
2025-01-26 00:51:39,444 Epoch: [12/20] Iter:[130/292], Time: 1.75, lr: [3.111606703906554e-06], Loss: 1.232107, Loss_D1: 0.556484, Loss_D2: 0.693109, Acc:0.572396, Semantic loss: 0.122249
2025-01-26 00:51:56,732 Epoch: [12/20] Iter:[140/292], Time: 1.75, lr: [3.0989091435032836e-06], Loss: 1.230339, Loss_D1: 0.611390, Loss_D2: 0.692892, Acc:0.569203, Semantic loss: 0.121996
2025-01-26 00:52:14,109 Epoch: [12/20] Iter:[150/292], Time: 1.75, lr: [3.086205799630975e-06], Loss: 1.229509, Loss_D1: 0.618766, Loss_D2: 0.693132, Acc:0.568600, Semantic loss: 0.122552
2025-01-26 00:52:31,226 Epoch: [12/20] Iter:[160/292], Time: 1.75, lr: [3.073496643180226e-06], Loss: 1.231340, Loss_D1: 0.483884, Loss_D2: 0.692762, Acc:0.569390, Semantic loss: 0.122134
2025-01-26 00:52:48,600 Epoch: [12/20] Iter:[170/292], Time: 1.75, lr: [3.0607816447606363e-06], Loss: 1.228985, Loss_D1: 0.606609, Loss_D2: 0.692922, Acc:0.569105, Semantic loss: 0.122180
2025-01-26 00:53:06,163 Epoch: [12/20] Iter:[180/292], Time: 1.75, lr: [3.0480607746967933e-06], Loss: 1.228729, Loss_D1: 0.510829, Loss_D2: 0.692647, Acc:0.569424, Semantic loss: 0.121925
2025-01-26 00:53:23,590 Epoch: [12/20] Iter:[190/292], Time: 1.75, lr: [3.035334003024163e-06], Loss: 1.236236, Loss_D1: 0.580600, Loss_D2: 0.693830, Acc:0.569762, Semantic loss: 0.122065
2025-01-26 00:53:41,098 Epoch: [12/20] Iter:[200/292], Time: 1.75, lr: [3.022601299484922e-06], Loss: 1.230704, Loss_D1: 0.563834, Loss_D2: 0.692847, Acc:0.568452, Semantic loss: 0.121694
2025-01-26 00:53:58,339 Epoch: [12/20] Iter:[210/292], Time: 1.75, lr: [3.009862633523693e-06], Loss: 1.233329, Loss_D1: 0.719920, Loss_D2: 0.693311, Acc:0.569438, Semantic loss: 0.121721
2025-01-26 00:54:15,738 Epoch: [12/20] Iter:[220/292], Time: 1.75, lr: [2.9971179742832057e-06], Loss: 1.233072, Loss_D1: 0.607485, Loss_D2: 0.693432, Acc:0.569190, Semantic loss: 0.122032
2025-01-26 00:54:33,039 Epoch: [12/20] Iter:[230/292], Time: 1.74, lr: [2.98436729059988e-06], Loss: 1.226510, Loss_D1: 0.465933, Loss_D2: 0.693861, Acc:0.568449, Semantic loss: 0.121725
2025-01-26 00:54:50,297 Epoch: [12/20] Iter:[240/292], Time: 1.74, lr: [2.9716105509993053e-06], Loss: 1.227549, Loss_D1: 0.544536, Loss_D2: 0.693921, Acc:0.569320, Semantic loss: 0.121569
2025-01-26 00:55:07,621 Epoch: [12/20] Iter:[250/292], Time: 1.74, lr: [2.9588477236916515e-06], Loss: 1.231012, Loss_D1: 0.579262, Loss_D2: 0.692897, Acc:0.569064, Semantic loss: 0.121788
2025-01-26 00:55:24,819 Epoch: [12/20] Iter:[260/292], Time: 1.74, lr: [2.946078776566972e-06], Loss: 1.227851, Loss_D1: 0.501887, Loss_D2: 0.693870, Acc:0.569880, Semantic loss: 0.121669
2025-01-26 00:55:42,079 Epoch: [12/20] Iter:[270/292], Time: 1.74, lr: [2.9333036771904313e-06], Loss: 1.227202, Loss_D1: 0.588010, Loss_D2: 0.693027, Acc:0.569165, Semantic loss: 0.121694
2025-01-26 00:55:59,364 Epoch: [12/20] Iter:[280/292], Time: 1.74, lr: [2.9205223927974215e-06], Loss: 1.231144, Loss_D1: 0.606819, Loss_D2: 0.693249, Acc:0.568889, Semantic loss: 0.121757
2025-01-26 00:56:16,783 Epoch: [12/20] Iter:[290/292], Time: 1.74, lr: [2.907734890288591e-06], Loss: 1.238017, Loss_D1: 0.547455, Loss_D2: 0.693332, Acc:0.570715, Semantic loss: 0.121864
2025-01-26 00:59:38,959 0 [0.         0.47013856 0.2158405  0.11587107 0.33779255 0.17750942
 0.12678072 0.02066929] 0.20922887400306858
2025-01-26 00:59:38,960 1 [0.         0.50356186 0.21510063 0.24300556 0.39790525 0.1415617
 0.05897306 0.25649653] 0.25951494124170366
2025-01-26 00:59:38,960 => saving checkpoint to output\loveDa\pidnet_small_loveda_train_AVDcheckpoint.pth.tar
2025-01-26 00:59:39,137 Loss: 1.249, MeanIU:  0.2595, Best_mIoU:  0.2744
2025-01-26 00:59:39,137 [0.         0.50356186 0.21510063 0.24300556 0.39790525 0.1415617
 0.05897306 0.25649653]
2025-01-26 00:59:40,896 Epoch: [13/20] Iter:[0/292], Time: 1.75, lr: [9.606200234767432e-07], Loss: 1.150242, Loss_D1: 0.569775, Loss_D2: 0.693138, Acc:0.604614, Semantic loss: 0.152306
2025-01-26 00:59:58,228 Epoch: [13/20] Iter:[10/292], Time: 1.73, lr: [9.563892510291813e-07], Loss: 1.296604, Loss_D1: 0.647968, Loss_D2: 0.693567, Acc:0.600656, Semantic loss: 0.125269
2025-01-26 01:00:15,755 Epoch: [13/20] Iter:[20/292], Time: 1.74, lr: [9.521563980356329e-07], Loss: 1.210163, Loss_D1: 0.472614, Loss_D2: 0.692892, Acc:0.575857, Semantic loss: 0.119768
2025-01-26 01:00:33,005 Epoch: [13/20] Iter:[30/292], Time: 1.74, lr: [9.47921453185898e-07], Loss: 1.206590, Loss_D1: 0.585997, Loss_D2: 0.690988, Acc:0.574536, Semantic loss: 0.123443
2025-01-26 01:00:50,476 Epoch: [13/20] Iter:[40/292], Time: 1.74, lr: [9.436844050518126e-07], Loss: 1.218943, Loss_D1: 0.498400, Loss_D2: 0.692734, Acc:0.581507, Semantic loss: 0.123397
2025-01-26 01:01:07,831 Epoch: [13/20] Iter:[50/292], Time: 1.74, lr: [9.39445242085427e-07], Loss: 1.233737, Loss_D1: 0.600697, Loss_D2: 0.692654, Acc:0.589051, Semantic loss: 0.122348
2025-01-26 01:01:25,047 Epoch: [13/20] Iter:[60/292], Time: 1.74, lr: [9.352039526171402e-07], Loss: 1.229746, Loss_D1: 0.445617, Loss_D2: 0.692867, Acc:0.583404, Semantic loss: 0.123592
2025-01-26 01:01:42,189 Epoch: [13/20] Iter:[70/292], Time: 1.73, lr: [9.30960524853799e-07], Loss: 1.236600, Loss_D1: 0.485557, Loss_D2: 0.693245, Acc:0.580756, Semantic loss: 0.122790
2025-01-26 01:01:59,682 Epoch: [13/20] Iter:[80/292], Time: 1.74, lr: [9.26714946876759e-07], Loss: 1.232315, Loss_D1: 0.579164, Loss_D2: 0.693166, Acc:0.575721, Semantic loss: 0.123421
2025-01-26 01:02:17,022 Epoch: [13/20] Iter:[90/292], Time: 1.73, lr: [9.224672066399013e-07], Loss: 1.249667, Loss_D1: 0.556569, Loss_D2: 0.693060, Acc:0.576516, Semantic loss: 0.122963
2025-01-26 01:02:34,311 Epoch: [13/20] Iter:[100/292], Time: 1.73, lr: [9.182172919676106e-07], Loss: 1.254455, Loss_D1: 0.498747, Loss_D2: 0.693115, Acc:0.581554, Semantic loss: 0.122341
2025-01-26 01:02:51,647 Epoch: [13/20] Iter:[110/292], Time: 1.73, lr: [9.13965190552709e-07], Loss: 1.256388, Loss_D1: 0.668985, Loss_D2: 0.693210, Acc:0.583257, Semantic loss: 0.122377
2025-01-26 01:03:08,973 Epoch: [13/20] Iter:[120/292], Time: 1.73, lr: [9.097108899543478e-07], Loss: 1.251240, Loss_D1: 0.608039, Loss_D2: 0.693228, Acc:0.581496, Semantic loss: 0.122397
2025-01-26 01:03:26,241 Epoch: [13/20] Iter:[130/292], Time: 1.73, lr: [9.054543775958514e-07], Loss: 1.265046, Loss_D1: 0.544250, Loss_D2: 0.693282, Acc:0.583487, Semantic loss: 0.122699
2025-01-26 01:03:43,530 Epoch: [13/20] Iter:[140/292], Time: 1.73, lr: [9.011956407625178e-07], Loss: 1.260376, Loss_D1: 0.577791, Loss_D2: 0.693195, Acc:0.582572, Semantic loss: 0.122374
2025-01-26 01:04:00,747 Epoch: [13/20] Iter:[150/292], Time: 1.73, lr: [8.969346665993713e-07], Loss: 1.254360, Loss_D1: 0.579354, Loss_D2: 0.693255, Acc:0.581395, Semantic loss: 0.122179
2025-01-26 01:04:18,185 Epoch: [13/20] Iter:[160/292], Time: 1.73, lr: [8.926714421088644e-07], Loss: 1.251759, Loss_D1: 0.554276, Loss_D2: 0.693483, Acc:0.582181, Semantic loss: 0.122054
2025-01-26 01:04:35,531 Epoch: [13/20] Iter:[170/292], Time: 1.73, lr: [8.884059541485327e-07], Loss: 1.245560, Loss_D1: 0.510020, Loss_D2: 0.693256, Acc:0.579801, Semantic loss: 0.122407
2025-01-26 01:04:52,805 Epoch: [13/20] Iter:[180/292], Time: 1.73, lr: [8.841381894285955e-07], Loss: 1.240725, Loss_D1: 0.576806, Loss_D2: 0.694574, Acc:0.577765, Semantic loss: 0.121859
2025-01-26 01:05:10,345 Epoch: [13/20] Iter:[190/292], Time: 1.73, lr: [8.79868134509507e-07], Loss: 1.249295, Loss_D1: 0.571427, Loss_D2: 0.693010, Acc:0.579991, Semantic loss: 0.122070
2025-01-26 01:05:27,694 Epoch: [13/20] Iter:[200/292], Time: 1.73, lr: [8.755957757994491e-07], Loss: 1.254972, Loss_D1: 0.622035, Loss_D2: 0.692892, Acc:0.580158, Semantic loss: 0.122169
2025-01-26 01:05:45,026 Epoch: [13/20] Iter:[210/292], Time: 1.73, lr: [8.71321099551773e-07], Loss: 1.252982, Loss_D1: 0.554642, Loss_D2: 0.693318, Acc:0.579249, Semantic loss: 0.121984
2025-01-26 01:06:02,454 Epoch: [13/20] Iter:[220/292], Time: 1.73, lr: [8.670440918623799e-07], Loss: 1.247704, Loss_D1: 0.626782, Loss_D2: 0.693197, Acc:0.578669, Semantic loss: 0.122285
2025-01-26 01:06:19,960 Epoch: [13/20] Iter:[230/292], Time: 1.74, lr: [8.62764738667044e-07], Loss: 1.246343, Loss_D1: 0.578997, Loss_D2: 0.693155, Acc:0.577990, Semantic loss: 0.122068
2025-01-26 01:06:37,215 Epoch: [13/20] Iter:[240/292], Time: 1.73, lr: [8.584830257386774e-07], Loss: 1.239128, Loss_D1: 0.576244, Loss_D2: 0.693211, Acc:0.577373, Semantic loss: 0.121999
2025-01-26 01:06:54,551 Epoch: [13/20] Iter:[250/292], Time: 1.73, lr: [8.541989386845275e-07], Loss: 1.235397, Loss_D1: 0.498592, Loss_D2: 0.693309, Acc:0.575118, Semantic loss: 0.121927
2025-01-26 01:07:11,930 Epoch: [13/20] Iter:[260/292], Time: 1.73, lr: [8.499124629433169e-07], Loss: 1.243217, Loss_D1: 0.596522, Loss_D2: 0.693010, Acc:0.576554, Semantic loss: 0.121835
2025-01-26 01:07:29,205 Epoch: [13/20] Iter:[270/292], Time: 1.73, lr: [8.456235837823102e-07], Loss: 1.241918, Loss_D1: 0.537103, Loss_D2: 0.692576, Acc:0.576378, Semantic loss: 0.121675
2025-01-26 01:07:46,574 Epoch: [13/20] Iter:[280/292], Time: 1.73, lr: [8.413322862943213e-07], Loss: 1.235622, Loss_D1: 0.490426, Loss_D2: 0.693765, Acc:0.575337, Semantic loss: 0.121845
2025-01-26 01:08:03,820 Epoch: [13/20] Iter:[290/292], Time: 1.73, lr: [8.370385553946427e-07], Loss: 1.235122, Loss_D1: 0.470054, Loss_D2: 0.692385, Acc:0.576617, Semantic loss: 0.121650
2025-01-26 01:11:30,136 0 [0.         0.46209741 0.20799271 0.1158777  0.29923304 0.17472033
 0.13158723 0.02082439] 0.201761829393128
2025-01-26 01:11:30,137 1 [0.         0.49724567 0.20970502 0.25549324 0.35479903 0.13550756
 0.04894768 0.29394261] 0.2565201147201502
2025-01-26 01:11:30,137 => saving checkpoint to output\loveDa\pidnet_small_loveda_train_AVDcheckpoint.pth.tar
2025-01-26 01:11:30,303 Loss: 1.247, MeanIU:  0.2565, Best_mIoU:  0.2744
2025-01-26 01:11:30,303 [0.         0.49724567 0.20970502 0.25549324 0.35479903 0.13550756
 0.04894768 0.29394261]
2025-01-26 01:11:32,250 Epoch: [14/20] Iter:[0/292], Time: 1.94, lr: [2.983761132611032e-07], Loss: 1.533511, Loss_D1: 0.534953, Loss_D2: 0.692411, Acc:0.716588, Semantic loss: 0.125231
2025-01-26 01:11:51,015 Epoch: [14/20] Iter:[10/292], Time: 1.88, lr: [2.9684292090660213e-07], Loss: 1.175785, Loss_D1: 0.571968, Loss_D2: 0.692691, Acc:0.531543, Semantic loss: 0.118769
2025-01-26 01:12:09,877 Epoch: [14/20] Iter:[20/292], Time: 1.88, lr: [2.9530884816096894e-07], Loss: 1.258608, Loss_D1: 0.572161, Loss_D2: 0.692819, Acc:0.575091, Semantic loss: 0.121317
2025-01-26 01:12:28,740 Epoch: [14/20] Iter:[30/292], Time: 1.88, lr: [2.937738894311283e-07], Loss: 1.235816, Loss_D1: 0.482953, Loss_D2: 0.693371, Acc:0.573931, Semantic loss: 0.120768
2025-01-26 01:12:47,351 Epoch: [14/20] Iter:[40/292], Time: 1.88, lr: [2.9223803905577623e-07], Loss: 1.243407, Loss_D1: 0.564970, Loss_D2: 0.692884, Acc:0.573838, Semantic loss: 0.123990
2025-01-26 01:13:05,958 Epoch: [14/20] Iter:[50/292], Time: 1.88, lr: [2.907012913041431e-07], Loss: 1.209036, Loss_D1: 0.622652, Loss_D2: 0.692964, Acc:0.572953, Semantic loss: 0.123502
2025-01-26 01:13:24,777 Epoch: [14/20] Iter:[60/292], Time: 1.88, lr: [2.891636403747294e-07], Loss: 1.223630, Loss_D1: 0.559404, Loss_D2: 0.693057, Acc:0.571374, Semantic loss: 0.123424
2025-01-26 01:13:43,455 Epoch: [14/20] Iter:[70/292], Time: 1.88, lr: [2.8762508039400805e-07], Loss: 1.248991, Loss_D1: 0.568239, Loss_D2: 0.693508, Acc:0.574641, Semantic loss: 0.122314
2025-01-26 01:14:02,002 Epoch: [14/20] Iter:[80/292], Time: 1.87, lr: [2.8608560541509727e-07], Loss: 1.232057, Loss_D1: 0.573643, Loss_D2: 0.693096, Acc:0.570101, Semantic loss: 0.122178
2025-01-26 01:14:20,661 Epoch: [14/20] Iter:[90/292], Time: 1.87, lr: [2.8454520941640015e-07], Loss: 1.239103, Loss_D1: 0.578652, Loss_D2: 0.693032, Acc:0.570755, Semantic loss: 0.121907
2025-01-26 01:14:39,221 Epoch: [14/20] Iter:[100/292], Time: 1.87, lr: [2.830038863002101e-07], Loss: 1.218792, Loss_D1: 0.625065, Loss_D2: 0.692853, Acc:0.565891, Semantic loss: 0.121460
2025-01-26 01:14:57,860 Epoch: [14/20] Iter:[110/292], Time: 1.87, lr: [2.814616298912828e-07], Loss: 1.235579, Loss_D1: 0.620445, Loss_D2: 0.692461, Acc:0.567565, Semantic loss: 0.121760
2025-01-26 01:15:16,483 Epoch: [14/20] Iter:[120/292], Time: 1.87, lr: [2.799184339353711e-07], Loss: 1.233416, Loss_D1: 0.545271, Loss_D2: 0.693266, Acc:0.564273, Semantic loss: 0.121904
2025-01-26 01:15:34,976 Epoch: [14/20] Iter:[130/292], Time: 1.87, lr: [2.7837429209772455e-07], Loss: 1.238149, Loss_D1: 0.616004, Loss_D2: 0.693206, Acc:0.565613, Semantic loss: 0.121854
2025-01-26 01:15:53,331 Epoch: [14/20] Iter:[140/292], Time: 1.87, lr: [2.7682919796154987e-07], Loss: 1.252673, Loss_D1: 0.733438, Loss_D2: 0.693361, Acc:0.566942, Semantic loss: 0.121747
2025-01-26 01:16:11,598 Epoch: [14/20] Iter:[150/292], Time: 1.86, lr: [2.75283145026433e-07], Loss: 1.243809, Loss_D1: 0.486392, Loss_D2: 0.693003, Acc:0.566853, Semantic loss: 0.121396
2025-01-26 01:16:29,928 Epoch: [14/20] Iter:[160/292], Time: 1.86, lr: [2.7373612670671997e-07], Loss: 1.244797, Loss_D1: 0.610231, Loss_D2: 0.693297, Acc:0.565909, Semantic loss: 0.121631
2025-01-26 01:16:48,279 Epoch: [14/20] Iter:[170/292], Time: 1.86, lr: [2.721881363298569e-07], Loss: 1.241778, Loss_D1: 0.535631, Loss_D2: 0.692718, Acc:0.567179, Semantic loss: 0.122159
2025-01-26 01:17:06,633 Epoch: [14/20] Iter:[180/292], Time: 1.86, lr: [2.7063916713468643e-07], Loss: 1.244389, Loss_D1: 0.539458, Loss_D2: 0.692553, Acc:0.568923, Semantic loss: 0.122205
2025-01-26 01:17:24,878 Epoch: [14/20] Iter:[190/292], Time: 1.86, lr: [2.6908921226970004e-07], Loss: 1.242543, Loss_D1: 0.724004, Loss_D2: 0.690589, Acc:0.567943, Semantic loss: 0.122263
2025-01-26 01:17:43,219 Epoch: [14/20] Iter:[200/292], Time: 1.86, lr: [2.6753826479124394e-07], Loss: 1.235232, Loss_D1: 0.599337, Loss_D2: 0.693549, Acc:0.565613, Semantic loss: 0.121926
2025-01-26 01:18:01,281 Epoch: [14/20] Iter:[210/292], Time: 1.85, lr: [2.659863176616781e-07], Loss: 1.234520, Loss_D1: 0.533398, Loss_D2: 0.694755, Acc:0.565482, Semantic loss: 0.121547
2025-01-26 01:18:19,363 Epoch: [14/20] Iter:[220/292], Time: 1.85, lr: [2.644333637474862e-07], Loss: 1.233113, Loss_D1: 0.515597, Loss_D2: 0.692271, Acc:0.564305, Semantic loss: 0.121621
2025-01-26 01:18:37,407 Epoch: [14/20] Iter:[230/292], Time: 1.85, lr: [2.628793958173346e-07], Loss: 1.229381, Loss_D1: 0.589034, Loss_D2: 0.692484, Acc:0.563608, Semantic loss: 0.121695
2025-01-26 01:18:55,271 Epoch: [14/20] Iter:[240/292], Time: 1.85, lr: [2.6132440654007954e-07], Loss: 1.230479, Loss_D1: 0.495402, Loss_D2: 0.693609, Acc:0.564883, Semantic loss: 0.121903
2025-01-26 01:19:13,298 Epoch: [14/20] Iter:[250/292], Time: 1.84, lr: [2.5976838848272014e-07], Loss: 1.234157, Loss_D1: 0.545278, Loss_D2: 0.701576, Acc:0.566022, Semantic loss: 0.121655
2025-01-26 01:19:31,391 Epoch: [14/20] Iter:[260/292], Time: 1.84, lr: [2.5821133410829486e-07], Loss: 1.233189, Loss_D1: 0.556150, Loss_D2: 0.692495, Acc:0.568298, Semantic loss: 0.121819
2025-01-26 01:19:49,515 Epoch: [14/20] Iter:[270/292], Time: 1.84, lr: [2.5665323577372145e-07], Loss: 1.229929, Loss_D1: 0.568031, Loss_D2: 0.693582, Acc:0.567330, Semantic loss: 0.121631
2025-01-26 01:20:07,316 Epoch: [14/20] Iter:[280/292], Time: 1.84, lr: [2.550940857275755e-07], Loss: 1.226701, Loss_D1: 0.534203, Loss_D2: 0.693768, Acc:0.566996, Semantic loss: 0.121499
2025-01-26 01:20:25,316 Epoch: [14/20] Iter:[290/292], Time: 1.84, lr: [2.535338761078087e-07], Loss: 1.221761, Loss_D1: 0.590578, Loss_D2: 0.694011, Acc:0.567132, Semantic loss: 0.121519
2025-01-26 01:23:59,598 0 [0.         0.46203073 0.19551958 0.11532427 0.32918566 0.16839535
 0.11229702 0.02210427] 0.2006938394754156
2025-01-26 01:23:59,599 1 [0.         0.49525185 0.18883725 0.2530008  0.40132247 0.12124308
 0.04372626 0.30678513] 0.25859526403825195
2025-01-26 01:23:59,600 => saving checkpoint to output\loveDa\pidnet_small_loveda_train_AVDcheckpoint.pth.tar
2025-01-26 01:23:59,764 Loss: 1.240, MeanIU:  0.2586, Best_mIoU:  0.2744
2025-01-26 01:23:59,765 [0.         0.49525185 0.18883725 0.2530008  0.40132247 0.12124308
 0.04372626 0.30678513]
2025-01-26 01:24:01,658 Epoch: [15/20] Iter:[0/292], Time: 1.89, lr: [1.452905637738451e-07], Loss: 1.068084, Loss_D1: 0.597061, Loss_D2: 0.692233, Acc:0.536144, Semantic loss: 0.118105
