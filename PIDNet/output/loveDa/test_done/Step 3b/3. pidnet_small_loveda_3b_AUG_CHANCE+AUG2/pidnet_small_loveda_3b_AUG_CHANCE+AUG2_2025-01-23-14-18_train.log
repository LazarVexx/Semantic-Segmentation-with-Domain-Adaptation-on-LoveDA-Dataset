2025-01-23 14:18:28,916 Namespace(cfg='configs/loveDa/pidnet_small_loveda_3b_AUG_CHANCE+AUG2.yaml', seed=304, opts=['GPUS', '[0]', 'TRAIN.BATCH_SIZE_PER_GPU', '6'])
2025-01-23 14:18:28,916 AUTO_RESUME: False
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  DATASET: loveDa
  EXTRA_TRAIN_SET: 
  NUM_CLASSES: 8
  ROOT: data/
  SOURCE_DATASET: loveDA-Urban
  SOURCE_TEST_SET: list/loveDA-Urban/val.lst
  SOURCE_TRAIN_SET: list/loveDA-Urban/train.lst
  TARGET_DATASET: loveDA-Rural
  TARGET_SET: list/cityscapes/val.lst
  TARGET_TEST_SET: list/loveDA-Rural/val.lst
  TARGET_TRAIN_SET: list/loveDA-Rural/train.lst
  TEST_SET: list/loveDa-Rural/val.lst
  TRAIN_SET: list/loveDA-Urban/train.lst
GPUS: (0,)
LOG_DIR: log
LOSS:
  BALANCE_WEIGHTS: [0.4, 1.0]
  CLASS_BALANCE: False
  OHEMKEEP: 131072
  OHEMTHRES: 0.7
  SB_WEIGHTS: 0.5
  USE_DICE: False
  USE_FOCAL: False
  USE_OHEM: True
MODEL:
  ALIGN_CORNERS: True
  NAME: pidnet_small
  NUM_OUTPUTS: 2
  PRETRAINED: pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar
OUTPUT_DIR: output
PIN_MEMORY: True
PRINT_FREQ: 10
TEST:
  BASE_SIZE: 1024
  BATCH_SIZE_PER_GPU: 6
  FLIP_TEST: False
  IMAGE_SIZE: [1024, 1024]
  MODEL_FILE: 
  MULTI_SCALE: False
  OUTPUT_INDEX: 1
TRAIN:
  ADVERSARIAL: False
  AUG: True
  AUG1: False
  AUG2: True
  AUG3: False
  AUG4: False
  AUG_CHANCE: True
  BASE_SIZE: 720
  BATCH_SIZE_PER_GPU: 6
  BEGIN_EPOCH: 1
  END_EPOCH: 20
  EVAL_INTERVAL: 1
  EXTRA_EPOCH: 0
  EXTRA_LR: 0.001
  FLIP: True
  GAN: Vanilla
  IGNORE_LABEL: 0
  IMAGE_SIZE: [720, 720]
  LAMBDA_ADV1: 0.001
  LAMBDA_ADV2: 0.001
  LR: 0.001
  LR_D1: 0.001
  LR_D2: 0.001
  MOMENTUM: 0.9
  MULTI_SCALE: True
  NESTEROV: False
  OPTIMIZER: adam
  RESUME: True
  SCALE_FACTOR: 16
  SCHEDULER: True
  SHUFFLE: True
  WD: 0.0005
WORKERS: 0
2025-01-23 14:18:29,640 Attention!!!
2025-01-23 14:18:29,640 Loaded 302 parameters!
2025-01-23 14:18:29,640 Over!!!
2025-01-23 14:18:30,604 => loaded checkpoint (epoch 17)
2025-01-23 14:18:39,845 Epoch: [17/20] Iter:[0/288], Time: 9.24, lr: [1.7981410331698773e-08], Loss: 1.164371, Acc:0.417003, Semantic loss: 0.140561, BCE loss: 0.974220, SB loss: 0.049590
2025-01-23 14:18:50,866 Epoch: [17/20] Iter:[10/288], Time: 1.83, lr: [1.779399511636946e-08], Loss: 1.231358, Acc:0.553682, Semantic loss: 0.120285, BCE loss: 1.065136, SB loss: 0.045937
2025-01-23 14:19:01,688 Epoch: [17/20] Iter:[20/288], Time: 1.47, lr: [1.7606360311475033e-08], Loss: 1.243612, Acc:0.576208, Semantic loss: 0.120982, BCE loss: 1.077860, SB loss: 0.044770
2025-01-23 14:19:12,933 Epoch: [17/20] Iter:[30/288], Time: 1.36, lr: [1.7418503053236708e-08], Loss: 1.239032, Acc:0.582321, Semantic loss: 0.119342, BCE loss: 1.075162, SB loss: 0.044528
2025-01-23 14:19:24,260 Epoch: [17/20] Iter:[40/288], Time: 1.31, lr: [1.723042040571793e-08], Loss: 1.224727, Acc:0.571658, Semantic loss: 0.123091, BCE loss: 1.055768, SB loss: 0.045868
2025-01-23 14:19:35,470 Epoch: [17/20] Iter:[50/288], Time: 1.27, lr: [1.704210935810767e-08], Loss: 1.211151, Acc:0.575356, Semantic loss: 0.121540, BCE loss: 1.043988, SB loss: 0.045623
2025-01-23 14:19:46,867 Epoch: [17/20] Iter:[60/288], Time: 1.25, lr: [1.6853566821867033e-08], Loss: 1.202890, Acc:0.576805, Semantic loss: 0.120688, BCE loss: 1.036996, SB loss: 0.045206
2025-01-23 14:19:57,239 Epoch: [17/20] Iter:[70/288], Time: 1.22, lr: [1.6664789627730062e-08], Loss: 1.179281, Acc:0.571844, Semantic loss: 0.121619, BCE loss: 1.012147, SB loss: 0.045514
2025-01-23 14:20:08,326 Epoch: [17/20] Iter:[80/288], Time: 1.20, lr: [1.6475774522549603e-08], Loss: 1.187732, Acc:0.571887, Semantic loss: 0.121079, BCE loss: 1.021256, SB loss: 0.045398
2025-01-23 14:20:19,648 Epoch: [17/20] Iter:[90/288], Time: 1.20, lr: [1.628651816597819e-08], Loss: 1.192480, Acc:0.574230, Semantic loss: 0.120490, BCE loss: 1.026817, SB loss: 0.045173
2025-01-23 14:20:30,989 Epoch: [17/20] Iter:[100/288], Time: 1.19, lr: [1.6097017126972797e-08], Loss: 1.202156, Acc:0.574946, Semantic loss: 0.121383, BCE loss: 1.035368, SB loss: 0.045405
2025-01-23 14:20:42,062 Epoch: [17/20] Iter:[110/288], Time: 1.18, lr: [1.590726788011207e-08], Loss: 1.203273, Acc:0.571087, Semantic loss: 0.121727, BCE loss: 1.036201, SB loss: 0.045344
2025-01-23 14:20:53,337 Epoch: [17/20] Iter:[120/288], Time: 1.18, lr: [1.5717266801712946e-08], Loss: 1.217358, Acc:0.572459, Semantic loss: 0.121801, BCE loss: 1.050385, SB loss: 0.045172
2025-01-23 14:21:03,737 Epoch: [17/20] Iter:[130/288], Time: 1.17, lr: [1.552701016573329e-08], Loss: 1.206192, Acc:0.570019, Semantic loss: 0.122372, BCE loss: 1.038461, SB loss: 0.045359
2025-01-23 14:21:14,721 Epoch: [17/20] Iter:[140/288], Time: 1.16, lr: [1.533649413944527e-08], Loss: 1.212049, Acc:0.572327, Semantic loss: 0.122011, BCE loss: 1.044867, SB loss: 0.045171
2025-01-23 14:21:25,741 Epoch: [17/20] Iter:[150/288], Time: 1.16, lr: [1.5145714778863676e-08], Loss: 1.207936, Acc:0.572200, Semantic loss: 0.122421, BCE loss: 1.040292, SB loss: 0.045223
2025-01-23 14:21:36,897 Epoch: [17/20] Iter:[160/288], Time: 1.16, lr: [1.4954668023911443e-08], Loss: 1.208912, Acc:0.574281, Semantic loss: 0.122410, BCE loss: 1.041171, SB loss: 0.045330
2025-01-23 14:21:48,204 Epoch: [17/20] Iter:[170/288], Time: 1.15, lr: [1.4763349693303258e-08], Loss: 1.209392, Acc:0.575977, Semantic loss: 0.122022, BCE loss: 1.042134, SB loss: 0.045236
2025-01-23 14:21:59,420 Epoch: [17/20] Iter:[180/288], Time: 1.15, lr: [1.457175547912689e-08], Loss: 1.217920, Acc:0.576795, Semantic loss: 0.122500, BCE loss: 1.050050, SB loss: 0.045369
2025-01-23 14:22:09,994 Epoch: [17/20] Iter:[190/288], Time: 1.15, lr: [1.4379880941099126e-08], Loss: 1.221120, Acc:0.577482, Semantic loss: 0.122582, BCE loss: 1.053114, SB loss: 0.045424
2025-01-23 14:22:21,405 Epoch: [17/20] Iter:[200/288], Time: 1.15, lr: [1.4187721500472242e-08], Loss: 1.233507, Acc:0.579322, Semantic loss: 0.122551, BCE loss: 1.065613, SB loss: 0.045343
2025-01-23 14:22:32,476 Epoch: [17/20] Iter:[210/288], Time: 1.15, lr: [1.3995272433563629e-08], Loss: 1.238967, Acc:0.579064, Semantic loss: 0.122483, BCE loss: 1.071165, SB loss: 0.045319
2025-01-23 14:22:43,949 Epoch: [17/20] Iter:[220/288], Time: 1.15, lr: [1.3802528864879628e-08], Loss: 1.243082, Acc:0.581583, Semantic loss: 0.122581, BCE loss: 1.075154, SB loss: 0.045347
2025-01-23 14:22:55,230 Epoch: [17/20] Iter:[230/288], Time: 1.14, lr: [1.3609485759800942e-08], Loss: 1.243866, Acc:0.582441, Semantic loss: 0.122453, BCE loss: 1.076107, SB loss: 0.045306
2025-01-23 14:23:06,295 Epoch: [17/20] Iter:[240/288], Time: 1.14, lr: [1.341613791679477e-08], Loss: 1.243940, Acc:0.583347, Semantic loss: 0.122091, BCE loss: 1.076592, SB loss: 0.045257
2025-01-23 14:23:16,954 Epoch: [17/20] Iter:[250/288], Time: 1.14, lr: [1.3222479959114583e-08], Loss: 1.241211, Acc:0.583706, Semantic loss: 0.121983, BCE loss: 1.074010, SB loss: 0.045219
2025-01-23 14:23:28,315 Epoch: [17/20] Iter:[260/288], Time: 1.14, lr: [1.3028506325945104e-08], Loss: 1.239707, Acc:0.582970, Semantic loss: 0.122010, BCE loss: 1.072453, SB loss: 0.045244
2025-01-23 14:23:39,775 Epoch: [17/20] Iter:[270/288], Time: 1.14, lr: [1.2834211262945666e-08], Loss: 1.242579, Acc:0.584340, Semantic loss: 0.121895, BCE loss: 1.075476, SB loss: 0.045208
2025-01-23 14:23:51,043 Epoch: [17/20] Iter:[280/288], Time: 1.14, lr: [1.2639588812140001e-08], Loss: 1.240431, Acc:0.583245, Semantic loss: 0.122298, BCE loss: 1.072930, SB loss: 0.045203
2025-01-23 14:33:51,080 0 [0.         0.42824551 0.28981245 0.12477668 0.28414502 0.1288357
 0.14246714 0.06248932] 0.20868168706915496
2025-01-23 14:33:51,080 1 [0.         0.46143289 0.33336268 0.28353187 0.3724762  0.05910299
 0.12779038 0.42646167] 0.2948798115504698
2025-01-23 14:33:51,100 => saving checkpoint to output/loveDa/pidnet_small_loveda_3b_AUG_CHANCE+AUG2checkpoint.pth.tar
2025-01-23 14:33:51,613 Loss: 1.249, MeanIU:  0.2949, Best_mIoU:  0.3007
2025-01-23 14:33:51,614 [0.         0.46143289 0.33336268 0.28353187 0.3724762  0.05910299
 0.12779038 0.42646167]
2025-01-23 14:33:52,919 Epoch: [18/20] Iter:[0/288], Time: 1.13, lr: [5.634034464040159e-09], Loss: 1.731688, Acc:0.529777, Semantic loss: 0.193770, BCE loss: 1.471147, SB loss: 0.066771
2025-01-23 14:34:03,391 Epoch: [18/20] Iter:[10/288], Time: 1.06, lr: [5.5459257681268765e-09], Loss: 1.125689, Acc:0.551267, Semantic loss: 0.129922, BCE loss: 0.949517, SB loss: 0.046250
2025-01-23 14:34:14,080 Epoch: [18/20] Iter:[20/288], Time: 1.06, lr: [5.4576612570218266e-09], Loss: 1.153543, Acc:0.578000, Semantic loss: 0.124267, BCE loss: 0.983892, SB loss: 0.045384
2025-01-23 14:34:25,183 Epoch: [18/20] Iter:[30/288], Time: 1.08, lr: [5.369237844946383e-09], Loss: 1.189081, Acc:0.584838, Semantic loss: 0.122898, BCE loss: 1.021609, SB loss: 0.044574
2025-01-23 14:34:36,105 Epoch: [18/20] Iter:[40/288], Time: 1.08, lr: [5.280652327310083e-09], Loss: 1.185771, Acc:0.588167, Semantic loss: 0.120596, BCE loss: 1.020407, SB loss: 0.044769
2025-01-23 14:34:47,081 Epoch: [18/20] Iter:[50/288], Time: 1.09, lr: [5.19190137383116e-09], Loss: 1.203859, Acc:0.569812, Semantic loss: 0.124449, BCE loss: 1.033802, SB loss: 0.045608
2025-01-23 14:34:58,309 Epoch: [18/20] Iter:[60/288], Time: 1.09, lr: [5.1029815211201215e-09], Loss: 1.200409, Acc:0.565357, Semantic loss: 0.125082, BCE loss: 1.029426, SB loss: 0.045901
2025-01-23 14:35:08,886 Epoch: [18/20] Iter:[70/288], Time: 1.09, lr: [5.013889164673292e-09], Loss: 1.217957, Acc:0.572098, Semantic loss: 0.124348, BCE loss: 1.048165, SB loss: 0.045444
2025-01-23 14:35:20,024 Epoch: [18/20] Iter:[80/288], Time: 1.09, lr: [4.924620550216832e-09], Loss: 1.220934, Acc:0.574505, Semantic loss: 0.123251, BCE loss: 1.052254, SB loss: 0.045429
2025-01-23 14:35:31,221 Epoch: [18/20] Iter:[90/288], Time: 1.09, lr: [4.835171764334207e-09], Loss: 1.236193, Acc:0.576218, Semantic loss: 0.123800, BCE loss: 1.066561, SB loss: 0.045832
2025-01-23 14:35:42,441 Epoch: [18/20] Iter:[100/288], Time: 1.10, lr: [4.745538724301991e-09], Loss: 1.233815, Acc:0.576157, Semantic loss: 0.122922, BCE loss: 1.065413, SB loss: 0.045480
2025-01-23 14:35:53,486 Epoch: [18/20] Iter:[110/288], Time: 1.10, lr: [4.655717167048855e-09], Loss: 1.219917, Acc:0.575435, Semantic loss: 0.123191, BCE loss: 1.051204, SB loss: 0.045522
2025-01-23 14:36:04,631 Epoch: [18/20] Iter:[120/288], Time: 1.10, lr: [4.56570263714186e-09], Loss: 1.219776, Acc:0.579326, Semantic loss: 0.122116, BCE loss: 1.052450, SB loss: 0.045210
2025-01-23 14:36:15,125 Epoch: [18/20] Iter:[130/288], Time: 1.09, lr: [4.475490473690871e-09], Loss: 1.218082, Acc:0.580381, Semantic loss: 0.122395, BCE loss: 1.050416, SB loss: 0.045271
2025-01-23 14:36:26,165 Epoch: [18/20] Iter:[140/288], Time: 1.10, lr: [4.385075796047385e-09], Loss: 1.218992, Acc:0.582978, Semantic loss: 0.121312, BCE loss: 1.052787, SB loss: 0.044893
2025-01-23 14:36:37,402 Epoch: [18/20] Iter:[150/288], Time: 1.10, lr: [4.2944534881563826e-09], Loss: 1.215292, Acc:0.581295, Semantic loss: 0.121383, BCE loss: 1.048892, SB loss: 0.045017
2025-01-23 14:36:48,581 Epoch: [18/20] Iter:[160/288], Time: 1.10, lr: [4.203618181399718e-09], Loss: 1.212879, Acc:0.584660, Semantic loss: 0.121584, BCE loss: 1.046429, SB loss: 0.044867
2025-01-23 14:36:59,850 Epoch: [18/20] Iter:[170/288], Time: 1.10, lr: [4.112564235745859e-09], Loss: 1.210104, Acc:0.583193, Semantic loss: 0.121439, BCE loss: 1.043811, SB loss: 0.044854
2025-01-23 14:37:10,895 Epoch: [18/20] Iter:[180/288], Time: 1.10, lr: [4.02128571899271e-09], Loss: 1.204455, Acc:0.584918, Semantic loss: 0.121092, BCE loss: 1.038543, SB loss: 0.044821
2025-01-23 14:37:21,746 Epoch: [18/20] Iter:[190/288], Time: 1.10, lr: [3.929776383857642e-09], Loss: 1.212938, Acc:0.586813, Semantic loss: 0.120878, BCE loss: 1.047280, SB loss: 0.044780
2025-01-23 14:37:33,083 Epoch: [18/20] Iter:[200/288], Time: 1.10, lr: [3.838029642629576e-09], Loss: 1.217490, Acc:0.588137, Semantic loss: 0.120755, BCE loss: 1.051881, SB loss: 0.044854
2025-01-23 14:37:44,352 Epoch: [18/20] Iter:[210/288], Time: 1.10, lr: [3.7460385390519775e-09], Loss: 1.224222, Acc:0.589352, Semantic loss: 0.120473, BCE loss: 1.059030, SB loss: 0.044718
2025-01-23 14:37:55,749 Epoch: [18/20] Iter:[220/288], Time: 1.10, lr: [3.653795717049909e-09], Loss: 1.220754, Acc:0.587058, Semantic loss: 0.120210, BCE loss: 1.055869, SB loss: 0.044675
2025-01-23 14:38:06,969 Epoch: [18/20] Iter:[230/288], Time: 1.10, lr: [3.561293385848268e-09], Loss: 1.223918, Acc:0.588161, Semantic loss: 0.120521, BCE loss: 1.058621, SB loss: 0.044776
2025-01-23 14:38:17,431 Epoch: [18/20] Iter:[240/288], Time: 1.10, lr: [3.468523280947944e-09], Loss: 1.216712, Acc:0.586270, Semantic loss: 0.120553, BCE loss: 1.051340, SB loss: 0.044818
2025-01-23 14:38:28,179 Epoch: [18/20] Iter:[250/288], Time: 1.10, lr: [3.375476620329816e-09], Loss: 1.213304, Acc:0.585193, Semantic loss: 0.120542, BCE loss: 1.047838, SB loss: 0.044924
2025-01-23 14:38:39,351 Epoch: [18/20] Iter:[260/288], Time: 1.10, lr: [3.2821440551382843e-09], Loss: 1.210138, Acc:0.585754, Semantic loss: 0.120114, BCE loss: 1.045256, SB loss: 0.044768
2025-01-23 14:38:50,466 Epoch: [18/20] Iter:[270/288], Time: 1.10, lr: [3.188515613951029e-09], Loss: 1.217016, Acc:0.586779, Semantic loss: 0.120149, BCE loss: 1.052096, SB loss: 0.044771
2025-01-23 14:39:01,504 Epoch: [18/20] Iter:[280/288], Time: 1.10, lr: [3.0945806395634395e-09], Loss: 1.216496, Acc:0.586002, Semantic loss: 0.120122, BCE loss: 1.051661, SB loss: 0.044713
2025-01-23 14:49:09,830 0 [0.         0.43861142 0.28425025 0.12846529 0.30050153 0.12197115
 0.15019288 0.06030747] 0.2120428567040589
2025-01-23 14:49:09,830 1 [0.         0.48995209 0.34028467 0.30972833 0.40754198 0.05817312
 0.15264378 0.41698322] 0.3107581691222445
2025-01-23 14:49:09,842 => saving checkpoint to output/loveDa/pidnet_small_loveda_3b_AUG_CHANCE+AUG2checkpoint.pth.tar
2025-01-23 14:49:10,281 Loss: 1.247, MeanIU:  0.3108, Best_mIoU:  0.3108
2025-01-23 14:49:10,281 [0.         0.48995209 0.34028467 0.30972833 0.40754198 0.05817312
 0.15264378 0.41698322]
2025-01-23 14:49:11,387 Epoch: [19/20] Iter:[0/288], Time: 0.96, lr: [3.878428647526291e-09], Loss: 1.394775, Acc:0.686711, Semantic loss: 0.110477, BCE loss: 1.238979, SB loss: 0.045319
2025-01-23 14:49:22,417 Epoch: [19/20] Iter:[10/288], Time: 1.09, lr: [3.757014605222851e-09], Loss: 1.162252, Acc:0.582972, Semantic loss: 0.124876, BCE loss: 0.990823, SB loss: 0.046552
2025-01-23 14:49:33,465 Epoch: [19/20] Iter:[20/288], Time: 1.10, lr: [3.635162936007162e-09], Loss: 1.163174, Acc:0.581613, Semantic loss: 0.120332, BCE loss: 0.998086, SB loss: 0.044756
2025-01-23 14:49:44,481 Epoch: [19/20] Iter:[30/288], Time: 1.10, lr: [3.512855635802599e-09], Loss: 1.185115, Acc:0.575106, Semantic loss: 0.122303, BCE loss: 1.017605, SB loss: 0.045208
2025-01-23 14:49:55,467 Epoch: [19/20] Iter:[40/288], Time: 1.10, lr: [3.3900732311923364e-09], Loss: 1.167407, Acc:0.568092, Semantic loss: 0.121720, BCE loss: 0.999943, SB loss: 0.045743
2025-01-23 14:50:06,364 Epoch: [19/20] Iter:[50/288], Time: 1.10, lr: [3.2667945951966758e-09], Loss: 1.199602, Acc:0.576898, Semantic loss: 0.121258, BCE loss: 1.032950, SB loss: 0.045393
2025-01-23 14:50:16,874 Epoch: [19/20] Iter:[60/288], Time: 1.09, lr: [3.1429967312054885e-09], Loss: 1.209846, Acc:0.580994, Semantic loss: 0.120846, BCE loss: 1.044022, SB loss: 0.044978
2025-01-23 14:50:27,832 Epoch: [19/20] Iter:[70/288], Time: 1.09, lr: [3.0186545179151235e-09], Loss: 1.232820, Acc:0.587338, Semantic loss: 0.119639, BCE loss: 1.068562, SB loss: 0.044620
2025-01-23 14:50:38,790 Epoch: [19/20] Iter:[80/288], Time: 1.09, lr: [2.893740406108884e-09], Loss: 1.220473, Acc:0.586179, Semantic loss: 0.120087, BCE loss: 1.056014, SB loss: 0.044372
2025-01-23 14:50:49,665 Epoch: [19/20] Iter:[90/288], Time: 1.09, lr: [2.7682240554214905e-09], Loss: 1.238649, Acc:0.589968, Semantic loss: 0.120253, BCE loss: 1.073908, SB loss: 0.044488
2025-01-23 14:51:00,637 Epoch: [19/20] Iter:[100/288], Time: 1.09, lr: [2.6420718955551495e-09], Loss: 1.245498, Acc:0.589613, Semantic loss: 0.120337, BCE loss: 1.080270, SB loss: 0.044890
2025-01-23 14:51:11,587 Epoch: [19/20] Iter:[110/288], Time: 1.09, lr: [2.515246591348183e-09], Loss: 1.243445, Acc:0.586354, Semantic loss: 0.120680, BCE loss: 1.077706, SB loss: 0.045059
2025-01-23 14:51:22,172 Epoch: [19/20] Iter:[120/288], Time: 1.09, lr: [2.3877063839956813e-09], Loss: 1.237347, Acc:0.586426, Semantic loss: 0.120019, BCE loss: 1.072429, SB loss: 0.044899
2025-01-23 14:51:32,859 Epoch: [19/20] Iter:[130/288], Time: 1.09, lr: [2.2594042705993747e-09], Loss: 1.237165, Acc:0.589939, Semantic loss: 0.119718, BCE loss: 1.072817, SB loss: 0.044630
2025-01-23 14:51:43,629 Epoch: [19/20] Iter:[140/288], Time: 1.09, lr: [2.1302869695185296e-09], Loss: 1.221409, Acc:0.589751, Semantic loss: 0.119279, BCE loss: 1.057594, SB loss: 0.044536
2025-01-23 14:51:54,402 Epoch: [19/20] Iter:[150/288], Time: 1.09, lr: [2.0002935971751652e-09], Loss: 1.223795, Acc:0.590430, Semantic loss: 0.119242, BCE loss: 1.060051, SB loss: 0.044502
2025-01-23 14:52:05,510 Epoch: [19/20] Iter:[160/288], Time: 1.09, lr: [1.8693539488207705e-09], Loss: 1.229285, Acc:0.591200, Semantic loss: 0.119248, BCE loss: 1.065593, SB loss: 0.044444
2025-01-23 14:52:16,671 Epoch: [19/20] Iter:[170/288], Time: 1.09, lr: [1.7373862240494814e-09], Loss: 1.227542, Acc:0.590260, Semantic loss: 0.119643, BCE loss: 1.063223, SB loss: 0.044676
2025-01-23 14:52:27,605 Epoch: [19/20] Iter:[180/288], Time: 1.09, lr: [1.6042939546385465e-09], Loss: 1.230800, Acc:0.591311, Semantic loss: 0.119615, BCE loss: 1.066618, SB loss: 0.044568
2025-01-23 14:52:37,966 Epoch: [19/20] Iter:[190/288], Time: 1.09, lr: [1.469961753662786e-09], Loss: 1.231663, Acc:0.591818, Semantic loss: 0.119016, BCE loss: 1.068212, SB loss: 0.044435
2025-01-23 14:52:48,979 Epoch: [19/20] Iter:[200/288], Time: 1.09, lr: [1.3342492642022254e-09], Loss: 1.238891, Acc:0.592809, Semantic loss: 0.119320, BCE loss: 1.075163, SB loss: 0.044408
2025-01-23 14:52:59,883 Epoch: [19/20] Iter:[210/288], Time: 1.09, lr: [1.1969822476364907e-09], Loss: 1.235776, Acc:0.591726, Semantic loss: 0.119956, BCE loss: 1.071381, SB loss: 0.044439
2025-01-23 14:53:10,653 Epoch: [19/20] Iter:[220/288], Time: 1.09, lr: [1.0579389053899705e-09], Loss: 1.222676, Acc:0.587264, Semantic loss: 0.119754, BCE loss: 1.058501, SB loss: 0.044420
2025-01-23 14:53:21,569 Epoch: [19/20] Iter:[230/288], Time: 1.09, lr: [9.168277741850882e-10], Loss: 1.225157, Acc:0.587332, Semantic loss: 0.119520, BCE loss: 1.061214, SB loss: 0.044423
2025-01-23 14:53:32,536 Epoch: [19/20] Iter:[240/288], Time: 1.09, lr: [7.732495584482736e-10], Loss: 1.223794, Acc:0.586688, Semantic loss: 0.119629, BCE loss: 1.059708, SB loss: 0.044457
2025-01-23 14:53:43,087 Epoch: [19/20] Iter:[250/288], Time: 1.09, lr: [6.266251246259543e-10], Loss: 1.229415, Acc:0.588583, Semantic loss: 0.119354, BCE loss: 1.065675, SB loss: 0.044387
2025-01-23 14:53:53,857 Epoch: [19/20] Iter:[260/288], Time: 1.09, lr: [4.760414783720139e-10], Loss: 1.226668, Acc:0.589349, Semantic loss: 0.118926, BCE loss: 1.063429, SB loss: 0.044313
2025-01-23 14:54:04,808 Epoch: [19/20] Iter:[270/288], Time: 1.09, lr: [3.1985108011120114e-10], Loss: 1.226746, Acc:0.587966, Semantic loss: 0.119064, BCE loss: 1.063319, SB loss: 0.044363
2025-01-23 14:54:15,654 Epoch: [19/20] Iter:[280/288], Time: 1.09, lr: [1.5416420771897145e-10], Loss: 1.227369, Acc:0.586532, Semantic loss: 0.118854, BCE loss: 1.064106, SB loss: 0.044409
2025-01-23 15:04:15,141 0 [0.         0.43507295 0.29481529 0.12858669 0.28648394 0.12136384
 0.14472147 0.05875111] 0.20997075469246082
2025-01-23 15:04:15,142 1 [0.         0.49106376 0.34373513 0.30284902 0.40477098 0.05191908
 0.14656896 0.42162179] 0.30893267241488415
2025-01-23 15:04:15,165 => saving checkpoint to output/loveDa/pidnet_small_loveda_3b_AUG_CHANCE+AUG2checkpoint.pth.tar
2025-01-23 15:04:15,684 Loss: 1.248, MeanIU:  0.3089, Best_mIoU:  0.3108
2025-01-23 15:04:15,685 [0.         0.49106376 0.34373513 0.30284902 0.40477098 0.05191908
 0.14656896 0.42162179]
2025-01-23 15:04:15,788 Hours: 0
2025-01-23 15:04:15,788 Done
