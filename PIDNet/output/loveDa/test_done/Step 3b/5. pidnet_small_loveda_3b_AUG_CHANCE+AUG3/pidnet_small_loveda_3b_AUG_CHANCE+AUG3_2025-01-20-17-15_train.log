2025-01-20 17:15:40,761 Namespace(cfg='configs/loveDa/pidnet_small_loveda_3b_AUG_CHANCE+AUG3.yaml', seed=304, opts=['GPUS', '[0]', 'TRAIN.BATCH_SIZE_PER_GPU', '8'])
2025-01-20 17:15:40,761 AUTO_RESUME: False
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  DATASET: loveDa
  EXTRA_TRAIN_SET: 
  NUM_CLASSES: 8
  ROOT: data/
  SOURCE_DATASET: loveDA-Urban
  SOURCE_TEST_SET: list/loveDA-Urban/val.lst
  SOURCE_TRAIN_SET: list/loveDA-Urban/train.lst
  TARGET_DATASET: loveDA-Rural
  TARGET_SET: list/cityscapes/val.lst
  TARGET_TEST_SET: list/loveDA-Rural/val.lst
  TARGET_TRAIN_SET: list/loveDA-Rural/train.lst
  TEST_SET: list/loveDa-Rural/val.lst
  TRAIN_SET: list/loveDA-Urban/train.lst
GPUS: (0,)
LOG_DIR: log
LOSS:
  BALANCE_WEIGHTS: [0.4, 1.0]
  CLASS_BALANCE: False
  OHEMKEEP: 131072
  OHEMTHRES: 0.7
  SB_WEIGHTS: 0.5
  USE_DICE: False
  USE_FOCAL: False
  USE_OHEM: True
MODEL:
  ALIGN_CORNERS: True
  NAME: pidnet_small
  NUM_OUTPUTS: 2
  PRETRAINED: pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar
OUTPUT_DIR: output
PIN_MEMORY: True
PRINT_FREQ: 10
TEST:
  BASE_SIZE: 1024
  BATCH_SIZE_PER_GPU: 20
  FLIP_TEST: False
  IMAGE_SIZE: [1024, 1024]
  MODEL_FILE: 
  MULTI_SCALE: False
  OUTPUT_INDEX: 1
TRAIN:
  ADVERSARIAL: False
  AUG: True
  AUG1: False
  AUG2: False
  AUG3: True
  AUG4: False
  AUG_CHANCE: True
  BASE_SIZE: 720
  BATCH_SIZE_PER_GPU: 8
  BEGIN_EPOCH: 1
  END_EPOCH: 20
  EVAL_INTERVAL: 1
  EXTRA_EPOCH: 0
  EXTRA_LR: 0.001
  FLIP: True
  GAN: Vanilla
  IGNORE_LABEL: 0
  IMAGE_SIZE: [720, 720]
  LAMBDA_ADV1: 0.001
  LAMBDA_ADV2: 0.001
  LR: 0.001
  LR_D1: 0.001
  LR_D2: 0.001
  MOMENTUM: 0.9
  MULTI_SCALE: True
  NESTEROV: False
  OPTIMIZER: adam
  RESUME: True
  SCALE_FACTOR: 16
  SCHEDULER: True
  SHUFFLE: True
  WD: 0.0005
WORKERS: 0
2025-01-20 17:15:41,070 Attention!!!
2025-01-20 17:15:41,070 Loaded 302 parameters!
2025-01-20 17:15:41,070 Over!!!
2025-01-20 17:15:41,447 => loaded checkpoint (epoch 7)
2025-01-20 17:15:46,049 Epoch: [7/20] Iter:[0/217], Time: 4.59, lr: [0.00024421006497713806], Loss: 1.886602, Acc:0.580346, Semantic loss: 0.153313, BCE loss: 1.687726, SB loss: 0.045563
2025-01-20 17:15:54,474 Epoch: [7/20] Iter:[10/217], Time: 1.17, lr: [0.00024343080916329598], Loss: 1.449435, Acc:0.566799, Semantic loss: 0.124414, BCE loss: 1.279615, SB loss: 0.045406
2025-01-20 17:16:02,886 Epoch: [7/20] Iter:[20/217], Time: 1.01, lr: [0.00024265127608294205], Loss: 1.321956, Acc:0.555889, Semantic loss: 0.122746, BCE loss: 1.153814, SB loss: 0.045395
2025-01-20 17:16:11,631 Epoch: [7/20] Iter:[30/217], Time: 0.97, lr: [0.0002418714646470047], Loss: 1.306572, Acc:0.548336, Semantic loss: 0.127664, BCE loss: 1.132920, SB loss: 0.045987
2025-01-20 17:16:20,218 Epoch: [7/20] Iter:[40/217], Time: 0.94, lr: [0.00024109137375821673], Loss: 1.282581, Acc:0.552643, Semantic loss: 0.128207, BCE loss: 1.107784, SB loss: 0.046590
2025-01-20 17:16:28,642 Epoch: [7/20] Iter:[50/217], Time: 0.92, lr: [0.0002403110023110235], Loss: 1.280505, Acc:0.554703, Semantic loss: 0.128425, BCE loss: 1.105212, SB loss: 0.046868
2025-01-20 17:16:37,014 Epoch: [7/20] Iter:[60/217], Time: 0.91, lr: [0.0002395303491914904], Loss: 1.265447, Acc:0.548258, Semantic loss: 0.129152, BCE loss: 1.089396, SB loss: 0.046900
2025-01-20 17:16:45,399 Epoch: [7/20] Iter:[70/217], Time: 0.90, lr: [0.00023874941327720867], Loss: 1.255626, Acc:0.554114, Semantic loss: 0.128093, BCE loss: 1.080701, SB loss: 0.046833
2025-01-20 17:16:53,755 Epoch: [7/20] Iter:[80/217], Time: 0.89, lr: [0.0002379681934372001], Loss: 1.255407, Acc:0.554238, Semantic loss: 0.127890, BCE loss: 1.080886, SB loss: 0.046630
2025-01-20 17:17:02,194 Epoch: [7/20] Iter:[90/217], Time: 0.89, lr: [0.00023718668853181974], Loss: 1.267232, Acc:0.551984, Semantic loss: 0.127779, BCE loss: 1.092957, SB loss: 0.046496
2025-01-20 17:17:10,520 Epoch: [7/20] Iter:[100/217], Time: 0.88, lr: [0.00023640489741265776], Loss: 1.274244, Acc:0.552684, Semantic loss: 0.127573, BCE loss: 1.100086, SB loss: 0.046585
2025-01-20 17:17:18,757 Epoch: [7/20] Iter:[110/217], Time: 0.88, lr: [0.00023562281892243947], Loss: 1.266405, Acc:0.549537, Semantic loss: 0.128089, BCE loss: 1.091331, SB loss: 0.046985
2025-01-20 17:17:27,192 Epoch: [7/20] Iter:[120/217], Time: 0.87, lr: [0.00023484045189492406], Loss: 1.265766, Acc:0.550470, Semantic loss: 0.128218, BCE loss: 1.090653, SB loss: 0.046895
2025-01-20 17:17:35,726 Epoch: [7/20] Iter:[130/217], Time: 0.87, lr: [0.0002340577951548015], Loss: 1.269772, Acc:0.553031, Semantic loss: 0.127613, BCE loss: 1.095510, SB loss: 0.046649
2025-01-20 17:17:44,409 Epoch: [7/20] Iter:[140/217], Time: 0.87, lr: [0.00023327484751758812], Loss: 1.273451, Acc:0.552717, Semantic loss: 0.127685, BCE loss: 1.098941, SB loss: 0.046825
2025-01-20 17:17:53,193 Epoch: [7/20] Iter:[150/217], Time: 0.87, lr: [0.00023249160778952052], Loss: 1.281292, Acc:0.554304, Semantic loss: 0.127413, BCE loss: 1.107143, SB loss: 0.046736
2025-01-20 17:18:02,093 Epoch: [7/20] Iter:[160/217], Time: 0.87, lr: [0.00023170807476744783], Loss: 1.279401, Acc:0.557179, Semantic loss: 0.126557, BCE loss: 1.106316, SB loss: 0.046527
2025-01-20 17:18:11,517 Epoch: [7/20] Iter:[170/217], Time: 0.88, lr: [0.00023092424723872242], Loss: 1.270801, Acc:0.553644, Semantic loss: 0.126668, BCE loss: 1.097445, SB loss: 0.046689
2025-01-20 17:18:20,132 Epoch: [7/20] Iter:[180/217], Time: 0.88, lr: [0.00023014012398108857], Loss: 1.265859, Acc:0.553501, Semantic loss: 0.126366, BCE loss: 1.092975, SB loss: 0.046519
2025-01-20 17:18:28,697 Epoch: [7/20] Iter:[190/217], Time: 0.87, lr: [0.0002293557037625701], Loss: 1.266199, Acc:0.554524, Semantic loss: 0.126438, BCE loss: 1.093242, SB loss: 0.046518
2025-01-20 17:18:37,189 Epoch: [7/20] Iter:[200/217], Time: 0.87, lr: [0.00022857098534135532], Loss: 1.264724, Acc:0.555207, Semantic loss: 0.126251, BCE loss: 1.091921, SB loss: 0.046553
2025-01-20 17:18:45,654 Epoch: [7/20] Iter:[210/217], Time: 0.87, lr: [0.000227785967465681], Loss: 1.268657, Acc:0.556224, Semantic loss: 0.126390, BCE loss: 1.095724, SB loss: 0.046544
2025-01-20 17:25:11,881 0 [0.         0.47934971 0.32604931 0.14697199 0.31314644 0.18004847
 0.11232037 0.09016501] 0.2060064128682217
2025-01-20 17:25:11,885 1 [0.         0.52566069 0.39975965 0.29330156 0.34127408 0.07075822
 0.0573527  0.42574667] 0.26423169472265573
2025-01-20 17:25:11,897 => saving checkpoint to output\loveDa\pidnet_small_loveda_3b_AUG_CHANCE+AUG3checkpoint.pth.tar
2025-01-20 17:25:12,233 Loss: 1.228, MeanIU:  0.2642, Best_mIoU:  0.2642
2025-01-20 17:25:12,233 [0.         0.52566069 0.39975965 0.29330156 0.34127408 0.07075822
 0.0573527  0.42574667]
2025-01-20 17:25:13,222 Epoch: [8/20] Iter:[0/217], Time: 0.88, lr: [0.0001388700039442685], Loss: 1.126554, Acc:0.575773, Semantic loss: 0.121029, BCE loss: 0.967161, SB loss: 0.038364
2025-01-20 17:25:21,961 Epoch: [8/20] Iter:[10/217], Time: 0.87, lr: [0.00013838994620355251], Loss: 1.210108, Acc:0.549547, Semantic loss: 0.125864, BCE loss: 1.039593, SB loss: 0.044651
2025-01-20 17:25:30,383 Epoch: [8/20] Iter:[20/217], Time: 0.86, lr: [0.00013790970336201395], Loss: 1.186577, Acc:0.540919, Semantic loss: 0.124219, BCE loss: 1.017331, SB loss: 0.045027
2025-01-20 17:25:39,289 Epoch: [8/20] Iter:[30/217], Time: 0.87, lr: [0.0001374292746315284], Loss: 1.243261, Acc:0.547483, Semantic loss: 0.125700, BCE loss: 1.071602, SB loss: 0.045959
2025-01-20 17:25:47,650 Epoch: [8/20] Iter:[40/217], Time: 0.86, lr: [0.00013694865921754035], Loss: 1.218078, Acc:0.536745, Semantic loss: 0.124303, BCE loss: 1.047727, SB loss: 0.046048
2025-01-20 17:25:56,038 Epoch: [8/20] Iter:[50/217], Time: 0.86, lr: [0.0001364678563189853], Loss: 1.216430, Acc:0.547599, Semantic loss: 0.121782, BCE loss: 1.049091, SB loss: 0.045558
2025-01-20 17:26:04,432 Epoch: [8/20] Iter:[60/217], Time: 0.85, lr: [0.00013598686512821068], Loss: 1.233896, Acc:0.557029, Semantic loss: 0.121608, BCE loss: 1.066712, SB loss: 0.045576
2025-01-20 17:26:12,812 Epoch: [8/20] Iter:[70/217], Time: 0.85, lr: [0.00013550568483089572], Loss: 1.243881, Acc:0.556062, Semantic loss: 0.123457, BCE loss: 1.074732, SB loss: 0.045692
2025-01-20 17:26:21,144 Epoch: [8/20] Iter:[80/217], Time: 0.85, lr: [0.00013502431460596964], Loss: 1.253622, Acc:0.558175, Semantic loss: 0.123551, BCE loss: 1.084278, SB loss: 0.045793
2025-01-20 17:26:29,492 Epoch: [8/20] Iter:[90/217], Time: 0.85, lr: [0.00013454275362552893], Loss: 1.257096, Acc:0.559550, Semantic loss: 0.122864, BCE loss: 1.088597, SB loss: 0.045635
2025-01-20 17:26:37,927 Epoch: [8/20] Iter:[100/217], Time: 0.85, lr: [0.0001340610010547529], Loss: 1.260767, Acc:0.563233, Semantic loss: 0.122375, BCE loss: 1.092980, SB loss: 0.045411
2025-01-20 17:26:46,612 Epoch: [8/20] Iter:[110/217], Time: 0.85, lr: [0.00013357905605181818], Loss: 1.263745, Acc:0.565494, Semantic loss: 0.122747, BCE loss: 1.095330, SB loss: 0.045667
2025-01-20 17:26:55,043 Epoch: [8/20] Iter:[120/217], Time: 0.85, lr: [0.00013309691776781162], Loss: 1.266384, Acc:0.564247, Semantic loss: 0.123710, BCE loss: 1.096748, SB loss: 0.045926
2025-01-20 17:27:03,490 Epoch: [8/20] Iter:[130/217], Time: 0.85, lr: [0.0001326145853466417], Loss: 1.260841, Acc:0.566200, Semantic loss: 0.123023, BCE loss: 1.092081, SB loss: 0.045738
2025-01-20 17:27:11,877 Epoch: [8/20] Iter:[140/217], Time: 0.85, lr: [0.00013213205792494867], Loss: 1.254786, Acc:0.567666, Semantic loss: 0.123011, BCE loss: 1.086157, SB loss: 0.045618
2025-01-20 17:27:20,452 Epoch: [8/20] Iter:[150/217], Time: 0.85, lr: [0.00013164933463201295], Loss: 1.247672, Acc:0.567201, Semantic loss: 0.122893, BCE loss: 1.079186, SB loss: 0.045593
2025-01-20 17:27:29,009 Epoch: [8/20] Iter:[160/217], Time: 0.85, lr: [0.00013116641458966246], Loss: 1.250918, Acc:0.569537, Semantic loss: 0.122378, BCE loss: 1.083007, SB loss: 0.045534
2025-01-20 17:27:37,608 Epoch: [8/20] Iter:[170/217], Time: 0.85, lr: [0.00013068329691217758], Loss: 1.254108, Acc:0.570666, Semantic loss: 0.122260, BCE loss: 1.086369, SB loss: 0.045480
2025-01-20 17:27:46,086 Epoch: [8/20] Iter:[180/217], Time: 0.85, lr: [0.00013019998070619543], Loss: 1.254499, Acc:0.569209, Semantic loss: 0.122153, BCE loss: 1.087026, SB loss: 0.045319
2025-01-20 17:27:54,682 Epoch: [8/20] Iter:[190/217], Time: 0.85, lr: [0.00012971646507061197], Loss: 1.259385, Acc:0.569444, Semantic loss: 0.122134, BCE loss: 1.091962, SB loss: 0.045288
2025-01-20 17:28:03,209 Epoch: [8/20] Iter:[200/217], Time: 0.85, lr: [0.0001292327490964824], Loss: 1.262438, Acc:0.569763, Semantic loss: 0.122121, BCE loss: 1.094977, SB loss: 0.045340
2025-01-20 17:28:11,726 Epoch: [8/20] Iter:[210/217], Time: 0.85, lr: [0.00012874883186692022], Loss: 1.262141, Acc:0.569982, Semantic loss: 0.121954, BCE loss: 1.094880, SB loss: 0.045307
2025-01-20 17:42:41,798 0 [0.         0.44898473 0.30506815 0.14223082 0.19590617 0.10557444
 0.11589207 0.06507941] 0.1723419727753948
2025-01-20 17:42:41,800 1 [0.         0.49971053 0.39181726 0.32390639 0.26089875 0.0165305
 0.0468833  0.34055597] 0.23503783744168108
2025-01-20 17:42:41,802 => saving checkpoint to output\loveDa\pidnet_small_loveda_3b_AUG_CHANCE+AUG3checkpoint.pth.tar
2025-01-20 17:42:41,987 Loss: 1.231, MeanIU:  0.2350, Best_mIoU:  0.2642
2025-01-20 17:42:41,987 [0.         0.49971053 0.39181726 0.32390639 0.26089875 0.0165305
 0.0468833  0.34055597]
2025-01-20 17:42:46,567 Epoch: [9/20] Iter:[0/217], Time: 2.75, lr: [7.093948740527816e-05], Loss: 1.731142, Acc:0.631202, Semantic loss: 0.128488, BCE loss: 1.553794, SB loss: 0.048860
2025-01-20 17:43:56,138 Epoch: [9/20] Iter:[10/217], Time: 6.50, lr: [7.067195940843109e-05], Loss: 1.238194, Acc:0.521983, Semantic loss: 0.129852, BCE loss: 1.058761, SB loss: 0.049580
2025-01-20 17:45:07,297 Epoch: [9/20] Iter:[20/217], Time: 6.69, lr: [7.040431883896811e-05], Loss: 1.265788, Acc:0.536217, Semantic loss: 0.127316, BCE loss: 1.090913, SB loss: 0.047559
2025-01-20 17:46:32,888 Epoch: [9/20] Iter:[30/217], Time: 7.18, lr: [7.013656517362446e-05], Loss: 1.269341, Acc:0.543671, Semantic loss: 0.128447, BCE loss: 1.093481, SB loss: 0.047413
2025-01-20 17:47:39,058 Epoch: [9/20] Iter:[40/217], Time: 7.06, lr: [6.986869788447219e-05], Loss: 1.276096, Acc:0.549835, Semantic loss: 0.124385, BCE loss: 1.105290, SB loss: 0.046420
2025-01-20 17:49:15,895 Epoch: [9/20] Iter:[50/217], Time: 7.68, lr: [6.96007164388587e-05], Loss: 1.279075, Acc:0.554760, Semantic loss: 0.125668, BCE loss: 1.106579, SB loss: 0.046828
2025-01-20 17:50:20,300 Epoch: [9/20] Iter:[60/217], Time: 7.47, lr: [6.933262029934392e-05], Loss: 1.285496, Acc:0.559919, Semantic loss: 0.124461, BCE loss: 1.114475, SB loss: 0.046560
2025-01-20 17:51:33,240 Epoch: [9/20] Iter:[70/217], Time: 7.43, lr: [6.906440892363657e-05], Loss: 1.261957, Acc:0.559532, Semantic loss: 0.123829, BCE loss: 1.091638, SB loss: 0.046490
2025-01-20 17:52:42,324 Epoch: [9/20] Iter:[80/217], Time: 7.32, lr: [6.879608176452924e-05], Loss: 1.257164, Acc:0.559496, Semantic loss: 0.124067, BCE loss: 1.086652, SB loss: 0.046445
2025-01-20 17:53:52,606 Epoch: [9/20] Iter:[90/217], Time: 7.31, lr: [6.852763826983231e-05], Loss: 1.250123, Acc:0.562788, Semantic loss: 0.123073, BCE loss: 1.080783, SB loss: 0.046267
2025-01-20 17:55:08,956 Epoch: [9/20] Iter:[100/217], Time: 7.31, lr: [6.825907788230672e-05], Loss: 1.243641, Acc:0.564603, Semantic loss: 0.123447, BCE loss: 1.074049, SB loss: 0.046145
2025-01-20 17:56:23,666 Epoch: [9/20] Iter:[110/217], Time: 7.36, lr: [6.799040003959548e-05], Loss: 1.242603, Acc:0.565494, Semantic loss: 0.122706, BCE loss: 1.073991, SB loss: 0.045906
2025-01-20 17:57:26,910 Epoch: [9/20] Iter:[120/217], Time: 7.29, lr: [6.772160417415395e-05], Loss: 1.252897, Acc:0.566855, Semantic loss: 0.122717, BCE loss: 1.084088, SB loss: 0.046092
2025-01-20 17:58:32,052 Epoch: [9/20] Iter:[130/217], Time: 7.22, lr: [6.745268971317899e-05], Loss: 1.248277, Acc:0.566343, Semantic loss: 0.123017, BCE loss: 1.079013, SB loss: 0.046247
2025-01-20 17:59:56,833 Epoch: [9/20] Iter:[140/217], Time: 7.28, lr: [6.718365607853656e-05], Loss: 1.244752, Acc:0.565905, Semantic loss: 0.123124, BCE loss: 1.075416, SB loss: 0.046211
2025-01-20 18:01:08,307 Epoch: [9/20] Iter:[150/217], Time: 7.31, lr: [6.69145026866883e-05], Loss: 1.243267, Acc:0.567450, Semantic loss: 0.122568, BCE loss: 1.074745, SB loss: 0.045954
2025-01-20 18:02:18,760 Epoch: [9/20] Iter:[160/217], Time: 7.30, lr: [6.664522894861654e-05], Loss: 1.244830, Acc:0.568139, Semantic loss: 0.122060, BCE loss: 1.077015, SB loss: 0.045756
2025-01-20 18:03:44,890 Epoch: [9/20] Iter:[170/217], Time: 7.39, lr: [6.637583426974808e-05], Loss: 1.244790, Acc:0.568231, Semantic loss: 0.122432, BCE loss: 1.076529, SB loss: 0.045829
2025-01-20 18:05:04,592 Epoch: [9/20] Iter:[180/217], Time: 7.41, lr: [6.610631804987636e-05], Loss: 1.245334, Acc:0.569293, Semantic loss: 0.122472, BCE loss: 1.077127, SB loss: 0.045735
2025-01-20 18:06:26,058 Epoch: [9/20] Iter:[190/217], Time: 7.43, lr: [6.583667968308244e-05], Loss: 1.242937, Acc:0.569922, Semantic loss: 0.122413, BCE loss: 1.074917, SB loss: 0.045607
2025-01-20 18:07:41,945 Epoch: [9/20] Iter:[200/217], Time: 7.45, lr: [6.556691855765438e-05], Loss: 1.245507, Acc:0.571307, Semantic loss: 0.122246, BCE loss: 1.077725, SB loss: 0.045535
2025-01-20 18:08:48,309 Epoch: [9/20] Iter:[210/217], Time: 7.41, lr: [6.529703405600493e-05], Loss: 1.236934, Acc:0.568085, Semantic loss: 0.122239, BCE loss: 1.069054, SB loss: 0.045642
2025-01-20 18:26:02,531 0 [0.         0.46036102 0.30628334 0.13520865 0.24529138 0.08186116
 0.092548   0.076889  ] 0.17480531714484773
2025-01-20 18:26:02,531 1 [0.         0.4988424  0.30817851 0.30289621 0.25429437 0.02503637
 0.05693408 0.39262917] 0.22985138953365852
2025-01-20 18:26:02,533 => saving checkpoint to output\loveDa\pidnet_small_loveda_3b_AUG_CHANCE+AUG3checkpoint.pth.tar
2025-01-20 18:26:02,717 Loss: 1.196, MeanIU:  0.2299, Best_mIoU:  0.2642
2025-01-20 18:26:02,717 [0.         0.4988424  0.30817851 0.30289621 0.25429437 0.02503637
 0.05693408 0.39262917]
