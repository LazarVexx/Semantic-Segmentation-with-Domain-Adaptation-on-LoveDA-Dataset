2025-01-23 09:40:38,495 Namespace(cfg='configs/loveDa/pidnet_small_loveda_3b_AUG_CHANCE+AUG1.yaml', seed=304, opts=['GPUS', '[0]', 'TRAIN.BATCH_SIZE_PER_GPU', '6'])
2025-01-23 09:40:38,495 AUTO_RESUME: False
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  DATASET: loveDa
  EXTRA_TRAIN_SET: 
  NUM_CLASSES: 8
  ROOT: data/
  SOURCE_DATASET: loveDA-Urban
  SOURCE_TEST_SET: list/loveDA-Urban/val.lst
  SOURCE_TRAIN_SET: list/loveDA-Urban/train.lst
  TARGET_DATASET: loveDA-Rural
  TARGET_SET: list/cityscapes/val.lst
  TARGET_TEST_SET: list/loveDA-Rural/val.lst
  TARGET_TRAIN_SET: list/loveDA-Rural/train.lst
  TEST_SET: list/loveDa-Rural/val.lst
  TRAIN_SET: list/loveDA-Urban/train.lst
GPUS: (0,)
LOG_DIR: log
LOSS:
  BALANCE_WEIGHTS: [0.4, 1.0]
  CLASS_BALANCE: False
  OHEMKEEP: 131072
  OHEMTHRES: 0.7
  SB_WEIGHTS: 0.5
  USE_DICE: False
  USE_FOCAL: False
  USE_OHEM: True
MODEL:
  ALIGN_CORNERS: True
  NAME: pidnet_small
  NUM_OUTPUTS: 2
  PRETRAINED: pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar
OUTPUT_DIR: output
PIN_MEMORY: True
PRINT_FREQ: 10
TEST:
  BASE_SIZE: 1024
  BATCH_SIZE_PER_GPU: 6
  FLIP_TEST: False
  IMAGE_SIZE: [1024, 1024]
  MODEL_FILE: 
  MULTI_SCALE: False
  OUTPUT_INDEX: 1
TRAIN:
  ADVERSARIAL: False
  AUG: True
  AUG1: True
  AUG2: False
  AUG3: False
  AUG4: False
  AUG_CHANCE: True
  BASE_SIZE: 720
  BATCH_SIZE_PER_GPU: 6
  BEGIN_EPOCH: 1
  END_EPOCH: 20
  EVAL_INTERVAL: 1
  EXTRA_EPOCH: 0
  EXTRA_LR: 0.001
  FLIP: True
  GAN: Vanilla
  IGNORE_LABEL: 0
  IMAGE_SIZE: [720, 720]
  LAMBDA_ADV1: 0.001
  LAMBDA_ADV2: 0.001
  LR: 0.001
  LR_D1: 0.001
  LR_D2: 0.001
  MOMENTUM: 0.9
  MULTI_SCALE: True
  NESTEROV: False
  OPTIMIZER: adam
  RESUME: False
  SCALE_FACTOR: 16
  SCHEDULER: True
  SHUFFLE: True
  WD: 0.0005
WORKERS: 0
2025-01-23 09:40:38,707 Attention!!!
2025-01-23 09:40:38,707 Loaded 302 parameters!
2025-01-23 09:40:38,707 Over!!!
2025-01-23 09:40:47,619 Epoch: [0/20] Iter:[0/294], Time: 8.73, lr: [0.0002], Loss: 5.067385, Acc:0.155252, Semantic loss: 0.604787, BCE loss: 4.213683, SB loss: 0.248915
2025-01-23 09:40:58,661 Epoch: [0/20] Iter:[10/294], Time: 1.79, lr: [0.00019969385150395307], Loss: 3.479153, Acc:0.245349, Semantic loss: 0.481741, BCE loss: 2.820565, SB loss: 0.176847
2025-01-23 09:41:09,228 Epoch: [0/20] Iter:[20/294], Time: 1.44, lr: [0.0001993876508486675], Loss: 2.996552, Acc:0.262226, Semantic loss: 0.427322, BCE loss: 2.413969, SB loss: 0.155261
2025-01-23 09:41:19,169 Epoch: [0/20] Iter:[30/294], Time: 1.30, lr: [0.00019908139793622514], Loss: 2.767952, Acc:0.274046, Semantic loss: 0.393499, BCE loss: 2.237486, SB loss: 0.136967
2025-01-23 09:41:29,528 Epoch: [0/20] Iter:[40/294], Time: 1.23, lr: [0.00019877509266835605], Loss: 2.549026, Acc:0.287738, Semantic loss: 0.365808, BCE loss: 2.058182, SB loss: 0.125036
2025-01-23 09:41:39,940 Epoch: [0/20] Iter:[50/294], Time: 1.19, lr: [0.0001984687349464371], Loss: 2.373695, Acc:0.300603, Semantic loss: 0.342576, BCE loss: 1.914983, SB loss: 0.116136
2025-01-23 09:41:50,313 Epoch: [0/20] Iter:[60/294], Time: 1.17, lr: [0.0001981623246714898], Loss: 2.243098, Acc:0.311519, Semantic loss: 0.323037, BCE loss: 1.810809, SB loss: 0.109251
2025-01-23 09:42:01,040 Epoch: [0/20] Iter:[70/294], Time: 1.15, lr: [0.00019785586174417844], Loss: 2.161670, Acc:0.329400, Semantic loss: 0.305169, BCE loss: 1.753880, SB loss: 0.102621
2025-01-23 09:42:11,546 Epoch: [0/20] Iter:[80/294], Time: 1.14, lr: [0.00019754934606480828], Loss: 2.097898, Acc:0.339239, Semantic loss: 0.291566, BCE loss: 1.708150, SB loss: 0.098182
2025-01-23 09:42:21,457 Epoch: [0/20] Iter:[90/294], Time: 1.13, lr: [0.00019724277753332365], Loss: 2.032200, Acc:0.345739, Semantic loss: 0.280375, BCE loss: 1.657504, SB loss: 0.094322
2025-01-23 09:42:32,136 Epoch: [0/20] Iter:[100/294], Time: 1.12, lr: [0.00019693615604930581], Loss: 1.978549, Acc:0.357499, Semantic loss: 0.271130, BCE loss: 1.616668, SB loss: 0.090751
2025-01-23 09:42:42,695 Epoch: [0/20] Iter:[110/294], Time: 1.11, lr: [0.0001966294815119713], Loss: 1.924809, Acc:0.362177, Semantic loss: 0.264691, BCE loss: 1.571650, SB loss: 0.088468
2025-01-23 09:42:53,253 Epoch: [0/20] Iter:[120/294], Time: 1.11, lr: [0.00019632275382016975], Loss: 1.899359, Acc:0.369634, Semantic loss: 0.257698, BCE loss: 1.555649, SB loss: 0.086012
2025-01-23 09:43:03,889 Epoch: [0/20] Iter:[130/294], Time: 1.11, lr: [0.0001960159728723819], Loss: 1.873735, Acc:0.373328, Semantic loss: 0.256135, BCE loss: 1.533256, SB loss: 0.084343
2025-01-23 09:43:14,067 Epoch: [0/20] Iter:[140/294], Time: 1.10, lr: [0.00019570913856671783], Loss: 1.868965, Acc:0.377018, Semantic loss: 0.252746, BCE loss: 1.533312, SB loss: 0.082906
2025-01-23 09:43:24,689 Epoch: [0/20] Iter:[150/294], Time: 1.10, lr: [0.00019540225080091474], Loss: 1.854674, Acc:0.382071, Semantic loss: 0.248728, BCE loss: 1.524611, SB loss: 0.081336
2025-01-23 09:43:35,174 Epoch: [0/20] Iter:[160/294], Time: 1.09, lr: [0.00019509530947233502], Loss: 1.830306, Acc:0.384442, Semantic loss: 0.244991, BCE loss: 1.505024, SB loss: 0.080291
2025-01-23 09:43:45,538 Epoch: [0/20] Iter:[170/294], Time: 1.09, lr: [0.00019478831447796425], Loss: 1.809636, Acc:0.386993, Semantic loss: 0.240539, BCE loss: 1.490187, SB loss: 0.078910
2025-01-23 09:43:56,550 Epoch: [0/20] Iter:[180/294], Time: 1.09, lr: [0.0001944812657144091], Loss: 1.807906, Acc:0.392471, Semantic loss: 0.236799, BCE loss: 1.493540, SB loss: 0.077567
2025-01-23 09:44:07,259 Epoch: [0/20] Iter:[190/294], Time: 1.09, lr: [0.0001941741630778952], Loss: 1.785287, Acc:0.393751, Semantic loss: 0.233253, BCE loss: 1.475393, SB loss: 0.076641
2025-01-23 09:44:17,055 Epoch: [0/20] Iter:[200/294], Time: 1.08, lr: [0.00019386700646426529], Loss: 1.769833, Acc:0.396982, Semantic loss: 0.229410, BCE loss: 1.464957, SB loss: 0.075466
2025-01-23 09:44:27,633 Epoch: [0/20] Iter:[210/294], Time: 1.08, lr: [0.00019355979576897686], Loss: 1.754159, Acc:0.400720, Semantic loss: 0.226027, BCE loss: 1.453632, SB loss: 0.074501
2025-01-23 09:44:38,332 Epoch: [0/20] Iter:[220/294], Time: 1.08, lr: [0.00019325253088710022], Loss: 1.738914, Acc:0.402974, Semantic loss: 0.223075, BCE loss: 1.442349, SB loss: 0.073490
2025-01-23 09:44:48,926 Epoch: [0/20] Iter:[230/294], Time: 1.08, lr: [0.0001929452117133164], Loss: 1.729626, Acc:0.404591, Semantic loss: 0.221096, BCE loss: 1.435693, SB loss: 0.072838
2025-01-23 09:44:59,529 Epoch: [0/20] Iter:[240/294], Time: 1.08, lr: [0.0001926378381419148], Loss: 1.711193, Acc:0.406591, Semantic loss: 0.218351, BCE loss: 1.420906, SB loss: 0.071937
2025-01-23 09:45:09,467 Epoch: [0/20] Iter:[250/294], Time: 1.08, lr: [0.00019233041006679128], Loss: 1.701219, Acc:0.408048, Semantic loss: 0.216279, BCE loss: 1.413576, SB loss: 0.071364
2025-01-23 09:45:19,552 Epoch: [0/20] Iter:[260/294], Time: 1.07, lr: [0.0001920229273814459], Loss: 1.696100, Acc:0.411695, Semantic loss: 0.213940, BCE loss: 1.411629, SB loss: 0.070530
2025-01-23 09:45:30,338 Epoch: [0/20] Iter:[270/294], Time: 1.07, lr: [0.0001917153899789807], Loss: 1.687398, Acc:0.414134, Semantic loss: 0.211917, BCE loss: 1.405436, SB loss: 0.070044
2025-01-23 09:45:40,904 Epoch: [0/20] Iter:[280/294], Time: 1.07, lr: [0.0001914077977520975], Loss: 1.677999, Acc:0.416967, Semantic loss: 0.209939, BCE loss: 1.398552, SB loss: 0.069507
2025-01-23 09:45:51,825 Epoch: [0/20] Iter:[290/294], Time: 1.07, lr: [0.00019110015059309576], Loss: 1.678015, Acc:0.420652, Semantic loss: 0.208415, BCE loss: 1.400709, SB loss: 0.068891
2025-01-23 09:55:26,810 0 [0.         0.44361888 0.11018541 0.10435049 0.17096822 0.12912981
 0.02349127 0.01880816] 0.1429360336284553
2025-01-23 09:55:26,811 1 [0.         0.4081644  0.16695319 0.15693955 0.30432034 0.06459091
 0.02652394 0.00846414] 0.1622794966009564
2025-01-23 09:55:26,812 => saving checkpoint to output/loveDa/pidnet_small_loveda_3b_AUG_CHANCE+AUG1checkpoint.pth.tar
2025-01-23 09:55:27,108 Loss: 1.294, MeanIU:  0.1623, Best_mIoU:  0.1623
2025-01-23 09:55:27,108 [0.         0.4081644  0.16695319 0.15693955 0.30432034 0.06459091
 0.02652394 0.00846414]
2025-01-23 09:55:28,160 Epoch: [1/20] Iter:[0/294], Time: 0.90, lr: [0.0003819541526485999], Loss: 1.066002, Acc:0.490076, Semantic loss: 0.160090, BCE loss: 0.848093, SB loss: 0.057819
2025-01-23 09:55:39,167 Epoch: [1/20] Iter:[10/294], Time: 1.08, lr: [0.000381338704157249], Loss: 1.318098, Acc:0.462906, Semantic loss: 0.152035, BCE loss: 1.110031, SB loss: 0.056032
2025-01-23 09:55:50,012 Epoch: [1/20] Iter:[20/294], Time: 1.08, lr: [0.00038072314528138796], Loss: 1.391113, Acc:0.459436, Semantic loss: 0.159847, BCE loss: 1.174936, SB loss: 0.056330
2025-01-23 09:56:00,735 Epoch: [1/20] Iter:[30/294], Time: 1.08, lr: [0.00038010747580284577], Loss: 1.373142, Acc:0.449536, Semantic loss: 0.160461, BCE loss: 1.156649, SB loss: 0.056032
2025-01-23 09:56:10,967 Epoch: [1/20] Iter:[40/294], Time: 1.07, lr: [0.0003794916955026267], Loss: 1.367168, Acc:0.455656, Semantic loss: 0.157881, BCE loss: 1.153671, SB loss: 0.055616
2025-01-23 09:56:21,578 Epoch: [1/20] Iter:[50/294], Time: 1.07, lr: [0.00037887580416090576], Loss: 1.380788, Acc:0.461686, Semantic loss: 0.161510, BCE loss: 1.163854, SB loss: 0.055424
2025-01-23 09:56:32,508 Epoch: [1/20] Iter:[60/294], Time: 1.07, lr: [0.0003782598015570238], Loss: 1.381195, Acc:0.460350, Semantic loss: 0.164417, BCE loss: 1.160692, SB loss: 0.056086
2025-01-23 09:56:43,473 Epoch: [1/20] Iter:[70/294], Time: 1.07, lr: [0.00037764368746948335], Loss: 1.399167, Acc:0.463919, Semantic loss: 0.161508, BCE loss: 1.182424, SB loss: 0.055235
2025-01-23 09:56:54,280 Epoch: [1/20] Iter:[80/294], Time: 1.07, lr: [0.00037702746167594335], Loss: 1.395665, Acc:0.464234, Semantic loss: 0.160139, BCE loss: 1.180267, SB loss: 0.055259
2025-01-23 09:57:05,134 Epoch: [1/20] Iter:[90/294], Time: 1.08, lr: [0.0003764111239532149], Loss: 1.389939, Acc:0.468119, Semantic loss: 0.159016, BCE loss: 1.176398, SB loss: 0.054525
2025-01-23 09:57:15,261 Epoch: [1/20] Iter:[100/294], Time: 1.07, lr: [0.0003757946740772559], Loss: 1.374077, Acc:0.465525, Semantic loss: 0.157394, BCE loss: 1.162452, SB loss: 0.054231
2025-01-23 09:57:25,967 Epoch: [1/20] Iter:[110/294], Time: 1.07, lr: [0.00037517811182316677], Loss: 1.378422, Acc:0.468946, Semantic loss: 0.157359, BCE loss: 1.167073, SB loss: 0.053991
2025-01-23 09:57:36,775 Epoch: [1/20] Iter:[120/294], Time: 1.07, lr: [0.0003745614369651854], Loss: 1.369290, Acc:0.466971, Semantic loss: 0.157007, BCE loss: 1.158084, SB loss: 0.054199
2025-01-23 09:57:47,563 Epoch: [1/20] Iter:[130/294], Time: 1.07, lr: [0.00037394464927668203], Loss: 1.362635, Acc:0.469038, Semantic loss: 0.157090, BCE loss: 1.151671, SB loss: 0.053874
2025-01-23 09:57:58,290 Epoch: [1/20] Iter:[140/294], Time: 1.07, lr: [0.00037332774853015486], Loss: 1.362179, Acc:0.468530, Semantic loss: 0.157927, BCE loss: 1.150022, SB loss: 0.054230
2025-01-23 09:58:08,834 Epoch: [1/20] Iter:[150/294], Time: 1.07, lr: [0.0003727107344972244], Loss: 1.359729, Acc:0.467305, Semantic loss: 0.158613, BCE loss: 1.146773, SB loss: 0.054344
2025-01-23 09:58:19,192 Epoch: [1/20] Iter:[160/294], Time: 1.07, lr: [0.0003720936069486291], Loss: 1.360326, Acc:0.469117, Semantic loss: 0.158195, BCE loss: 1.147684, SB loss: 0.054447
2025-01-23 09:58:29,302 Epoch: [1/20] Iter:[170/294], Time: 1.06, lr: [0.00037147636565421966], Loss: 1.355222, Acc:0.469112, Semantic loss: 0.157122, BCE loss: 1.143841, SB loss: 0.054259
2025-01-23 09:58:39,991 Epoch: [1/20] Iter:[180/294], Time: 1.06, lr: [0.0003708590103829549], Loss: 1.364224, Acc:0.469455, Semantic loss: 0.157084, BCE loss: 1.152854, SB loss: 0.054287
2025-01-23 09:58:50,660 Epoch: [1/20] Iter:[190/294], Time: 1.06, lr: [0.00037024154090289544], Loss: 1.375841, Acc:0.470534, Semantic loss: 0.156900, BCE loss: 1.164560, SB loss: 0.054381
2025-01-23 09:59:01,223 Epoch: [1/20] Iter:[200/294], Time: 1.06, lr: [0.0003696239569811996], Loss: 1.384085, Acc:0.474025, Semantic loss: 0.156588, BCE loss: 1.173292, SB loss: 0.054206
2025-01-23 09:59:11,822 Epoch: [1/20] Iter:[210/294], Time: 1.06, lr: [0.00036900625838411744], Loss: 1.383031, Acc:0.474613, Semantic loss: 0.156419, BCE loss: 1.172455, SB loss: 0.054157
2025-01-23 09:59:21,591 Epoch: [1/20] Iter:[220/294], Time: 1.06, lr: [0.0003683884448769862], Loss: 1.380100, Acc:0.476004, Semantic loss: 0.155643, BCE loss: 1.170534, SB loss: 0.053923
2025-01-23 09:59:32,241 Epoch: [1/20] Iter:[230/294], Time: 1.06, lr: [0.0003677705162242243], Loss: 1.378120, Acc:0.477264, Semantic loss: 0.155392, BCE loss: 1.168888, SB loss: 0.053840
2025-01-23 09:59:42,984 Epoch: [1/20] Iter:[240/294], Time: 1.06, lr: [0.00036715247218932674], Loss: 1.381540, Acc:0.479180, Semantic loss: 0.154693, BCE loss: 1.173182, SB loss: 0.053665
2025-01-23 09:59:53,605 Epoch: [1/20] Iter:[250/294], Time: 1.06, lr: [0.00036653431253485906], Loss: 1.381575, Acc:0.479019, Semantic loss: 0.154292, BCE loss: 1.173783, SB loss: 0.053500
2025-01-23 10:00:04,375 Epoch: [1/20] Iter:[260/294], Time: 1.06, lr: [0.00036591603702245263], Loss: 1.381525, Acc:0.479241, Semantic loss: 0.154039, BCE loss: 1.174079, SB loss: 0.053407
2025-01-23 10:00:14,998 Epoch: [1/20] Iter:[270/294], Time: 1.06, lr: [0.00036529764541279856], Loss: 1.382485, Acc:0.479431, Semantic loss: 0.153753, BCE loss: 1.175413, SB loss: 0.053320
2025-01-23 10:00:25,058 Epoch: [1/20] Iter:[280/294], Time: 1.06, lr: [0.00036467913746564273], Loss: 1.377727, Acc:0.477940, Semantic loss: 0.153641, BCE loss: 1.170608, SB loss: 0.053477
2025-01-23 10:00:35,707 Epoch: [1/20] Iter:[290/294], Time: 1.06, lr: [0.00036406051293977993], Loss: 1.372867, Acc:0.477535, Semantic loss: 0.153713, BCE loss: 1.165601, SB loss: 0.053553
2025-01-23 10:10:10,600 0 [0.         0.42947187 0.19631609 0.09522976 0.23589759 0.15766342
 0.04400212 0.0302866 ] 0.16983820573470718
2025-01-23 10:10:10,600 1 [0.         0.43696625 0.23764741 0.19031105 0.25028555 0.09388682
 0.0339861  0.26627383] 0.21562242941091178
2025-01-23 10:10:10,601 => saving checkpoint to output/loveDa/pidnet_small_loveda_3b_AUG_CHANCE+AUG1checkpoint.pth.tar
2025-01-23 10:10:11,001 Loss: 1.177, MeanIU:  0.2156, Best_mIoU:  0.2156
2025-01-23 10:10:11,001 [0.         0.43696625 0.23764741 0.19031105 0.25028555 0.09388682
 0.0339861  0.26627383]
2025-01-23 10:10:12,155 Epoch: [2/20] Iter:[0/294], Time: 0.98, lr: [0.0005457195456497774], Loss: 1.506125, Acc:0.462000, Semantic loss: 0.158099, BCE loss: 1.295009, SB loss: 0.053017
2025-01-23 10:10:22,742 Epoch: [2/20] Iter:[10/294], Time: 1.05, lr: [0.000544791363435128], Loss: 1.314379, Acc:0.505059, Semantic loss: 0.147267, BCE loss: 1.116671, SB loss: 0.050441
2025-01-23 10:10:33,351 Epoch: [2/20] Iter:[20/294], Time: 1.06, lr: [0.0005438630054782096], Loss: 1.438116, Acc:0.494131, Semantic loss: 0.154669, BCE loss: 1.227897, SB loss: 0.055550
2025-01-23 10:10:43,730 Epoch: [2/20] Iter:[30/294], Time: 1.05, lr: [0.0005429344714123016], Loss: 1.347834, Acc:0.488626, Semantic loss: 0.153915, BCE loss: 1.139055, SB loss: 0.054864
2025-01-23 10:10:53,961 Epoch: [2/20] Iter:[40/294], Time: 1.04, lr: [0.0005420057608692197], Loss: 1.313315, Acc:0.482570, Semantic loss: 0.150860, BCE loss: 1.108210, SB loss: 0.054245
2025-01-23 10:11:04,161 Epoch: [2/20] Iter:[50/294], Time: 1.04, lr: [0.0005410768734793076], Loss: 1.320557, Acc:0.479707, Semantic loss: 0.150986, BCE loss: 1.115206, SB loss: 0.054365
2025-01-23 10:11:14,728 Epoch: [2/20] Iter:[60/294], Time: 1.04, lr: [0.0005401478088714275], Loss: 1.343313, Acc:0.474058, Semantic loss: 0.150925, BCE loss: 1.138073, SB loss: 0.054316
2025-01-23 10:11:25,312 Epoch: [2/20] Iter:[70/294], Time: 1.04, lr: [0.0005392185666729521], Loss: 1.349173, Acc:0.472725, Semantic loss: 0.150852, BCE loss: 1.144110, SB loss: 0.054211
2025-01-23 10:11:35,883 Epoch: [2/20] Iter:[80/294], Time: 1.05, lr: [0.0005382891465097556], Loss: 1.361854, Acc:0.476584, Semantic loss: 0.150087, BCE loss: 1.158230, SB loss: 0.053537
2025-01-23 10:11:46,604 Epoch: [2/20] Iter:[90/294], Time: 1.05, lr: [0.0005373595480062042], Loss: 1.374425, Acc:0.479277, Semantic loss: 0.149423, BCE loss: 1.171432, SB loss: 0.053570
2025-01-23 10:11:57,128 Epoch: [2/20] Iter:[100/294], Time: 1.05, lr: [0.0005364297707851478], Loss: 1.364969, Acc:0.477795, Semantic loss: 0.149667, BCE loss: 1.161301, SB loss: 0.054001
2025-01-23 10:12:07,036 Epoch: [2/20] Iter:[110/294], Time: 1.04, lr: [0.0005354998144679108], Loss: 1.366751, Acc:0.480333, Semantic loss: 0.149984, BCE loss: 1.162983, SB loss: 0.053784
2025-01-23 10:12:17,711 Epoch: [2/20] Iter:[120/294], Time: 1.05, lr: [0.0005345696786742827], Loss: 1.378062, Acc:0.485043, Semantic loss: 0.150165, BCE loss: 1.174115, SB loss: 0.053782
2025-01-23 10:12:28,887 Epoch: [2/20] Iter:[130/294], Time: 1.05, lr: [0.0005336393630225092], Loss: 1.388739, Acc:0.485768, Semantic loss: 0.151236, BCE loss: 1.183937, SB loss: 0.053566
2025-01-23 10:12:39,517 Epoch: [2/20] Iter:[140/294], Time: 1.05, lr: [0.0005327088671292826], Loss: 1.397154, Acc:0.488820, Semantic loss: 0.151924, BCE loss: 1.191817, SB loss: 0.053414
2025-01-23 10:12:50,082 Epoch: [2/20] Iter:[150/294], Time: 1.05, lr: [0.0005317781906097328], Loss: 1.385452, Acc:0.486983, Semantic loss: 0.151457, BCE loss: 1.180747, SB loss: 0.053249
2025-01-23 10:13:00,823 Epoch: [2/20] Iter:[160/294], Time: 1.05, lr: [0.0005308473330774177], Loss: 1.394550, Acc:0.487290, Semantic loss: 0.151477, BCE loss: 1.189803, SB loss: 0.053269
2025-01-23 10:13:10,727 Epoch: [2/20] Iter:[170/294], Time: 1.05, lr: [0.0005299162941443139], Loss: 1.392402, Acc:0.484913, Semantic loss: 0.151629, BCE loss: 1.187597, SB loss: 0.053176
2025-01-23 10:13:21,167 Epoch: [2/20] Iter:[180/294], Time: 1.05, lr: [0.0005289850734208065], Loss: 1.387448, Acc:0.485663, Semantic loss: 0.150924, BCE loss: 1.183472, SB loss: 0.053052
2025-01-23 10:13:32,020 Epoch: [2/20] Iter:[190/294], Time: 1.05, lr: [0.0005280536705156803], Loss: 1.392209, Acc:0.487134, Semantic loss: 0.151254, BCE loss: 1.187809, SB loss: 0.053147
2025-01-23 10:13:42,665 Epoch: [2/20] Iter:[200/294], Time: 1.05, lr: [0.0005271220850361099], Loss: 1.386103, Acc:0.487343, Semantic loss: 0.150595, BCE loss: 1.182461, SB loss: 0.053047
2025-01-23 10:13:53,370 Epoch: [2/20] Iter:[210/294], Time: 1.05, lr: [0.000526190316587649], Loss: 1.390067, Acc:0.487944, Semantic loss: 0.150537, BCE loss: 1.186737, SB loss: 0.052794
2025-01-23 10:14:03,483 Epoch: [2/20] Iter:[220/294], Time: 1.05, lr: [0.0005252583647742216], Loss: 1.385194, Acc:0.486928, Semantic loss: 0.150673, BCE loss: 1.181505, SB loss: 0.053016
2025-01-23 10:14:13,675 Epoch: [2/20] Iter:[230/294], Time: 1.05, lr: [0.0005243262291981118], Loss: 1.378635, Acc:0.487026, Semantic loss: 0.149995, BCE loss: 1.175812, SB loss: 0.052827
2025-01-23 10:14:24,221 Epoch: [2/20] Iter:[240/294], Time: 1.05, lr: [0.000523393909459953], Loss: 1.373574, Acc:0.488388, Semantic loss: 0.149394, BCE loss: 1.171423, SB loss: 0.052757
2025-01-23 10:14:34,742 Epoch: [2/20] Iter:[250/294], Time: 1.05, lr: [0.0005224614051587193], Loss: 1.366833, Acc:0.488617, Semantic loss: 0.149010, BCE loss: 1.165232, SB loss: 0.052591
2025-01-23 10:14:45,351 Epoch: [2/20] Iter:[260/294], Time: 1.05, lr: [0.0005215287158917131], Loss: 1.365599, Acc:0.488809, Semantic loss: 0.148568, BCE loss: 1.164480, SB loss: 0.052552
2025-01-23 10:14:55,775 Epoch: [2/20] Iter:[270/294], Time: 1.05, lr: [0.0005205958412545576], Loss: 1.361229, Acc:0.489801, Semantic loss: 0.148358, BCE loss: 1.160285, SB loss: 0.052587
2025-01-23 10:15:05,644 Epoch: [2/20] Iter:[280/294], Time: 1.05, lr: [0.0005196627808411832], Loss: 1.365874, Acc:0.492049, Semantic loss: 0.147819, BCE loss: 1.165642, SB loss: 0.052412
2025-01-23 10:15:15,908 Epoch: [2/20] Iter:[290/294], Time: 1.05, lr: [0.00051872953424382], Loss: 1.360042, Acc:0.492818, Semantic loss: 0.147599, BCE loss: 1.160091, SB loss: 0.052352
2025-01-23 10:24:46,852 0 [0.         0.46924302 0.26597406 0.1158858  0.30001399 0.04592911
 0.007064   0.01818256] 0.1746132185735946
2025-01-23 10:24:46,853 1 [0.         0.4191735  0.25781542 0.13729896 0.23665209 0.0161269
 0.00152291 0.04416546] 0.15896503387492164
2025-01-23 10:24:46,854 => saving checkpoint to output/loveDa/pidnet_small_loveda_3b_AUG_CHANCE+AUG1checkpoint.pth.tar
2025-01-23 10:24:47,150 Loss: 1.241, MeanIU:  0.1590, Best_mIoU:  0.2156
2025-01-23 10:24:47,150 [0.         0.4191735  0.25781542 0.13729896 0.23665209 0.0161269
 0.00152291 0.04416546]
2025-01-23 10:24:48,167 Epoch: [3/20] Iter:[0/294], Time: 0.83, lr: [0.0006911415778422553], Loss: 1.120981, Acc:0.495271, Semantic loss: 0.136505, BCE loss: 0.932869, SB loss: 0.051608
2025-01-23 10:24:58,839 Epoch: [3/20] Iter:[10/294], Time: 1.05, lr: [0.0006898969005845704], Loss: 1.327032, Acc:0.500016, Semantic loss: 0.142987, BCE loss: 1.132584, SB loss: 0.051461
2025-01-23 10:25:09,599 Epoch: [3/20] Iter:[20/294], Time: 1.06, lr: [0.0006886519737673607], Loss: 1.342558, Acc:0.487911, Semantic loss: 0.146935, BCE loss: 1.144390, SB loss: 0.051232
2025-01-23 10:25:20,383 Epoch: [3/20] Iter:[30/294], Time: 1.07, lr: [0.0006874067968391129], Loss: 1.315873, Acc:0.496904, Semantic loss: 0.150383, BCE loss: 1.113138, SB loss: 0.052352
2025-01-23 10:25:30,410 Epoch: [3/20] Iter:[40/294], Time: 1.05, lr: [0.0006861613692459821], Loss: 1.319619, Acc:0.490504, Semantic loss: 0.151424, BCE loss: 1.115412, SB loss: 0.052783
2025-01-23 10:25:41,102 Epoch: [3/20] Iter:[50/294], Time: 1.06, lr: [0.0006849156904317769], Loss: 1.344417, Acc:0.498004, Semantic loss: 0.149999, BCE loss: 1.141961, SB loss: 0.052457
2025-01-23 10:25:51,827 Epoch: [3/20] Iter:[60/294], Time: 1.06, lr: [0.0006836697598379455], Loss: 1.328985, Acc:0.495801, Semantic loss: 0.148666, BCE loss: 1.128365, SB loss: 0.051955
2025-01-23 10:26:02,422 Epoch: [3/20] Iter:[70/294], Time: 1.06, lr: [0.0006824235769035605], Loss: 1.333895, Acc:0.488260, Semantic loss: 0.149596, BCE loss: 1.131835, SB loss: 0.052464
2025-01-23 10:26:13,195 Epoch: [3/20] Iter:[80/294], Time: 1.06, lr: [0.0006811771410653038], Loss: 1.344505, Acc:0.490603, Semantic loss: 0.148167, BCE loss: 1.144134, SB loss: 0.052204
2025-01-23 10:26:24,293 Epoch: [3/20] Iter:[90/294], Time: 1.07, lr: [0.0006799304517574516], Loss: 1.356758, Acc:0.495928, Semantic loss: 0.148207, BCE loss: 1.156767, SB loss: 0.051784
2025-01-23 10:26:34,429 Epoch: [3/20] Iter:[100/294], Time: 1.06, lr: [0.0006786835084118592], Loss: 1.353976, Acc:0.497465, Semantic loss: 0.149041, BCE loss: 1.153273, SB loss: 0.051662
2025-01-23 10:26:45,257 Epoch: [3/20] Iter:[110/294], Time: 1.06, lr: [0.000677436310457946], Loss: 1.368694, Acc:0.495580, Semantic loss: 0.149613, BCE loss: 1.166792, SB loss: 0.052289
2025-01-23 10:26:55,793 Epoch: [3/20] Iter:[120/294], Time: 1.06, lr: [0.0006761888573226798], Loss: 1.383417, Acc:0.496769, Semantic loss: 0.150299, BCE loss: 1.180742, SB loss: 0.052375
2025-01-23 10:27:06,696 Epoch: [3/20] Iter:[130/294], Time: 1.06, lr: [0.000674941148430561], Loss: 1.390114, Acc:0.497637, Semantic loss: 0.150979, BCE loss: 1.186534, SB loss: 0.052601
2025-01-23 10:27:17,463 Epoch: [3/20] Iter:[140/294], Time: 1.07, lr: [0.0006736931832036073], Loss: 1.384217, Acc:0.496397, Semantic loss: 0.150675, BCE loss: 1.181062, SB loss: 0.052479
2025-01-23 10:27:28,575 Epoch: [3/20] Iter:[150/294], Time: 1.07, lr: [0.0006724449610613374], Loss: 1.383567, Acc:0.494027, Semantic loss: 0.151676, BCE loss: 1.178692, SB loss: 0.053200
2025-01-23 10:27:38,686 Epoch: [3/20] Iter:[160/294], Time: 1.06, lr: [0.0006711964814207557], Loss: 1.380380, Acc:0.492627, Semantic loss: 0.151619, BCE loss: 1.175664, SB loss: 0.053097
2025-01-23 10:27:49,309 Epoch: [3/20] Iter:[170/294], Time: 1.06, lr: [0.0006699477436963351], Loss: 1.384400, Acc:0.492780, Semantic loss: 0.152166, BCE loss: 1.178941, SB loss: 0.053294
2025-01-23 10:27:59,817 Epoch: [3/20] Iter:[180/294], Time: 1.06, lr: [0.0006686987473000021], Loss: 1.378495, Acc:0.491325, Semantic loss: 0.151701, BCE loss: 1.173563, SB loss: 0.053231
2025-01-23 10:28:10,378 Epoch: [3/20] Iter:[190/294], Time: 1.06, lr: [0.0006674494916411192], Loss: 1.375818, Acc:0.490316, Semantic loss: 0.151507, BCE loss: 1.170936, SB loss: 0.053375
2025-01-23 10:28:21,004 Epoch: [3/20] Iter:[200/294], Time: 1.06, lr: [0.0006661999761264694], Loss: 1.369120, Acc:0.488432, Semantic loss: 0.151454, BCE loss: 1.164480, SB loss: 0.053187
2025-01-23 10:28:31,035 Epoch: [3/20] Iter:[210/294], Time: 1.06, lr: [0.0006649502001602384], Loss: 1.361206, Acc:0.488923, Semantic loss: 0.151179, BCE loss: 1.157064, SB loss: 0.052963
2025-01-23 10:28:41,585 Epoch: [3/20] Iter:[220/294], Time: 1.06, lr: [0.0006637001631439989], Loss: 1.364153, Acc:0.489254, Semantic loss: 0.151334, BCE loss: 1.159729, SB loss: 0.053090
2025-01-23 10:28:52,183 Epoch: [3/20] Iter:[230/294], Time: 1.06, lr: [0.000662449864476693], Loss: 1.366729, Acc:0.488988, Semantic loss: 0.151052, BCE loss: 1.162533, SB loss: 0.053144
2025-01-23 10:29:03,015 Epoch: [3/20] Iter:[240/294], Time: 1.06, lr: [0.0006611993035546153], Loss: 1.368063, Acc:0.487642, Semantic loss: 0.151140, BCE loss: 1.163780, SB loss: 0.053142
2025-01-23 10:29:13,732 Epoch: [3/20] Iter:[250/294], Time: 1.06, lr: [0.0006599484797713951], Loss: 1.365745, Acc:0.487524, Semantic loss: 0.150791, BCE loss: 1.161811, SB loss: 0.053142
2025-01-23 10:29:24,521 Epoch: [3/20] Iter:[260/294], Time: 1.06, lr: [0.0006586973925179802], Loss: 1.363132, Acc:0.487218, Semantic loss: 0.150427, BCE loss: 1.159585, SB loss: 0.053120
2025-01-23 10:29:35,069 Epoch: [3/20] Iter:[270/294], Time: 1.06, lr: [0.0006574460411826182], Loss: 1.368953, Acc:0.488230, Semantic loss: 0.150197, BCE loss: 1.165845, SB loss: 0.052910
2025-01-23 10:29:45,269 Epoch: [3/20] Iter:[280/294], Time: 1.06, lr: [0.0006561944251508396], Loss: 1.359204, Acc:0.488615, Semantic loss: 0.149977, BCE loss: 1.156372, SB loss: 0.052855
2025-01-23 10:29:56,074 Epoch: [3/20] Iter:[290/294], Time: 1.06, lr: [0.0006549425438054388], Loss: 1.362818, Acc:0.488563, Semantic loss: 0.150224, BCE loss: 1.159823, SB loss: 0.052771
2025-01-23 10:39:21,545 0 [0.         0.45709522 0.20832526 0.12715745 0.26146545 0.06920365
 0.02083578 0.02580248] 0.16712647011701648
2025-01-23 10:39:21,546 1 [0.         0.48363831 0.13325038 0.1711319  0.23324501 0.04624797
 0.01787073 0.04103714] 0.16091734645731953
2025-01-23 10:39:21,547 => saving checkpoint to output/loveDa/pidnet_small_loveda_3b_AUG_CHANCE+AUG1checkpoint.pth.tar
2025-01-23 10:39:21,842 Loss: 1.265, MeanIU:  0.1609, Best_mIoU:  0.2156
2025-01-23 10:39:21,843 [0.         0.48363831 0.13325038 0.1711319  0.23324501 0.04624797
 0.01787073 0.04103714]
2025-01-23 10:39:22,936 Epoch: [4/20] Iter:[0/294], Time: 0.94, lr: [0.0008180521460508585], Loss: 1.407121, Acc:0.525666, Semantic loss: 0.119937, BCE loss: 1.242116, SB loss: 0.045068
2025-01-23 10:39:33,783 Epoch: [4/20] Iter:[10/294], Time: 1.07, lr: [0.0008164868287675814], Loss: 1.241543, Acc:0.490577, Semantic loss: 0.152109, BCE loss: 1.034452, SB loss: 0.054982
2025-01-23 10:39:43,613 Epoch: [4/20] Iter:[20/294], Time: 1.03, lr: [0.0008149211779765766], Loss: 1.336706, Acc:0.491839, Semantic loss: 0.149691, BCE loss: 1.133102, SB loss: 0.053913
2025-01-23 10:39:54,257 Epoch: [4/20] Iter:[30/294], Time: 1.04, lr: [0.0008133551928945428], Loss: 1.334023, Acc:0.491265, Semantic loss: 0.148486, BCE loss: 1.131314, SB loss: 0.054223
2025-01-23 10:40:04,763 Epoch: [4/20] Iter:[40/294], Time: 1.04, lr: [0.0008117888727346593], Loss: 1.318607, Acc:0.490759, Semantic loss: 0.147414, BCE loss: 1.117238, SB loss: 0.053955
2025-01-23 10:40:15,350 Epoch: [4/20] Iter:[50/294], Time: 1.05, lr: [0.0008102222167065622], Loss: 1.317343, Acc:0.490644, Semantic loss: 0.148017, BCE loss: 1.115627, SB loss: 0.053698
2025-01-23 10:40:25,947 Epoch: [4/20] Iter:[60/294], Time: 1.05, lr: [0.0008086552240163209], Loss: 1.331870, Acc:0.496932, Semantic loss: 0.147272, BCE loss: 1.131644, SB loss: 0.052954
2025-01-23 10:40:35,879 Epoch: [4/20] Iter:[70/294], Time: 1.04, lr: [0.0008070878938664143], Loss: 1.327678, Acc:0.485713, Semantic loss: 0.149487, BCE loss: 1.124611, SB loss: 0.053580
2025-01-23 10:40:46,323 Epoch: [4/20] Iter:[80/294], Time: 1.04, lr: [0.0008055202254557068], Loss: 1.328995, Acc:0.490309, Semantic loss: 0.148759, BCE loss: 1.127384, SB loss: 0.052852
2025-01-23 10:40:56,637 Epoch: [4/20] Iter:[90/294], Time: 1.04, lr: [0.0008039522179794238], Loss: 1.331117, Acc:0.491501, Semantic loss: 0.149245, BCE loss: 1.128862, SB loss: 0.053009
2025-01-23 10:41:06,893 Epoch: [4/20] Iter:[100/294], Time: 1.04, lr: [0.0008023838706291279], Loss: 1.341492, Acc:0.495464, Semantic loss: 0.148756, BCE loss: 1.140133, SB loss: 0.052603
2025-01-23 10:41:17,591 Epoch: [4/20] Iter:[110/294], Time: 1.04, lr: [0.0008008151825926932], Loss: 1.336885, Acc:0.494673, Semantic loss: 0.148078, BCE loss: 1.136400, SB loss: 0.052408
2025-01-23 10:41:28,053 Epoch: [4/20] Iter:[120/294], Time: 1.04, lr: [0.0007992461530542817], Loss: 1.341489, Acc:0.493371, Semantic loss: 0.148749, BCE loss: 1.140105, SB loss: 0.052635
2025-01-23 10:41:38,250 Epoch: [4/20] Iter:[130/294], Time: 1.04, lr: [0.000797676781194317], Loss: 1.337535, Acc:0.491830, Semantic loss: 0.149079, BCE loss: 1.135834, SB loss: 0.052622
2025-01-23 10:41:48,829 Epoch: [4/20] Iter:[140/294], Time: 1.04, lr: [0.0007961070661894596], Loss: 1.344426, Acc:0.492878, Semantic loss: 0.148924, BCE loss: 1.142927, SB loss: 0.052574
2025-01-23 10:41:59,422 Epoch: [4/20] Iter:[150/294], Time: 1.04, lr: [0.0007945370072125812], Loss: 1.351527, Acc:0.493596, Semantic loss: 0.148883, BCE loss: 1.150203, SB loss: 0.052440
2025-01-23 10:42:10,064 Epoch: [4/20] Iter:[160/294], Time: 1.04, lr: [0.0007929666034327392], Loss: 1.351227, Acc:0.491254, Semantic loss: 0.149236, BCE loss: 1.149461, SB loss: 0.052531
2025-01-23 10:42:20,630 Epoch: [4/20] Iter:[170/294], Time: 1.04, lr: [0.0007913958540151498], Loss: 1.352830, Acc:0.492578, Semantic loss: 0.148859, BCE loss: 1.151484, SB loss: 0.052486
2025-01-23 10:42:30,748 Epoch: [4/20] Iter:[180/294], Time: 1.04, lr: [0.0007898247581211628], Loss: 1.351459, Acc:0.491243, Semantic loss: 0.148922, BCE loss: 1.149729, SB loss: 0.052808
2025-01-23 10:42:40,723 Epoch: [4/20] Iter:[190/294], Time: 1.04, lr: [0.0007882533149082346], Loss: 1.354927, Acc:0.490351, Semantic loss: 0.149571, BCE loss: 1.152651, SB loss: 0.052705
2025-01-23 10:42:51,275 Epoch: [4/20] Iter:[200/294], Time: 1.04, lr: [0.0007866815235299011], Loss: 1.360173, Acc:0.491392, Semantic loss: 0.149515, BCE loss: 1.157972, SB loss: 0.052686
2025-01-23 10:43:01,449 Epoch: [4/20] Iter:[210/294], Time: 1.04, lr: [0.0007851093831357514], Loss: 1.367004, Acc:0.493278, Semantic loss: 0.149355, BCE loss: 1.165005, SB loss: 0.052643
2025-01-23 10:43:11,902 Epoch: [4/20] Iter:[220/294], Time: 1.04, lr: [0.0007835368928714006], Loss: 1.370971, Acc:0.495359, Semantic loss: 0.149502, BCE loss: 1.168809, SB loss: 0.052660
2025-01-23 10:43:21,839 Epoch: [4/20] Iter:[230/294], Time: 1.04, lr: [0.000781964051878461], Loss: 1.369531, Acc:0.495582, Semantic loss: 0.149068, BCE loss: 1.167965, SB loss: 0.052498
2025-01-23 10:43:32,369 Epoch: [4/20] Iter:[240/294], Time: 1.04, lr: [0.0007803908592945162], Loss: 1.368641, Acc:0.493683, Semantic loss: 0.149790, BCE loss: 1.166192, SB loss: 0.052659
2025-01-23 10:43:42,605 Epoch: [4/20] Iter:[250/294], Time: 1.04, lr: [0.0007788173142530921], Loss: 1.364778, Acc:0.494575, Semantic loss: 0.149516, BCE loss: 1.162704, SB loss: 0.052558
2025-01-23 10:43:53,157 Epoch: [4/20] Iter:[260/294], Time: 1.04, lr: [0.0007772434158836288], Loss: 1.361114, Acc:0.492496, Semantic loss: 0.149733, BCE loss: 1.158904, SB loss: 0.052477
2025-01-23 10:44:03,540 Epoch: [4/20] Iter:[270/294], Time: 1.04, lr: [0.0007756691633114519], Loss: 1.356342, Acc:0.491533, Semantic loss: 0.149249, BCE loss: 1.154715, SB loss: 0.052378
2025-01-23 10:44:13,953 Epoch: [4/20] Iter:[280/294], Time: 1.04, lr: [0.0007740945556577441], Loss: 1.359065, Acc:0.491197, Semantic loss: 0.149724, BCE loss: 1.156747, SB loss: 0.052594
2025-01-23 10:44:23,746 Epoch: [4/20] Iter:[290/294], Time: 1.04, lr: [0.0007725195920395162], Loss: 1.364404, Acc:0.492505, Semantic loss: 0.149470, BCE loss: 1.162402, SB loss: 0.052532
2025-01-23 10:53:43,460 0 [0.         0.36613595 0.25874796 0.12401384 0.05993161 0.11225182
 0.04507759 0.09820661] 0.15205219637188344
2025-01-23 10:53:43,460 1 [0.         0.40164871 0.28914381 0.17367651 0.06948294 0.05164947
 0.02696539 0.20999782] 0.17465209192537628
2025-01-23 10:53:43,461 => saving checkpoint to output/loveDa/pidnet_small_loveda_3b_AUG_CHANCE+AUG1checkpoint.pth.tar
2025-01-23 10:53:43,919 Loss: 1.278, MeanIU:  0.1747, Best_mIoU:  0.2156
2025-01-23 10:53:43,919 [0.         0.40164871 0.28914381 0.17367651 0.06948294 0.05164947
 0.02696539 0.20999782]
2025-01-23 10:53:45,190 Epoch: [5/20] Iter:[0/294], Time: 1.11, lr: [0.0005894321327841773], Loss: 1.401119, Acc:0.511516, Semantic loss: 0.152333, BCE loss: 1.195995, SB loss: 0.052791
2025-01-23 10:53:55,410 Epoch: [5/20] Iter:[10/294], Time: 1.03, lr: [0.0005882290735648814], Loss: 1.340506, Acc:0.498865, Semantic loss: 0.161116, BCE loss: 1.125398, SB loss: 0.053992
2025-01-23 10:54:05,804 Epoch: [5/20] Iter:[20/294], Time: 1.03, lr: [0.0005870257408917153], Loss: 1.434776, Acc:0.481079, Semantic loss: 0.154151, BCE loss: 1.227164, SB loss: 0.053460
2025-01-23 10:54:16,353 Epoch: [5/20] Iter:[30/294], Time: 1.04, lr: [0.000585822134079408], Loss: 1.421990, Acc:0.486637, Semantic loss: 0.150568, BCE loss: 1.218772, SB loss: 0.052650
2025-01-23 10:54:26,832 Epoch: [5/20] Iter:[40/294], Time: 1.04, lr: [0.0005846182524394021], Loss: 1.421379, Acc:0.493750, Semantic loss: 0.148918, BCE loss: 1.219618, SB loss: 0.052843
2025-01-23 10:54:37,576 Epoch: [5/20] Iter:[50/294], Time: 1.05, lr: [0.0005834140952798316], Loss: 1.403713, Acc:0.494855, Semantic loss: 0.148998, BCE loss: 1.201589, SB loss: 0.053126
2025-01-23 10:54:48,028 Epoch: [5/20] Iter:[60/294], Time: 1.05, lr: [0.0005822096619054973], Loss: 1.396237, Acc:0.495728, Semantic loss: 0.150378, BCE loss: 1.192823, SB loss: 0.053036
2025-01-23 10:54:57,670 Epoch: [5/20] Iter:[70/294], Time: 1.04, lr: [0.0005810049516178435], Loss: 1.411495, Acc:0.499736, Semantic loss: 0.149509, BCE loss: 1.209645, SB loss: 0.052341
2025-01-23 10:55:08,055 Epoch: [5/20] Iter:[80/294], Time: 1.04, lr: [0.000579799963714934], Loss: 1.410449, Acc:0.506143, Semantic loss: 0.148962, BCE loss: 1.209257, SB loss: 0.052230
2025-01-23 10:55:18,504 Epoch: [5/20] Iter:[90/294], Time: 1.04, lr: [0.0005785946974914281], Loss: 1.410366, Acc:0.506637, Semantic loss: 0.148816, BCE loss: 1.209578, SB loss: 0.051972
2025-01-23 10:55:28,778 Epoch: [5/20] Iter:[100/294], Time: 1.04, lr: [0.0005773891522385558], Loss: 1.414075, Acc:0.510263, Semantic loss: 0.147802, BCE loss: 1.214425, SB loss: 0.051847
2025-01-23 10:55:39,405 Epoch: [5/20] Iter:[110/294], Time: 1.04, lr: [0.0005761833272440931], Loss: 1.402652, Acc:0.509591, Semantic loss: 0.146675, BCE loss: 1.204335, SB loss: 0.051642
2025-01-23 10:55:49,064 Epoch: [5/20] Iter:[120/294], Time: 1.03, lr: [0.0005749772217923377], Loss: 1.403494, Acc:0.509286, Semantic loss: 0.146330, BCE loss: 1.205451, SB loss: 0.051713
2025-01-23 10:55:59,347 Epoch: [5/20] Iter:[130/294], Time: 1.03, lr: [0.000573770835164083], Loss: 1.394049, Acc:0.510460, Semantic loss: 0.145085, BCE loss: 1.197591, SB loss: 0.051373
2025-01-23 10:56:09,727 Epoch: [5/20] Iter:[140/294], Time: 1.03, lr: [0.0005725641666365935], Loss: 1.386674, Acc:0.509292, Semantic loss: 0.145625, BCE loss: 1.189584, SB loss: 0.051466
2025-01-23 10:56:20,072 Epoch: [5/20] Iter:[150/294], Time: 1.03, lr: [0.0005713572154835789], Loss: 1.372791, Acc:0.506658, Semantic loss: 0.144789, BCE loss: 1.176786, SB loss: 0.051216
2025-01-23 10:56:30,664 Epoch: [5/20] Iter:[160/294], Time: 1.03, lr: [0.0005701499809751676], Loss: 1.365102, Acc:0.506146, Semantic loss: 0.144475, BCE loss: 1.169558, SB loss: 0.051070
2025-01-23 10:56:40,495 Epoch: [5/20] Iter:[170/294], Time: 1.03, lr: [0.0005689424623778817], Loss: 1.369942, Acc:0.508226, Semantic loss: 0.144544, BCE loss: 1.174288, SB loss: 0.051110
2025-01-23 10:56:50,916 Epoch: [5/20] Iter:[180/294], Time: 1.03, lr: [0.0005677346589546099], Loss: 1.361335, Acc:0.509332, Semantic loss: 0.144406, BCE loss: 1.165795, SB loss: 0.051135
2025-01-23 10:57:01,371 Epoch: [5/20] Iter:[190/294], Time: 1.03, lr: [0.000566526569964581], Loss: 1.358380, Acc:0.510674, Semantic loss: 0.144305, BCE loss: 1.162950, SB loss: 0.051125
2025-01-23 10:57:11,977 Epoch: [5/20] Iter:[200/294], Time: 1.03, lr: [0.0005653181946633371], Loss: 1.356852, Acc:0.512361, Semantic loss: 0.144531, BCE loss: 1.161184, SB loss: 0.051138
2025-01-23 10:57:22,282 Epoch: [5/20] Iter:[210/294], Time: 1.03, lr: [0.0005641095323027064], Loss: 1.344134, Acc:0.511874, Semantic loss: 0.144236, BCE loss: 1.148867, SB loss: 0.051031
2025-01-23 10:57:32,689 Epoch: [5/20] Iter:[220/294], Time: 1.03, lr: [0.0005629005821307758], Loss: 1.338118, Acc:0.511339, Semantic loss: 0.144112, BCE loss: 1.143159, SB loss: 0.050847
2025-01-23 10:57:42,827 Epoch: [5/20] Iter:[230/294], Time: 1.03, lr: [0.0005616913433918631], Loss: 1.335235, Acc:0.511958, Semantic loss: 0.143661, BCE loss: 1.140933, SB loss: 0.050641
2025-01-23 10:57:53,396 Epoch: [5/20] Iter:[240/294], Time: 1.03, lr: [0.0005604818153264891], Loss: 1.342221, Acc:0.512310, Semantic loss: 0.143741, BCE loss: 1.147863, SB loss: 0.050617
2025-01-23 10:58:03,685 Epoch: [5/20] Iter:[250/294], Time: 1.03, lr: [0.0005592719971713499], Loss: 1.338300, Acc:0.512272, Semantic loss: 0.143298, BCE loss: 1.144453, SB loss: 0.050549
2025-01-23 10:58:14,236 Epoch: [5/20] Iter:[260/294], Time: 1.04, lr: [0.0005580618881592872], Loss: 1.335592, Acc:0.511675, Semantic loss: 0.142966, BCE loss: 1.142200, SB loss: 0.050426
2025-01-23 10:58:24,829 Epoch: [5/20] Iter:[270/294], Time: 1.04, lr: [0.0005568514875192606], Loss: 1.331041, Acc:0.512291, Semantic loss: 0.142471, BCE loss: 1.138232, SB loss: 0.050338
2025-01-23 10:58:34,453 Epoch: [5/20] Iter:[280/294], Time: 1.03, lr: [0.0005556407944763181], Loss: 1.334134, Acc:0.511386, Semantic loss: 0.142718, BCE loss: 1.141002, SB loss: 0.050414
2025-01-23 10:58:44,517 Epoch: [5/20] Iter:[290/294], Time: 1.03, lr: [0.000554429808251567], Loss: 1.328438, Acc:0.509230, Semantic loss: 0.142344, BCE loss: 1.135746, SB loss: 0.050348
2025-01-23 11:08:03,636 0 [0.         0.3988059  0.33803171 0.18163705 0.20345273 0.00828926
 0.07151931 0.00563373] 0.1724813847690744
2025-01-23 11:08:03,637 1 [0.         0.44452418 0.30841382 0.15655298 0.22803444 0.01332773
 0.01679315 0.01122061] 0.16840955919351597
2025-01-23 11:08:03,638 => saving checkpoint to output/loveDa/pidnet_small_loveda_3b_AUG_CHANCE+AUG1checkpoint.pth.tar
2025-01-23 11:08:03,938 Loss: 1.268, MeanIU:  0.1684, Best_mIoU:  0.2156
2025-01-23 11:08:03,939 [0.         0.44452418 0.30841382 0.15655298 0.22803444 0.01332773
 0.01679315 0.01122061]
2025-01-23 11:08:04,968 Epoch: [6/20] Iter:[0/294], Time: 0.87, lr: [0.00038882720645376935], Loss: 1.665725, Acc:0.643090, Semantic loss: 0.146549, BCE loss: 1.471258, SB loss: 0.047919
2025-01-23 11:08:15,274 Epoch: [6/20] Iter:[10/294], Time: 1.02, lr: [0.0003879768978191985], Loss: 1.368130, Acc:0.484108, Semantic loss: 0.142320, BCE loss: 1.174092, SB loss: 0.051718
2025-01-23 11:08:25,809 Epoch: [6/20] Iter:[20/294], Time: 1.03, lr: [0.00038712638206990025], Loss: 1.312014, Acc:0.498039, Semantic loss: 0.137319, BCE loss: 1.125060, SB loss: 0.049635
2025-01-23 11:08:36,052 Epoch: [6/20] Iter:[30/294], Time: 1.03, lr: [0.00038627565864958924], Loss: 1.316372, Acc:0.513995, Semantic loss: 0.136906, BCE loss: 1.130477, SB loss: 0.048990
2025-01-23 11:08:46,644 Epoch: [6/20] Iter:[40/294], Time: 1.04, lr: [0.000385424726999121], Loss: 1.291041, Acc:0.509444, Semantic loss: 0.135201, BCE loss: 1.107266, SB loss: 0.048574
2025-01-23 11:08:56,514 Epoch: [6/20] Iter:[50/294], Time: 1.03, lr: [0.00038457358655646955], Loss: 1.281855, Acc:0.507703, Semantic loss: 0.135491, BCE loss: 1.097930, SB loss: 0.048434
2025-01-23 11:09:06,821 Epoch: [6/20] Iter:[60/294], Time: 1.03, lr: [0.0003837222367567059], Loss: 1.322455, Acc:0.513132, Semantic loss: 0.136080, BCE loss: 1.137571, SB loss: 0.048805
2025-01-23 11:09:17,159 Epoch: [6/20] Iter:[70/294], Time: 1.03, lr: [0.0003828706770319759], Loss: 1.313133, Acc:0.514487, Semantic loss: 0.135548, BCE loss: 1.128849, SB loss: 0.048737
2025-01-23 11:09:27,201 Epoch: [6/20] Iter:[80/294], Time: 1.03, lr: [0.0003820189068114775], Loss: 1.295513, Acc:0.508374, Semantic loss: 0.136402, BCE loss: 1.110201, SB loss: 0.048910
2025-01-23 11:09:37,373 Epoch: [6/20] Iter:[90/294], Time: 1.03, lr: [0.0003811669255214385], Loss: 1.296589, Acc:0.507910, Semantic loss: 0.136421, BCE loss: 1.111410, SB loss: 0.048759
2025-01-23 11:09:47,376 Epoch: [6/20] Iter:[100/294], Time: 1.02, lr: [0.00038031473258509326], Loss: 1.305286, Acc:0.512056, Semantic loss: 0.135604, BCE loss: 1.121199, SB loss: 0.048483
2025-01-23 11:09:57,520 Epoch: [6/20] Iter:[110/294], Time: 1.02, lr: [0.00037946232742265996], Loss: 1.306784, Acc:0.517509, Semantic loss: 0.135141, BCE loss: 1.123316, SB loss: 0.048327
2025-01-23 11:10:07,874 Epoch: [6/20] Iter:[120/294], Time: 1.02, lr: [0.00037860970945131694], Loss: 1.292996, Acc:0.515560, Semantic loss: 0.134630, BCE loss: 1.110250, SB loss: 0.048116
2025-01-23 11:10:18,195 Epoch: [6/20] Iter:[130/294], Time: 1.02, lr: [0.00037775687808517947], Loss: 1.291632, Acc:0.514819, Semantic loss: 0.135372, BCE loss: 1.107657, SB loss: 0.048603
2025-01-23 11:10:28,798 Epoch: [6/20] Iter:[140/294], Time: 1.03, lr: [0.0003769038327352756], Loss: 1.285051, Acc:0.516810, Semantic loss: 0.134755, BCE loss: 1.101855, SB loss: 0.048441
2025-01-23 11:10:38,829 Epoch: [6/20] Iter:[150/294], Time: 1.02, lr: [0.0003760505728095221], Loss: 1.285537, Acc:0.518593, Semantic loss: 0.134934, BCE loss: 1.102228, SB loss: 0.048375
2025-01-23 11:10:48,678 Epoch: [6/20] Iter:[160/294], Time: 1.02, lr: [0.00037519709771270047], Loss: 1.287384, Acc:0.520405, Semantic loss: 0.134298, BCE loss: 1.104887, SB loss: 0.048199
2025-01-23 11:10:59,241 Epoch: [6/20] Iter:[170/294], Time: 1.02, lr: [0.00037434340684643216], Loss: 1.285513, Acc:0.520112, Semantic loss: 0.134261, BCE loss: 1.102948, SB loss: 0.048304
2025-01-23 11:11:09,847 Epoch: [6/20] Iter:[180/294], Time: 1.03, lr: [0.00037348949960915343], Loss: 1.289495, Acc:0.521506, Semantic loss: 0.134032, BCE loss: 1.107314, SB loss: 0.048148
2025-01-23 11:11:20,427 Epoch: [6/20] Iter:[190/294], Time: 1.03, lr: [0.00037263537539609085], Loss: 1.287560, Acc:0.520877, Semantic loss: 0.134243, BCE loss: 1.104970, SB loss: 0.048347
2025-01-23 11:11:31,109 Epoch: [6/20] Iter:[200/294], Time: 1.03, lr: [0.0003717810335992355], Loss: 1.292865, Acc:0.521782, Semantic loss: 0.134603, BCE loss: 1.109927, SB loss: 0.048335
2025-01-23 11:11:40,772 Epoch: [6/20] Iter:[210/294], Time: 1.03, lr: [0.0003709264736073178], Loss: 1.297745, Acc:0.521438, Semantic loss: 0.134373, BCE loss: 1.115032, SB loss: 0.048340
2025-01-23 11:11:51,084 Epoch: [6/20] Iter:[220/294], Time: 1.03, lr: [0.00037007169480578076], Loss: 1.302272, Acc:0.523806, Semantic loss: 0.134520, BCE loss: 1.119471, SB loss: 0.048281
2025-01-23 11:12:01,409 Epoch: [6/20] Iter:[230/294], Time: 1.03, lr: [0.000369216696576755], Loss: 1.302578, Acc:0.522150, Semantic loss: 0.135326, BCE loss: 1.118645, SB loss: 0.048607
2025-01-23 11:12:11,815 Epoch: [6/20] Iter:[240/294], Time: 1.03, lr: [0.00036836147829903156], Loss: 1.299076, Acc:0.522114, Semantic loss: 0.135290, BCE loss: 1.115159, SB loss: 0.048627
2025-01-23 11:12:22,327 Epoch: [6/20] Iter:[250/294], Time: 1.03, lr: [0.0003675060393480351], Loss: 1.309665, Acc:0.523177, Semantic loss: 0.135849, BCE loss: 1.125171, SB loss: 0.048646
2025-01-23 11:12:32,098 Epoch: [6/20] Iter:[260/294], Time: 1.03, lr: [0.0003666503790957974], Loss: 1.313047, Acc:0.523106, Semantic loss: 0.135890, BCE loss: 1.128492, SB loss: 0.048665
2025-01-23 11:12:42,284 Epoch: [6/20] Iter:[270/294], Time: 1.03, lr: [0.00036579449691092974], Loss: 1.310978, Acc:0.523177, Semantic loss: 0.135544, BCE loss: 1.126787, SB loss: 0.048646
2025-01-23 11:12:52,601 Epoch: [6/20] Iter:[280/294], Time: 1.03, lr: [0.0003649383921585956], Loss: 1.312164, Acc:0.524409, Semantic loss: 0.135307, BCE loss: 1.128263, SB loss: 0.048593
2025-01-23 11:13:02,820 Epoch: [6/20] Iter:[290/294], Time: 1.03, lr: [0.0003640820642004823], Loss: 1.307570, Acc:0.523316, Semantic loss: 0.135733, BCE loss: 1.123014, SB loss: 0.048823
2025-01-23 11:22:19,972 0 [0.         0.37349643 0.27261801 0.15394181 0.19675468 0.15609843
 0.07395698 0.06247244] 0.1841912536034975
2025-01-23 11:22:19,973 1 [0.         0.38952756 0.20838419 0.22123486 0.20164982 0.0855012
 0.0497426  0.23616949] 0.19888710145844188
2025-01-23 11:22:19,974 => saving checkpoint to output/loveDa/pidnet_small_loveda_3b_AUG_CHANCE+AUG1checkpoint.pth.tar
2025-01-23 11:22:20,272 Loss: 1.281, MeanIU:  0.1989, Best_mIoU:  0.2156
2025-01-23 11:22:20,273 [0.         0.38952756 0.20838419 0.22123486 0.20164982 0.0855012
 0.0497426  0.23616949]
2025-01-23 11:22:21,354 Epoch: [7/20] Iter:[0/294], Time: 0.92, lr: [0.00023344659090771683], Loss: 1.646663, Acc:0.573976, Semantic loss: 0.133714, BCE loss: 1.465422, SB loss: 0.047528
2025-01-23 11:22:31,724 Epoch: [7/20] Iter:[10/294], Time: 1.03, lr: [0.0002328968016767269], Loss: 1.292138, Acc:0.539770, Semantic loss: 0.129274, BCE loss: 1.115239, SB loss: 0.047626
2025-01-23 11:22:42,240 Epoch: [7/20] Iter:[20/294], Time: 1.04, lr: [0.00023234686820071786], Loss: 1.385525, Acc:0.544383, Semantic loss: 0.133068, BCE loss: 1.204253, SB loss: 0.048204
2025-01-23 11:22:52,568 Epoch: [7/20] Iter:[30/294], Time: 1.04, lr: [0.00023179679006230227], Loss: 1.381974, Acc:0.545559, Semantic loss: 0.136403, BCE loss: 1.195565, SB loss: 0.050006
2025-01-23 11:23:02,723 Epoch: [7/20] Iter:[40/294], Time: 1.03, lr: [0.00023124656684178074], Loss: 1.364050, Acc:0.544744, Semantic loss: 0.135420, BCE loss: 1.179001, SB loss: 0.049629
2025-01-23 11:23:13,158 Epoch: [7/20] Iter:[50/294], Time: 1.03, lr: [0.00023069619811712312], Loss: 1.334415, Acc:0.539903, Semantic loss: 0.134441, BCE loss: 1.151300, SB loss: 0.048673
2025-01-23 11:23:24,010 Epoch: [7/20] Iter:[60/294], Time: 1.04, lr: [0.00023014568346394932], Loss: 1.329595, Acc:0.542733, Semantic loss: 0.134204, BCE loss: 1.146767, SB loss: 0.048623
2025-01-23 11:23:34,804 Epoch: [7/20] Iter:[70/294], Time: 1.05, lr: [0.00022959502245551022], Loss: 1.328879, Acc:0.540542, Semantic loss: 0.135837, BCE loss: 1.144208, SB loss: 0.048834
2025-01-23 11:23:45,438 Epoch: [7/20] Iter:[80/294], Time: 1.05, lr: [0.00022904421466266758], Loss: 1.318328, Acc:0.539744, Semantic loss: 0.135889, BCE loss: 1.134125, SB loss: 0.048313
2025-01-23 11:23:55,562 Epoch: [7/20] Iter:[90/294], Time: 1.05, lr: [0.00022849325965387465], Loss: 1.314589, Acc:0.541396, Semantic loss: 0.135077, BCE loss: 1.131373, SB loss: 0.048138
2025-01-23 11:24:05,430 Epoch: [7/20] Iter:[100/294], Time: 1.04, lr: [0.000227942156995156], Loss: 1.315471, Acc:0.540272, Semantic loss: 0.135352, BCE loss: 1.131943, SB loss: 0.048176
2025-01-23 11:24:15,829 Epoch: [7/20] Iter:[110/294], Time: 1.04, lr: [0.00022739090625008724], Loss: 1.315966, Acc:0.540416, Semantic loss: 0.135479, BCE loss: 1.132283, SB loss: 0.048204
2025-01-23 11:24:26,399 Epoch: [7/20] Iter:[120/294], Time: 1.04, lr: [0.00022683950697977484], Loss: 1.316742, Acc:0.538807, Semantic loss: 0.135537, BCE loss: 1.132926, SB loss: 0.048280
2025-01-23 11:24:36,648 Epoch: [7/20] Iter:[130/294], Time: 1.04, lr: [0.00022628795874283513], Loss: 1.306866, Acc:0.537019, Semantic loss: 0.135377, BCE loss: 1.123127, SB loss: 0.048362
2025-01-23 11:24:47,059 Epoch: [7/20] Iter:[140/294], Time: 1.04, lr: [0.0002257362610953734], Loss: 1.316289, Acc:0.539858, Semantic loss: 0.135739, BCE loss: 1.132173, SB loss: 0.048377
2025-01-23 11:24:56,902 Epoch: [7/20] Iter:[150/294], Time: 1.04, lr: [0.0002251844135909631], Loss: 1.309716, Acc:0.540382, Semantic loss: 0.135557, BCE loss: 1.125899, SB loss: 0.048261
2025-01-23 11:25:07,385 Epoch: [7/20] Iter:[160/294], Time: 1.04, lr: [0.00022463241578062407], Loss: 1.304377, Acc:0.540502, Semantic loss: 0.135000, BCE loss: 1.121219, SB loss: 0.048157
2025-01-23 11:25:17,831 Epoch: [7/20] Iter:[170/294], Time: 1.04, lr: [0.00022408026721280113], Loss: 1.290760, Acc:0.539360, Semantic loss: 0.134716, BCE loss: 1.107956, SB loss: 0.048088
2025-01-23 11:25:28,115 Epoch: [7/20] Iter:[180/294], Time: 1.04, lr: [0.00022352796743334213], Loss: 1.292425, Acc:0.541179, Semantic loss: 0.134478, BCE loss: 1.109953, SB loss: 0.047995
2025-01-23 11:25:38,618 Epoch: [7/20] Iter:[190/294], Time: 1.04, lr: [0.00022297551598547596], Loss: 1.301877, Acc:0.542030, Semantic loss: 0.134619, BCE loss: 1.119132, SB loss: 0.048127
2025-01-23 11:25:48,588 Epoch: [7/20] Iter:[200/294], Time: 1.04, lr: [0.00022242291240979003], Loss: 1.293135, Acc:0.541679, Semantic loss: 0.134336, BCE loss: 1.110728, SB loss: 0.048070
2025-01-23 11:25:59,044 Epoch: [7/20] Iter:[210/294], Time: 1.04, lr: [0.00022187015624420788], Loss: 1.293438, Acc:0.540855, Semantic loss: 0.134181, BCE loss: 1.111208, SB loss: 0.048050
2025-01-23 11:26:09,288 Epoch: [7/20] Iter:[220/294], Time: 1.04, lr: [0.0002213172470239659], Loss: 1.295351, Acc:0.540858, Semantic loss: 0.133825, BCE loss: 1.113471, SB loss: 0.048054
2025-01-23 11:26:19,846 Epoch: [7/20] Iter:[230/294], Time: 1.04, lr: [0.00022076418428159083], Loss: 1.297192, Acc:0.540719, Semantic loss: 0.134213, BCE loss: 1.114840, SB loss: 0.048140
2025-01-23 11:26:30,049 Epoch: [7/20] Iter:[240/294], Time: 1.04, lr: [0.00022021096754687577], Loss: 1.291379, Acc:0.540312, Semantic loss: 0.133985, BCE loss: 1.109273, SB loss: 0.048121
2025-01-23 11:26:40,409 Epoch: [7/20] Iter:[250/294], Time: 1.04, lr: [0.00021965759634685685], Loss: 1.290390, Acc:0.539394, Semantic loss: 0.133798, BCE loss: 1.108472, SB loss: 0.048120
2025-01-23 11:26:49,966 Epoch: [7/20] Iter:[260/294], Time: 1.03, lr: [0.00021910407020578923], Loss: 1.290884, Acc:0.540706, Semantic loss: 0.133259, BCE loss: 1.109601, SB loss: 0.048023
2025-01-23 11:27:00,101 Epoch: [7/20] Iter:[270/294], Time: 1.03, lr: [0.00021855038864512284], Loss: 1.288646, Acc:0.541369, Semantic loss: 0.133257, BCE loss: 1.107426, SB loss: 0.047964
2025-01-23 11:27:10,516 Epoch: [7/20] Iter:[280/294], Time: 1.03, lr: [0.00021799655118347796], Loss: 1.292064, Acc:0.542621, Semantic loss: 0.133192, BCE loss: 1.110961, SB loss: 0.047911
2025-01-23 11:27:20,986 Epoch: [7/20] Iter:[290/294], Time: 1.03, lr: [0.0002174425573366204], Loss: 1.290718, Acc:0.543558, Semantic loss: 0.132818, BCE loss: 1.110105, SB loss: 0.047794
2025-01-23 11:36:37,690 0 [0.         0.41221494 0.35179808 0.13892419 0.23682726 0.14376981
 0.04169893 0.04937954] 0.19637324909533635
2025-01-23 11:36:37,691 1 [0.         0.44707687 0.25619245 0.19999154 0.26337343 0.12215278
 0.02425794 0.29300612] 0.22943587686529957
2025-01-23 11:36:37,692 => saving checkpoint to output/loveDa/pidnet_small_loveda_3b_AUG_CHANCE+AUG1checkpoint.pth.tar
2025-01-23 11:36:38,092 Loss: 1.259, MeanIU:  0.2294, Best_mIoU:  0.2294
2025-01-23 11:36:38,093 [0.         0.44707687 0.25619245 0.19999154 0.26337343 0.12215278
 0.02425794 0.29300612]
2025-01-23 11:36:39,137 Epoch: [8/20] Iter:[0/294], Time: 0.88, lr: [0.00012663789925380445], Loss: 1.092104, Acc:0.455234, Semantic loss: 0.175679, BCE loss: 0.865082, SB loss: 0.051343
2025-01-23 11:36:49,201 Epoch: [8/20] Iter:[10/294], Time: 1.00, lr: [0.0001263147975561446], Loss: 1.318732, Acc:0.533465, Semantic loss: 0.128817, BCE loss: 1.145577, SB loss: 0.044337
2025-01-23 11:36:58,862 Epoch: [8/20] Iter:[20/294], Time: 0.98, lr: [0.00012599160400286215], Loss: 1.268078, Acc:0.543879, Semantic loss: 0.126838, BCE loss: 1.095852, SB loss: 0.045388
2025-01-23 11:37:09,061 Epoch: [8/20] Iter:[30/294], Time: 0.99, lr: [0.0001256683183058846], Loss: 1.263560, Acc:0.546337, Semantic loss: 0.129093, BCE loss: 1.088253, SB loss: 0.046214
2025-01-23 11:37:19,500 Epoch: [8/20] Iter:[40/294], Time: 1.01, lr: [0.0001253449401754096], Loss: 1.261640, Acc:0.548653, Semantic loss: 0.127870, BCE loss: 1.087686, SB loss: 0.046085
2025-01-23 11:37:30,074 Epoch: [8/20] Iter:[50/294], Time: 1.02, lr: [0.00012502146931988987], Loss: 1.281948, Acc:0.554661, Semantic loss: 0.128598, BCE loss: 1.106607, SB loss: 0.046742
2025-01-23 11:37:40,438 Epoch: [8/20] Iter:[60/294], Time: 1.02, lr: [0.00012469790544601748], Loss: 1.270686, Acc:0.556531, Semantic loss: 0.127636, BCE loss: 1.096511, SB loss: 0.046538
