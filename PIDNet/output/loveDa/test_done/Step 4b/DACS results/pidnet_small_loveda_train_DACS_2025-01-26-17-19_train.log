2025-01-26 17:19:59,321 Namespace(cfg='configs/loveda/pidnet_small_loveda_train_DACS.yaml', seed=304, opts=['GPUS', '[0]', 'TRAIN.BATCH_SIZE_PER_GPU', '6'])
2025-01-26 17:19:59,321 AUTO_RESUME: False
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  DATASET: loveDa
  EXTRA_TRAIN_SET: 
  NUM_CLASSES: 8
  ROOT: data/
  SOURCE_DATASET: loveDa
  SOURCE_TEST_SET: list/loveDA-Urban/val.lst
  SOURCE_TRAIN_SET: list/loveDA-Urban/train.lst
  TARGET_DATASET: loveDa
  TARGET_SET: list/loveDa/val.lst
  TARGET_TEST_SET: list/loveDa-Rural/val.lst
  TARGET_TRAIN_SET: list/loveDa-Rural/train.lst
  TEST_SET: list/loveDa/val.lst
  TRAIN_SET: list/loveDa/train.lst
GPUS: (0,)
LOG_DIR: log
LOSS:
  BALANCE_WEIGHTS: [0.4, 1.0]
  CLASS_BALANCE: False
  OHEMKEEP: 131072
  OHEMTHRES: 0.7
  SB_WEIGHTS: 0.5
  USE_DICE: False
  USE_FOCAL: False
  USE_OHEM: True
MODEL:
  ALIGN_CORNERS: True
  NAME: pidnet_small
  NUM_OUTPUTS: 2
  PRETRAINED: pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar
OUTPUT_DIR: output
PIN_MEMORY: True
PRINT_FREQ: 10
TEST:
  BASE_SIZE: 1024
  BATCH_SIZE_PER_GPU: 6
  FLIP_TEST: False
  IMAGE_SIZE: [1024, 1024]
  MODEL_FILE: 
  MULTI_SCALE: False
  OUTPUT_INDEX: 1
TRAIN:
  ADVERSARIAL: False
  AUG: True
  AUG1: False
  AUG2: True
  AUG3: True
  AUG4: False
  AUG_CHANCE: True
  BASE_SIZE: 720
  BATCH_SIZE_PER_GPU: 6
  BEGIN_EPOCH: 0
  D1: False
  END_EPOCH: 20
  EVAL_INTERVAL: 1
  EXTRA_EPOCH: 0
  EXTRA_LR: 0.001
  FLIP: True
  GAN: Vanilla
  IGNORE_LABEL: 0
  IMAGE_SIZE: [720, 720]
  LAMBDA_ADV1: 0.001
  LAMBDA_ADV2: 0.001
  LR: 0.001
  LR_D1: 0.001
  LR_D2: 0.001
  MOMENTUM: 0.9
  MULTI_SCALE: True
  NESTEROV: False
  OPTIMIZER: adam
  RESUME: True
  SCALE_FACTOR: 16
  SCHEDULER: True
  SHUFFLE: True
  WD: 0.0005
WORKERS: 0
2025-01-26 17:19:59,922 Attention!!!
2025-01-26 17:19:59,922 Loaded 302 parameters!
2025-01-26 17:19:59,922 Over!!!
2025-01-26 17:20:00,847 => loaded checkpoint (epoch 14)
2025-01-26 17:20:01,031 Attention!!!
2025-01-26 17:20:01,031 Loaded 302 parameters!
2025-01-26 17:20:01,031 Over!!!
2025-01-26 17:20:10,865 Epoch: [14/20] Iter:[0/289], Time: 5.47, lr: [2.837156369129285e-07], Loss: 2.096502, Acc:0.839346, Source Loss: 1.617260, Target Loss: 1.026067, MixUp Loss: 0.958483
2025-01-26 17:20:31,063 Epoch: [14/20] Iter:[10/289], Time: 2.71, lr: [2.8224263888517077e-07], Loss: 1.742656, Acc:0.760539, Source Loss: 1.200331, Target Loss: 1.032134, MixUp Loss: 1.071409
2025-01-26 17:20:51,335 Epoch: [14/20] Iter:[20/289], Time: 2.39, lr: [2.807687861973248e-07], Loss: 1.702421, Acc:0.740445, Source Loss: 1.158273, Target Loss: 1.065926, MixUp Loss: 1.392080
2025-01-26 17:21:11,513 Epoch: [14/20] Iter:[30/289], Time: 2.27, lr: [2.792940733627451e-07], Loss: 1.742793, Acc:0.763935, Source Loss: 1.220524, Target Loss: 1.049513, MixUp Loss: 1.017152
2025-01-26 17:21:31,313 Epoch: [14/20] Iter:[40/289], Time: 2.20, lr: [2.778184948271482e-07], Loss: 1.772907, Acc:0.761273, Source Loss: 1.247535, Target Loss: 1.065496, MixUp Loss: 0.806817
2025-01-26 17:21:51,873 Epoch: [14/20] Iter:[50/289], Time: 2.17, lr: [2.76342044967374e-07], Loss: 1.814168, Acc:0.764682, Source Loss: 1.279132, Target Loss: 1.063433, MixUp Loss: 1.152772
2025-01-26 17:22:11,656 Epoch: [14/20] Iter:[60/289], Time: 2.14, lr: [2.748647180901181e-07], Loss: 1.792017, Acc:0.762403, Source Loss: 1.260865, Target Loss: 1.061844, MixUp Loss: 0.860815
2025-01-26 17:22:32,310 Epoch: [14/20] Iter:[70/289], Time: 2.13, lr: [2.733865084306322e-07], Loss: 1.798967, Acc:0.765804, Source Loss: 1.268921, Target Loss: 1.068119, MixUp Loss: 0.854863
2025-01-26 17:22:52,622 Epoch: [14/20] Iter:[80/289], Time: 2.12, lr: [2.719074101513925e-07], Loss: 1.806514, Acc:0.769072, Source Loss: 1.277094, Target Loss: 1.069401, MixUp Loss: 0.895879
2025-01-26 17:23:12,435 Epoch: [14/20] Iter:[90/289], Time: 2.10, lr: [2.7042741734073533e-07], Loss: 1.799277, Acc:0.771802, Source Loss: 1.270118, Target Loss: 1.082816, MixUp Loss: 0.822151
2025-01-26 17:23:32,895 Epoch: [14/20] Iter:[100/289], Time: 2.10, lr: [2.6894652401145874e-07], Loss: 1.802254, Acc:0.772672, Source Loss: 1.272582, Target Loss: 1.086972, MixUp Loss: 1.391921
2025-01-26 17:23:52,754 Epoch: [14/20] Iter:[110/289], Time: 2.09, lr: [2.67464724099389e-07], Loss: 1.812358, Acc:0.778136, Source Loss: 1.277851, Target Loss: 1.085119, MixUp Loss: 1.575464
2025-01-26 17:24:13,341 Epoch: [14/20] Iter:[120/289], Time: 2.08, lr: [2.6598201146191083e-07], Loss: 1.806291, Acc:0.778570, Source Loss: 1.273062, Target Loss: 1.083950, MixUp Loss: 1.082562
2025-01-26 17:24:33,704 Epoch: [14/20] Iter:[130/289], Time: 2.08, lr: [2.6449837987646005e-07], Loss: 1.791492, Acc:0.777700, Source Loss: 1.261209, Target Loss: 1.087969, MixUp Loss: 0.849866
2025-01-26 17:24:53,721 Epoch: [14/20] Iter:[140/289], Time: 2.07, lr: [2.6301382303897783e-07], Loss: 1.796790, Acc:0.779767, Source Loss: 1.266554, Target Loss: 1.087493, MixUp Loss: 0.671819
2025-01-26 17:25:14,181 Epoch: [14/20] Iter:[150/289], Time: 2.07, lr: [2.615283345623259e-07], Loss: 1.796122, Acc:0.777184, Source Loss: 1.269537, Target Loss: 1.076607, MixUp Loss: 0.595976
2025-01-26 17:25:34,216 Epoch: [14/20] Iter:[160/289], Time: 2.07, lr: [2.600419079746593e-07], Loss: 1.795162, Acc:0.779194, Source Loss: 1.270268, Target Loss: 1.083561, MixUp Loss: 1.297269
2025-01-26 17:25:54,615 Epoch: [14/20] Iter:[170/289], Time: 2.07, lr: [2.5855453671775813e-07], Loss: 1.777408, Acc:0.778474, Source Loss: 1.256926, Target Loss: 1.081872, MixUp Loss: 0.873318
2025-01-26 17:26:14,677 Epoch: [14/20] Iter:[180/289], Time: 2.06, lr: [2.5706621414531437e-07], Loss: 1.783406, Acc:0.778163, Source Loss: 1.261117, Target Loss: 1.086196, MixUp Loss: 1.009028
2025-01-26 17:26:34,831 Epoch: [14/20] Iter:[190/289], Time: 2.06, lr: [2.555769335211743e-07], Loss: 1.783647, Acc:0.776365, Source Loss: 1.262158, Target Loss: 1.082608, MixUp Loss: 0.729105
2025-01-26 17:26:55,503 Epoch: [14/20] Iter:[200/289], Time: 2.06, lr: [2.5408668801753424e-07], Loss: 1.777043, Acc:0.774093, Source Loss: 1.255912, Target Loss: 1.085340, MixUp Loss: 1.103012
2025-01-26 17:27:15,404 Epoch: [14/20] Iter:[210/289], Time: 2.06, lr: [2.525954707130874e-07], Loss: 1.771503, Acc:0.774191, Source Loss: 1.251778, Target Loss: 1.084653, MixUp Loss: 0.666349
2025-01-26 17:27:36,224 Epoch: [14/20] Iter:[220/289], Time: 2.06, lr: [2.511032745911211e-07], Loss: 1.773088, Acc:0.778439, Source Loss: 1.252691, Target Loss: 1.087063, MixUp Loss: 1.267246
2025-01-26 17:27:56,696 Epoch: [14/20] Iter:[230/289], Time: 2.06, lr: [2.4961009253756315e-07], Loss: 1.768602, Acc:0.777596, Source Loss: 1.248903, Target Loss: 1.086971, MixUp Loss: 1.004639
2025-01-26 17:28:16,932 Epoch: [14/20] Iter:[240/289], Time: 2.06, lr: [2.481159173389739e-07], Loss: 1.775808, Acc:0.781564, Source Loss: 1.255989, Target Loss: 1.085181, MixUp Loss: 1.070037
2025-01-26 17:28:37,531 Epoch: [14/20] Iter:[250/289], Time: 2.06, lr: [2.46620741680484e-07], Loss: 1.770706, Acc:0.779141, Source Loss: 1.252059, Target Loss: 1.080663, MixUp Loss: 0.854006
2025-01-26 17:28:57,688 Epoch: [14/20] Iter:[260/289], Time: 2.06, lr: [2.451245581436742e-07], Loss: 1.772144, Acc:0.778568, Source Loss: 1.250971, Target Loss: 1.085910, MixUp Loss: 1.018987
2025-01-26 17:29:18,471 Epoch: [14/20] Iter:[270/289], Time: 2.06, lr: [2.4362735920439754e-07], Loss: 1.776637, Acc:0.778322, Source Loss: 1.253728, Target Loss: 1.086877, MixUp Loss: 0.656706
2025-01-26 17:29:39,187 Epoch: [14/20] Iter:[280/289], Time: 2.06, lr: [2.421291372305394e-07], Loss: 1.771914, Acc:0.778155, Source Loss: 1.249981, Target Loss: 1.086487, MixUp Loss: 0.950351
2025-01-26 17:35:51,489 0 [0.         0.4804159  0.25002366 0.11264912 0.3890166  0.13178708
 0.10301464 0.07086604] 0.1922216296594605
2025-01-26 17:35:51,490 1 [0.         0.54406013 0.22982188 0.26875607 0.46562773 0.11309827
 0.10679429 0.35044755] 0.25982573917423757
2025-01-26 17:35:51,492 Epoch 15/20 - Source Loss: 1.2558, Target Loss: 1.0844
2025-01-26 17:35:51,492 => saving checkpoint to output/loveDa/pidnet_small_loveda_train_DACScheckpoint.pth.tar
2025-01-26 17:35:51,848 Epoch [14], Loss: 1.778, MeanIoU: 0.2598, best_mIoU: 0.2918
2025-01-26 17:35:51,849 IoU per class: [0.         0.54406013 0.22982188 0.26875607 0.46562773 0.11309827
 0.10679429 0.35044755]
2025-01-26 17:35:52,120 Attention!!!
2025-01-26 17:35:52,120 Loaded 302 parameters!
2025-01-26 17:35:52,121 Over!!!
2025-01-26 17:35:54,879 Epoch: [15/20] Iter:[0/289], Time: 2.66, lr: [7.630787511148683e-08], Loss: 2.331214, Acc:0.794483, Source Loss: 1.876832, Target Loss: 0.915947, MixUp Loss: 0.908763
2025-01-26 17:36:14,811 Epoch: [15/20] Iter:[10/289], Time: 2.05, lr: [7.583243627537236e-08], Loss: 1.758848, Acc:0.768321, Source Loss: 1.267619, Target Loss: 1.017781, MixUp Loss: 1.295825
2025-01-26 17:36:35,368 Epoch: [15/20] Iter:[20/289], Time: 2.05, lr: [7.535666600471014e-08], Loss: 1.726665, Acc:0.775862, Source Loss: 1.232102, Target Loss: 1.054368, MixUp Loss: 1.173113
2025-01-26 17:36:55,361 Epoch: [15/20] Iter:[30/289], Time: 2.04, lr: [7.48805617401182e-08], Loss: 1.759619, Acc:0.783004, Source Loss: 1.248327, Target Loss: 1.037327, MixUp Loss: 0.999242
2025-01-26 17:37:16,015 Epoch: [15/20] Iter:[40/289], Time: 2.04, lr: [7.440412088421652e-08], Loss: 1.764632, Acc:0.784781, Source Loss: 1.256638, Target Loss: 1.031191, MixUp Loss: 1.204343
2025-01-26 17:37:36,477 Epoch: [15/20] Iter:[50/289], Time: 2.04, lr: [7.392734080078827e-08], Loss: 1.763706, Acc:0.784147, Source Loss: 1.252586, Target Loss: 1.035956, MixUp Loss: 0.725267
2025-01-26 17:37:56,563 Epoch: [15/20] Iter:[60/289], Time: 2.04, lr: [7.345021881391636e-08], Loss: 1.789153, Acc:0.779937, Source Loss: 1.272171, Target Loss: 1.040260, MixUp Loss: 1.409108
2025-01-26 17:38:17,310 Epoch: [15/20] Iter:[70/289], Time: 2.04, lr: [7.297275220709461e-08], Loss: 1.791991, Acc:0.779696, Source Loss: 1.275958, Target Loss: 1.042045, MixUp Loss: 1.096527
2025-01-26 17:38:37,272 Epoch: [15/20] Iter:[80/289], Time: 2.04, lr: [7.249493822231212e-08], Loss: 1.787197, Acc:0.777508, Source Loss: 1.274749, Target Loss: 1.030019, MixUp Loss: 0.726932
2025-01-26 17:38:58,083 Epoch: [15/20] Iter:[90/289], Time: 2.04, lr: [7.201677405911048e-08], Loss: 1.828167, Acc:0.781056, Source Loss: 1.301819, Target Loss: 1.043961, MixUp Loss: 1.556252
2025-01-26 17:39:18,468 Epoch: [15/20] Iter:[100/289], Time: 2.04, lr: [7.153825687361213e-08], Loss: 1.822150, Acc:0.779874, Source Loss: 1.298382, Target Loss: 1.043616, MixUp Loss: 0.597136
2025-01-26 17:39:38,349 Epoch: [15/20] Iter:[110/289], Time: 2.04, lr: [7.105938377751932e-08], Loss: 1.838616, Acc:0.779321, Source Loss: 1.310711, Target Loss: 1.050386, MixUp Loss: 0.954310
2025-01-26 17:39:59,116 Epoch: [15/20] Iter:[120/289], Time: 2.04, lr: [7.0580151837082e-08], Loss: 1.830371, Acc:0.781376, Source Loss: 1.303351, Target Loss: 1.046929, MixUp Loss: 0.974870
2025-01-26 17:40:19,414 Epoch: [15/20] Iter:[130/289], Time: 2.04, lr: [7.01005580720342e-08], Loss: 1.819970, Acc:0.780110, Source Loss: 1.292300, Target Loss: 1.047546, MixUp Loss: 1.350896
2025-01-26 17:40:39,548 Epoch: [15/20] Iter:[140/289], Time: 2.04, lr: [6.96205994544969e-08], Loss: 1.818244, Acc:0.779381, Source Loss: 1.291723, Target Loss: 1.048878, MixUp Loss: 1.127297
2025-01-26 17:40:59,869 Epoch: [15/20] Iter:[150/289], Time: 2.04, lr: [6.914027290784657e-08], Loss: 1.800613, Acc:0.776671, Source Loss: 1.276920, Target Loss: 1.044167, MixUp Loss: 1.184252
2025-01-26 17:41:19,617 Epoch: [15/20] Iter:[160/289], Time: 2.03, lr: [6.865957530554758e-08], Loss: 1.795017, Acc:0.775713, Source Loss: 1.272017, Target Loss: 1.046632, MixUp Loss: 1.203378
2025-01-26 17:41:40,091 Epoch: [15/20] Iter:[170/289], Time: 2.03, lr: [6.817850346994796e-08], Loss: 1.787570, Acc:0.776879, Source Loss: 1.265340, Target Loss: 1.046290, MixUp Loss: 1.004758
2025-01-26 17:42:00,067 Epoch: [15/20] Iter:[180/289], Time: 2.03, lr: [6.769705417103576e-08], Loss: 1.791019, Acc:0.778492, Source Loss: 1.270303, Target Loss: 1.044243, MixUp Loss: 0.963291
2025-01-26 17:42:20,313 Epoch: [15/20] Iter:[190/289], Time: 2.03, lr: [6.721522412515551e-08], Loss: 1.792743, Acc:0.780639, Source Loss: 1.271069, Target Loss: 1.041037, MixUp Loss: 0.823021
2025-01-26 17:42:41,048 Epoch: [15/20] Iter:[200/289], Time: 2.03, lr: [6.673300999368237e-08], Loss: 1.780408, Acc:0.779155, Source Loss: 1.261621, Target Loss: 1.039944, MixUp Loss: 1.055117
2025-01-26 17:43:01,042 Epoch: [15/20] Iter:[210/289], Time: 2.03, lr: [6.625040838165307e-08], Loss: 1.776926, Acc:0.778587, Source Loss: 1.258677, Target Loss: 1.038071, MixUp Loss: 1.095770
2025-01-26 17:43:21,906 Epoch: [15/20] Iter:[220/289], Time: 2.03, lr: [6.576741583635098e-08], Loss: 1.775217, Acc:0.777953, Source Loss: 1.257165, Target Loss: 1.040860, MixUp Loss: 1.146356
2025-01-26 17:43:42,068 Epoch: [15/20] Iter:[230/289], Time: 2.03, lr: [6.52840288458439e-08], Loss: 1.776328, Acc:0.777175, Source Loss: 1.258453, Target Loss: 1.039310, MixUp Loss: 0.796686
2025-01-26 17:44:02,479 Epoch: [15/20] Iter:[240/289], Time: 2.03, lr: [6.480024383747266e-08], Loss: 1.781741, Acc:0.777946, Source Loss: 1.263749, Target Loss: 1.037844, MixUp Loss: 1.381424
2025-01-26 17:44:23,231 Epoch: [15/20] Iter:[250/289], Time: 2.04, lr: [6.431605717628792e-08], Loss: 1.778663, Acc:0.776986, Source Loss: 1.261695, Target Loss: 1.037927, MixUp Loss: 1.079619
2025-01-26 17:44:43,303 Epoch: [15/20] Iter:[260/289], Time: 2.03, lr: [6.383146516343375e-08], Loss: 1.768437, Acc:0.771840, Source Loss: 1.251518, Target Loss: 1.040282, MixUp Loss: 0.634827
2025-01-26 17:45:03,864 Epoch: [15/20] Iter:[270/289], Time: 2.04, lr: [6.334646403447491e-08], Loss: 1.765762, Acc:0.773067, Source Loss: 1.250034, Target Loss: 1.038468, MixUp Loss: 0.633266
2025-01-26 17:45:24,525 Epoch: [15/20] Iter:[280/289], Time: 2.04, lr: [6.28610499576659e-08], Loss: 1.768709, Acc:0.774561, Source Loss: 1.251883, Target Loss: 1.040309, MixUp Loss: 1.142346
2025-01-26 17:51:14,500 0 [0.         0.47857831 0.27960676 0.11303333 0.36547724 0.11868107
 0.13158686 0.06484145] 0.193975629363263
2025-01-26 17:51:14,500 1 [0.         0.54228848 0.25962408 0.27254157 0.44690075 0.08591677
 0.19292741 0.33986874] 0.2675084766170176
2025-01-26 17:51:14,502 Epoch 16/20 - Source Loss: 1.2517, Target Loss: 1.0373
2025-01-26 17:51:14,502 => saving checkpoint to output/loveDa/pidnet_small_loveda_train_DACScheckpoint.pth.tar
2025-01-26 17:51:14,902 Epoch [15], Loss: 1.768, MeanIoU: 0.2675, best_mIoU: 0.2918
2025-01-26 17:51:14,903 IoU per class: [0.         0.54228848 0.25962408 0.27254157 0.44690075 0.08591677
 0.19292741 0.33986874]
2025-01-26 17:51:15,393 Attention!!!
2025-01-26 17:51:15,394 Loaded 302 parameters!
2025-01-26 17:51:15,394 Over!!!
2025-01-26 17:51:17,895 Epoch: [16/20] Iter:[0/289], Time: 2.62, lr: [2.670739870378061e-08], Loss: 1.681226, Acc:0.538928, Source Loss: 1.155226, Target Loss: 1.278609, MixUp Loss: 1.052000
2025-01-26 17:51:37,534 Epoch: [16/20] Iter:[10/289], Time: 2.02, lr: [2.6499378907596798e-08], Loss: 1.796100, Acc:0.770090, Source Loss: 1.262775, Target Loss: 1.170401, MixUp Loss: 1.193356
2025-01-26 17:51:57,933 Epoch: [16/20] Iter:[20/289], Time: 2.03, lr: [2.6291177511625844e-08], Loss: 1.856717, Acc:0.770691, Source Loss: 1.308158, Target Loss: 1.180276, MixUp Loss: 1.091010
2025-01-26 17:52:17,750 Epoch: [16/20] Iter:[30/289], Time: 2.02, lr: [2.608279275659967e-08], Loss: 1.802945, Acc:0.747904, Source Loss: 1.259382, Target Loss: 1.162183, MixUp Loss: 0.815622
2025-01-26 17:52:38,072 Epoch: [16/20] Iter:[40/289], Time: 2.02, lr: [2.5874222850423827e-08], Loss: 1.812095, Acc:0.750290, Source Loss: 1.263463, Target Loss: 1.180208, MixUp Loss: 1.332933
2025-01-26 17:52:58,611 Epoch: [16/20] Iter:[50/289], Time: 2.03, lr: [2.566546596726525e-08], Loss: 1.777324, Acc:0.737701, Source Loss: 1.242821, Target Loss: 1.168562, MixUp Loss: 0.915642
2025-01-26 17:53:18,204 Epoch: [16/20] Iter:[60/289], Time: 2.02, lr: [2.5456520246606046e-08], Loss: 1.746035, Acc:0.728458, Source Loss: 1.223518, Target Loss: 1.169430, MixUp Loss: 1.271332
2025-01-26 17:53:38,582 Epoch: [16/20] Iter:[70/289], Time: 2.02, lr: [2.5247383792262054e-08], Loss: 1.745130, Acc:0.736118, Source Loss: 1.226760, Target Loss: 1.174138, MixUp Loss: 1.138784
2025-01-26 17:53:58,225 Epoch: [16/20] Iter:[80/289], Time: 2.01, lr: [2.5038054671364134e-08], Loss: 1.726851, Acc:0.737170, Source Loss: 1.208945, Target Loss: 1.174087, MixUp Loss: 1.103459
2025-01-26 17:54:18,514 Epoch: [16/20] Iter:[90/289], Time: 2.01, lr: [2.4828530913300758e-08], Loss: 1.742278, Acc:0.737416, Source Loss: 1.227890, Target Loss: 1.160438, MixUp Loss: 1.369267
2025-01-26 17:54:38,481 Epoch: [16/20] Iter:[100/289], Time: 2.01, lr: [2.4618810508619812e-08], Loss: 1.728004, Acc:0.739007, Source Loss: 1.218756, Target Loss: 1.151767, MixUp Loss: 1.156762
2025-01-26 17:54:58,539 Epoch: [16/20] Iter:[110/289], Time: 2.01, lr: [2.440889140788784e-08], Loss: 1.739982, Acc:0.743952, Source Loss: 1.226889, Target Loss: 1.150670, MixUp Loss: 1.109619
2025-01-26 17:55:18,945 Epoch: [16/20] Iter:[120/289], Time: 2.01, lr: [2.419877152050446e-08], Loss: 1.741078, Acc:0.743184, Source Loss: 1.228804, Target Loss: 1.143730, MixUp Loss: 1.162636
2025-01-26 17:55:38,517 Epoch: [16/20] Iter:[130/289], Time: 2.01, lr: [2.3988448713469874e-08], Loss: 1.742642, Acc:0.744509, Source Loss: 1.230397, Target Loss: 1.149593, MixUp Loss: 0.904452
2025-01-26 17:55:59,010 Epoch: [16/20] Iter:[140/289], Time: 2.01, lr: [2.377792081010306e-08], Loss: 1.737785, Acc:0.740786, Source Loss: 1.224193, Target Loss: 1.150693, MixUp Loss: 1.429890
2025-01-26 17:56:19,158 Epoch: [16/20] Iter:[150/289], Time: 2.01, lr: [2.35671855887083e-08], Loss: 1.747398, Acc:0.743092, Source Loss: 1.231072, Target Loss: 1.148639, MixUp Loss: 0.915592
2025-01-26 17:56:39,425 Epoch: [16/20] Iter:[160/289], Time: 2.01, lr: [2.3356240781187234e-08], Loss: 1.754503, Acc:0.744672, Source Loss: 1.236036, Target Loss: 1.146502, MixUp Loss: 1.250284
2025-01-26 17:57:00,056 Epoch: [16/20] Iter:[170/289], Time: 2.02, lr: [2.3145084071593786e-08], Loss: 1.761389, Acc:0.745334, Source Loss: 1.242488, Target Loss: 1.148721, MixUp Loss: 1.139267
2025-01-26 17:57:19,899 Epoch: [16/20] Iter:[180/289], Time: 2.01, lr: [2.2933713094628962e-08], Loss: 1.770704, Acc:0.745508, Source Loss: 1.250251, Target Loss: 1.149704, MixUp Loss: 1.486505
2025-01-26 17:57:40,054 Epoch: [16/20] Iter:[190/289], Time: 2.01, lr: [2.2722125434072357e-08], Loss: 1.765219, Acc:0.745737, Source Loss: 1.245496, Target Loss: 1.150766, MixUp Loss: 1.317207
2025-01-26 17:57:59,945 Epoch: [16/20] Iter:[200/289], Time: 2.01, lr: [2.251031862114713e-08], Loss: 1.777132, Acc:0.749540, Source Loss: 1.253087, Target Loss: 1.154526, MixUp Loss: 1.143338
2025-01-26 17:58:20,222 Epoch: [16/20] Iter:[210/289], Time: 2.01, lr: [2.2298290132814712e-08], Loss: 1.767841, Acc:0.750200, Source Loss: 1.245392, Target Loss: 1.158834, MixUp Loss: 1.279008
2025-01-26 17:58:40,619 Epoch: [16/20] Iter:[220/289], Time: 2.02, lr: [2.208603738999562e-08], Loss: 1.774628, Acc:0.750344, Source Loss: 1.249773, Target Loss: 1.160160, MixUp Loss: 1.415600
2025-01-26 17:59:00,535 Epoch: [16/20] Iter:[230/289], Time: 2.01, lr: [2.187355775571224e-08], Loss: 1.783169, Acc:0.752001, Source Loss: 1.256837, Target Loss: 1.161735, MixUp Loss: 0.782748
2025-01-26 17:59:20,868 Epoch: [16/20] Iter:[240/289], Time: 2.01, lr: [2.1660848533149426e-08], Loss: 1.790565, Acc:0.753482, Source Loss: 1.261549, Target Loss: 1.168029, MixUp Loss: 1.387482
2025-01-26 17:59:40,556 Epoch: [16/20] Iter:[250/289], Time: 2.01, lr: [2.1447906963628125e-08], Loss: 1.792685, Acc:0.751541, Source Loss: 1.263165, Target Loss: 1.168454, MixUp Loss: 1.418376
2025-01-26 18:00:01,151 Epoch: [16/20] Iter:[260/289], Time: 2.01, lr: [2.123473022448731e-08], Loss: 1.794506, Acc:0.750598, Source Loss: 1.264954, Target Loss: 1.166006, MixUp Loss: 0.707282
2025-01-26 18:00:21,454 Epoch: [16/20] Iter:[270/289], Time: 2.02, lr: [2.102131542686885e-08], Loss: 1.793786, Acc:0.750535, Source Loss: 1.264131, Target Loss: 1.164125, MixUp Loss: 0.706826
2025-01-26 18:00:41,170 Epoch: [16/20] Iter:[280/289], Time: 2.01, lr: [2.080765961339995e-08], Loss: 1.790950, Acc:0.751627, Source Loss: 1.261280, Target Loss: 1.163568, MixUp Loss: 1.009474
2025-01-26 18:06:12,490 0 [0.         0.48123136 0.29138424 0.11657825 0.35161665 0.13608168
 0.11973928 0.06274354] 0.19492187441928885
2025-01-26 18:06:12,491 1 [0.         0.54358582 0.27909595 0.29089729 0.45796692 0.10160452
 0.15707062 0.34394164] 0.27177034435000513
2025-01-26 18:06:12,494 Epoch 17/20 - Source Loss: 1.2616, Target Loss: 1.1660
2025-01-26 18:06:12,494 => saving checkpoint to output/loveDa/pidnet_small_loveda_train_DACScheckpoint.pth.tar
2025-01-26 18:06:12,898 Epoch [16], Loss: 1.790, MeanIoU: 0.2718, best_mIoU: 0.2918
2025-01-26 18:06:12,899 IoU per class: [0.         0.54358582 0.27909595 0.29089729 0.45796692 0.10160452
 0.15707062 0.34394164]
2025-01-26 18:06:13,155 Attention!!!
2025-01-26 18:06:13,155 Loaded 302 parameters!
2025-01-26 18:06:13,155 Over!!!
2025-01-26 18:06:15,613 Epoch: [17/20] Iter:[0/289], Time: 2.33, lr: [1.7474926415075008e-08], Loss: 1.999151, Acc:0.883263, Source Loss: 1.499267, Target Loss: 0.983950, MixUp Loss: 0.999767
2025-01-26 18:06:35,546 Epoch: [17/20] Iter:[10/289], Time: 2.03, lr: [1.7293420735755714e-08], Loss: 1.816975, Acc:0.752963, Source Loss: 1.307007, Target Loss: 1.127967, MixUp Loss: 0.957510
2025-01-26 18:06:55,666 Epoch: [17/20] Iter:[20/289], Time: 2.02, lr: [1.711170313584531e-08], Loss: 1.870100, Acc:0.761482, Source Loss: 1.338122, Target Loss: 1.116152, MixUp Loss: 1.054013
2025-01-26 18:07:15,370 Epoch: [17/20] Iter:[30/289], Time: 2.00, lr: [1.6929770861375723e-08], Loss: 1.836671, Acc:0.736845, Source Loss: 1.305201, Target Loss: 1.163014, MixUp Loss: 1.126147
2025-01-26 18:07:35,976 Epoch: [17/20] Iter:[40/289], Time: 2.02, lr: [1.6747621089236768e-08], Loss: 1.875436, Acc:0.754009, Source Loss: 1.338226, Target Loss: 1.167389, MixUp Loss: 1.101638
2025-01-26 18:07:56,666 Epoch: [17/20] Iter:[50/289], Time: 2.03, lr: [1.656525092458265e-08], Loss: 1.834012, Acc:0.747058, Source Loss: 1.306542, Target Loss: 1.152165, MixUp Loss: 1.212199
2025-01-26 18:08:16,373 Epoch: [17/20] Iter:[60/289], Time: 2.02, lr: [1.638265739810806e-08], Loss: 1.847029, Acc:0.755123, Source Loss: 1.316182, Target Loss: 1.151998, MixUp Loss: 1.267918
2025-01-26 18:08:36,842 Epoch: [17/20] Iter:[70/289], Time: 2.02, lr: [1.6199837463185856e-08], Loss: 1.853162, Acc:0.752370, Source Loss: 1.323320, Target Loss: 1.140726, MixUp Loss: 0.930323
2025-01-26 18:08:56,626 Epoch: [17/20] Iter:[80/289], Time: 2.02, lr: [1.6016787992857384e-08], Loss: 1.838792, Acc:0.748039, Source Loss: 1.315297, Target Loss: 1.145278, MixUp Loss: 0.947298
2025-01-26 18:09:16,907 Epoch: [17/20] Iter:[90/289], Time: 2.02, lr: [1.583350577666584e-08], Loss: 1.822089, Acc:0.748787, Source Loss: 1.299997, Target Loss: 1.154535, MixUp Loss: 1.322152
2025-01-26 18:09:37,241 Epoch: [17/20] Iter:[100/289], Time: 2.02, lr: [1.564998751732249e-08], Loss: 1.805929, Acc:0.750466, Source Loss: 1.285090, Target Loss: 1.155039, MixUp Loss: 1.051808
2025-01-26 18:09:57,020 Epoch: [17/20] Iter:[110/289], Time: 2.02, lr: [1.5466229827194474e-08], Loss: 1.818117, Acc:0.754717, Source Loss: 1.290699, Target Loss: 1.161191, MixUp Loss: 1.097811
2025-01-26 18:10:17,393 Epoch: [17/20] Iter:[120/289], Time: 2.02, lr: [1.528222922460227e-08], Loss: 1.813808, Acc:0.751003, Source Loss: 1.287696, Target Loss: 1.158403, MixUp Loss: 0.809671
2025-01-26 18:10:36,890 Epoch: [17/20] Iter:[130/289], Time: 2.01, lr: [1.509798212991371e-08], Loss: 1.806614, Acc:0.749385, Source Loss: 1.282102, Target Loss: 1.155547, MixUp Loss: 1.112645
2025-01-26 18:10:57,280 Epoch: [17/20] Iter:[140/289], Time: 2.01, lr: [1.4913484861420637e-08], Loss: 1.819864, Acc:0.753735, Source Loss: 1.291026, Target Loss: 1.160692, MixUp Loss: 1.081686
2025-01-26 18:11:17,259 Epoch: [17/20] Iter:[150/289], Time: 2.01, lr: [1.4728733630982748e-08], Loss: 1.825395, Acc:0.753792, Source Loss: 1.298714, Target Loss: 1.150968, MixUp Loss: 1.205055
2025-01-26 18:11:37,144 Epoch: [17/20] Iter:[160/289], Time: 2.01, lr: [1.4543724539422132e-08], Loss: 1.823359, Acc:0.755773, Source Loss: 1.297415, Target Loss: 1.151926, MixUp Loss: 0.973947
2025-01-26 18:11:57,359 Epoch: [17/20] Iter:[170/289], Time: 2.01, lr: [1.4358453571650473e-08], Loss: 1.824308, Acc:0.756707, Source Loss: 1.299134, Target Loss: 1.148402, MixUp Loss: 0.879349
2025-01-26 18:12:17,005 Epoch: [17/20] Iter:[180/289], Time: 2.01, lr: [1.4172916591509498e-08], Loss: 1.827273, Acc:0.759004, Source Loss: 1.304163, Target Loss: 1.144614, MixUp Loss: 0.698076
2025-01-26 18:12:37,323 Epoch: [17/20] Iter:[190/289], Time: 2.01, lr: [1.3987109336303054e-08], Loss: 1.828836, Acc:0.760165, Source Loss: 1.303890, Target Loss: 1.150257, MixUp Loss: 1.072453
2025-01-26 18:12:57,033 Epoch: [17/20] Iter:[200/289], Time: 2.01, lr: [1.3801027410997867e-08], Loss: 1.824856, Acc:0.760356, Source Loss: 1.299362, Target Loss: 1.156260, MixUp Loss: 0.782499
2025-01-26 18:13:17,445 Epoch: [17/20] Iter:[210/289], Time: 2.01, lr: [1.3614666282067385e-08], Loss: 1.818362, Acc:0.757309, Source Loss: 1.294638, Target Loss: 1.150726, MixUp Loss: 0.886267
2025-01-26 18:13:37,697 Epoch: [17/20] Iter:[220/289], Time: 2.01, lr: [1.342802127095123e-08], Loss: 1.820098, Acc:0.758636, Source Loss: 1.295938, Target Loss: 1.154415, MixUp Loss: 0.767143
2025-01-26 18:13:57,328 Epoch: [17/20] Iter:[230/289], Time: 2.01, lr: [1.3241087547099647e-08], Loss: 1.819808, Acc:0.756816, Source Loss: 1.295563, Target Loss: 1.157482, MixUp Loss: 1.005926
2025-01-26 18:14:17,653 Epoch: [17/20] Iter:[240/289], Time: 2.01, lr: [1.3053860120569895e-08], Loss: 1.822924, Acc:0.756765, Source Loss: 1.297353, Target Loss: 1.158268, MixUp Loss: 1.091793
2025-01-26 18:14:37,277 Epoch: [17/20] Iter:[250/289], Time: 2.01, lr: [1.286633383413797e-08], Loss: 1.815669, Acc:0.755617, Source Loss: 1.291439, Target Loss: 1.157670, MixUp Loss: 0.789279
2025-01-26 18:14:57,702 Epoch: [17/20] Iter:[260/289], Time: 2.01, lr: [1.2678503354885724e-08], Loss: 1.809654, Acc:0.753942, Source Loss: 1.285505, Target Loss: 1.159399, MixUp Loss: 0.962648
2025-01-26 18:15:17,699 Epoch: [17/20] Iter:[270/289], Time: 2.01, lr: [1.2490363165219029e-08], Loss: 1.806175, Acc:0.754349, Source Loss: 1.282324, Target Loss: 1.159976, MixUp Loss: 0.534318
2025-01-26 18:15:37,893 Epoch: [17/20] Iter:[280/289], Time: 2.01, lr: [1.2301907553268498e-08], Loss: 1.810452, Acc:0.756074, Source Loss: 1.285080, Target Loss: 1.158461, MixUp Loss: 1.018317
2025-01-26 18:21:10,161 0 [0.         0.48511691 0.29622569 0.12121828 0.34917445 0.13781442
 0.10955206 0.06754054] 0.19583029436953409
2025-01-26 18:21:10,161 1 [0.         0.54154124 0.27953365 0.30734992 0.44914756 0.08864592
 0.10324686 0.36423654] 0.26671271055388146
2025-01-26 18:21:10,162 Epoch 18/20 - Source Loss: 1.2841, Target Loss: 1.1600
2025-01-26 18:21:10,162 => saving checkpoint to output/loveDa/pidnet_small_loveda_train_DACScheckpoint.pth.tar
2025-01-26 18:21:10,598 Epoch [17], Loss: 1.809, MeanIoU: 0.2667, best_mIoU: 0.2918
2025-01-26 18:21:10,599 IoU per class: [0.         0.54154124 0.27953365 0.30734992 0.44914756 0.08864592
 0.10324686 0.36423654]
2025-01-26 18:21:10,856 Attention!!!
2025-01-26 18:21:10,856 Loaded 302 parameters!
2025-01-26 18:21:10,856 Over!!!
2025-01-26 18:21:13,605 Epoch: [18/20] Iter:[0/289], Time: 2.63, lr: [1.4131216285988759e-08], Loss: 1.589293, Acc:0.828551, Source Loss: 0.974664, Target Loss: 1.405916, MixUp Loss: 1.229258
2025-01-26 18:21:33,179 Epoch: [18/20] Iter:[10/289], Time: 2.02, lr: [1.3910988484906853e-08], Loss: 1.671991, Acc:0.689285, Source Loss: 1.146759, Target Loss: 1.151326, MixUp Loss: 0.896332
2025-01-26 18:21:54,164 Epoch: [18/20] Iter:[20/289], Time: 2.06, lr: [1.369037259624442e-08], Loss: 1.701792, Acc:0.721767, Source Loss: 1.172857, Target Loss: 1.151023, MixUp Loss: 1.193469
