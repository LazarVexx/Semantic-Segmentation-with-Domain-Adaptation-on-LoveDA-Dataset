2025-01-16 18:03:14,709 Namespace(cfg='configs/loveDa/pidnet_small_loveda_train_AVD.yaml', seed=304, opts=['GPUS', '[0]', 'TRAIN.BATCH_SIZE_PER_GPU', '6'])
2025-01-16 18:03:14,709 AUTO_RESUME: False
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  DATASET: loveDa
  EXTRA_TRAIN_SET: 
  NUM_CLASSES: 8
  ROOT: data/
  SOURCE_DATASET: loveDA-Urban
  SOURCE_TEST_SET: list/loveDA-Urban/val.lst
  SOURCE_TRAIN_SET: list/loveDA-Urban/train.lst
  TARGET_DATASET: loveDA-Rural
  TARGET_SET: list/loveDa/target.lst
  TARGET_TEST_SET: list/loveDA-Rural/val.lst
  TARGET_TRAIN_SET: list/loveDA-Rural/train.lst
  TEST_SET: list/loveDa-Rural/val.lst
  TRAIN_SET: list/loveDa/train.lst
GPUS: (0,)
LOG_DIR: log
LOSS:
  BALANCE_WEIGHTS: [0.4, 1.0]
  CLASS_BALANCE: False
  OHEMKEEP: 131072
  OHEMTHRES: 0.9
  SB_WEIGHTS: 1.0
  USE_DICE: False
  USE_FOCAL: False
  USE_OHEM: True
MODEL:
  ALIGN_CORNERS: True
  NAME: pidnet_small
  NUM_OUTPUTS: 2
  PRETRAINED: pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar
OUTPUT_DIR: output
PIN_MEMORY: True
PRINT_FREQ: 10
TEST:
  BASE_SIZE: 2048
  BATCH_SIZE_PER_GPU: 6
  FLIP_TEST: False
  IMAGE_SIZE: [1024, 1024]
  MODEL_FILE: 
  MULTI_SCALE: False
  OUTPUT_INDEX: 1
TRAIN:
  ADVERSARIAL: True
  AUG: False
  AUG1: False
  AUG2: False
  AUG3: False
  AUG4: False
  AUG_CHANCE: False
  BASE_SIZE: 1440
  BATCH_SIZE_PER_GPU: 6
  BEGIN_EPOCH: 0
  END_EPOCH: 20
  EVAL_INTERVAL: 1
  EXTRA_EPOCH: 0
  EXTRA_LR: 0.001
  FLIP: True
  GAN: Vanilla
  IGNORE_LABEL: 255
  IMAGE_SIZE: [720, 720]
  LAMBDA_ADVT1: 0.0002
  LR: 0.01
  LR_D1: 0.0001
  MOMENTUM: 0.9
  MULTI_SCALE: True
  NESTEROV: False
  OPTIMIZER: sgd
  RESUME: False
  SCALE_FACTOR: 16
  SCHEDULER: False
  SHUFFLE: True
  WD: 0.0005
WORKERS: 0
2025-01-16 18:03:14,897 Attention!!!
2025-01-16 18:03:14,897 Loaded 302 parameters!
2025-01-16 18:03:14,897 Over!!!
2025-01-16 18:03:23,715 Epoch: [0/20] Iter:[0/192], Time: 7.09, lr: [0.01], Loss: 4.596371, Loss_D: 0.693146, Acc:0.187284, Semantic loss: 0.595856
2025-01-16 18:03:38,858 Epoch: [0/20] Iter:[10/192], Time: 15.13, lr: [0.009976559445324192], Loss: 4.452372, Loss_D: 0.692983, Acc:0.222026, Semantic loss: 0.518005
2025-01-16 18:03:53,071 Epoch: [0/20] Iter:[20/192], Time: 22.25, lr: [0.009953112769592761], Loss: 3.938897, Loss_D: 0.693095, Acc:0.276683, Semantic loss: 0.478931
2025-01-16 18:04:07,192 Epoch: [0/20] Iter:[30/192], Time: 29.33, lr: [0.009929659955177281], Loss: 3.701039, Loss_D: 0.699378, Acc:0.298837, Semantic loss: 0.454069
2025-01-16 18:04:20,855 Epoch: [0/20] Iter:[40/192], Time: 36.35, lr: [0.009906200984352154], Loss: 3.448240, Loss_D: 0.707385, Acc:0.318975, Semantic loss: 0.429760
2025-01-16 18:04:35,019 Epoch: [0/20] Iter:[50/192], Time: 43.33, lr: [0.009882735839293803], Loss: 3.327317, Loss_D: 0.703130, Acc:0.330988, Semantic loss: 0.408443
2025-01-16 18:04:48,750 Epoch: [0/20] Iter:[60/192], Time: 50.31, lr: [0.00985926450207989], Loss: 3.262694, Loss_D: 0.678895, Acc:0.342124, Semantic loss: 0.391319
2025-01-16 18:05:02,532 Epoch: [0/20] Iter:[70/192], Time: 57.26, lr: [0.009835786954688485], Loss: 3.183218, Loss_D: 0.693024, Acc:0.350067, Semantic loss: 0.376671
2025-01-16 18:05:16,429 Epoch: [0/20] Iter:[80/192], Time: 64.20, lr: [0.00981230317899726], Loss: 3.140382, Loss_D: 0.691960, Acc:0.357552, Semantic loss: 0.363534
2025-01-16 18:05:30,399 Epoch: [0/20] Iter:[90/192], Time: 71.15, lr: [0.009788813156782662], Loss: 3.109297, Loss_D: 0.693111, Acc:0.365177, Semantic loss: 0.351713
2025-01-16 18:05:44,517 Epoch: [0/20] Iter:[100/192], Time: 78.12, lr: [0.009765316869719067], Loss: 3.058827, Loss_D: 0.689527, Acc:0.367542, Semantic loss: 0.342058
2025-01-16 18:05:58,525 Epoch: [0/20] Iter:[110/192], Time: 85.10, lr: [0.009741814299377942], Loss: 3.014707, Loss_D: 0.684004, Acc:0.373770, Semantic loss: 0.332246
2025-01-16 18:06:12,742 Epoch: [0/20] Iter:[120/192], Time: 92.09, lr: [0.009718305427226986], Loss: 2.983101, Loss_D: 0.683276, Acc:0.380524, Semantic loss: 0.322738
2025-01-16 18:06:26,576 Epoch: [0/20] Iter:[130/192], Time: 99.08, lr: [0.009694790234629266], Loss: 2.945395, Loss_D: 0.670271, Acc:0.386659, Semantic loss: 0.313981
2025-01-16 18:06:40,446 Epoch: [0/20] Iter:[140/192], Time: 106.07, lr: [0.009671268702842338], Loss: 2.926892, Loss_D: 0.632050, Acc:0.391067, Semantic loss: 0.308004
2025-01-16 18:06:54,331 Epoch: [0/20] Iter:[150/192], Time: 113.04, lr: [0.009647740813017376], Loss: 2.903063, Loss_D: 0.646186, Acc:0.397816, Semantic loss: 0.300670
2025-01-16 18:07:08,193 Epoch: [0/20] Iter:[160/192], Time: 120.02, lr: [0.009624206546198262], Loss: 2.886916, Loss_D: 0.724383, Acc:0.401996, Semantic loss: 0.294313
2025-01-16 18:07:21,925 Epoch: [0/20] Iter:[170/192], Time: 126.98, lr: [0.009600665883320689], Loss: 2.865744, Loss_D: 0.650749, Acc:0.405378, Semantic loss: 0.288973
2025-01-16 18:07:36,320 Epoch: [0/20] Iter:[180/192], Time: 133.95, lr: [0.009577118805211254], Loss: 2.860550, Loss_D: 0.659284, Acc:0.410076, Semantic loss: 0.283449
2025-01-16 18:07:50,808 Epoch: [0/20] Iter:[190/192], Time: 140.95, lr: [0.009553565292586523], Loss: 2.849212, Loss_D: 0.677159, Acc:0.413160, Semantic loss: 0.278981
2025-01-16 18:11:15,517 0 [0.         0.327133   0.08373553 0.05670656 0.184074   0.04812134
 0.0602691  0.01520661] 0.09690576568596011
2025-01-16 18:11:15,517 1 [0.         0.37496389 0.10626136 0.03852542 0.01532559 0.02789329
 0.00394896 0.00043103] 0.07091869164965449
2025-01-16 18:11:15,519 => saving checkpoint to output\loveDa\pidnet_small_loveda_train_AVDcheckpoint.pth.tar
2025-01-16 18:11:15,807 Loss: 1.531, MeanIU:  0.0709, Best_mIoU:  0.0709
2025-01-16 18:11:15,808 [0.         0.37496389 0.10626136 0.03852542 0.01532559 0.02789329
 0.00394896 0.00043103]
2025-01-16 18:11:17,433 Epoch: [1/20] Iter:[0/192], Time: 1.58, lr: [0.009548853816214998], Loss: 2.034801, Loss_D: 0.645441, Acc:0.525865, Semantic loss: 0.186337
