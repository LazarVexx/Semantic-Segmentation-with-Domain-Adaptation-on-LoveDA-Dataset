2025-01-16 18:27:56,931 Namespace(cfg='configs/loveDa/pidnet_small_loveda_train_AVD.yaml', seed=304, opts=['GPUS', '[0]', 'TRAIN.BATCH_SIZE_PER_GPU', '6'])
2025-01-16 18:27:56,931 AUTO_RESUME: False
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  DATASET: loveDa
  EXTRA_TRAIN_SET: 
  NUM_CLASSES: 8
  ROOT: data/
  SOURCE_DATASET: loveDA-Urban
  SOURCE_TEST_SET: list/loveDA-Urban/val.lst
  SOURCE_TRAIN_SET: list/loveDA-Urban/train.lst
  TARGET_DATASET: loveDA-Rural
  TARGET_SET: list/loveDa/target.lst
  TARGET_TEST_SET: list/loveDA-Rural/val.lst
  TARGET_TRAIN_SET: list/loveDA-Rural/train.lst
  TEST_SET: list/loveDa-Rural/val.lst
  TRAIN_SET: list/loveDa/train.lst
GPUS: (0,)
LOG_DIR: log
LOSS:
  BALANCE_WEIGHTS: [0.4, 1.0]
  CLASS_BALANCE: False
  OHEMKEEP: 131072
  OHEMTHRES: 0.9
  SB_WEIGHTS: 1.0
  USE_DICE: False
  USE_FOCAL: False
  USE_OHEM: True
MODEL:
  ALIGN_CORNERS: True
  NAME: pidnet_small
  NUM_OUTPUTS: 2
  PRETRAINED: pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar
OUTPUT_DIR: output
PIN_MEMORY: True
PRINT_FREQ: 10
TEST:
  BASE_SIZE: 2048
  BATCH_SIZE_PER_GPU: 6
  FLIP_TEST: False
  IMAGE_SIZE: [1024, 1024]
  MODEL_FILE: 
  MULTI_SCALE: False
  OUTPUT_INDEX: 1
TRAIN:
  ADVERSARIAL: True
  AUG: False
  AUG1: False
  AUG2: False
  AUG3: False
  AUG4: False
  AUG_CHANCE: False
  BASE_SIZE: 1440
  BATCH_SIZE_PER_GPU: 6
  BEGIN_EPOCH: 0
  END_EPOCH: 20
  EVAL_INTERVAL: 1
  EXTRA_EPOCH: 0
  EXTRA_LR: 0.001
  FLIP: True
  GAN: Vanilla
  IGNORE_LABEL: 255
  IMAGE_SIZE: [720, 720]
  LAMBDA_ADV: 0.001
  LR: 0.01
  LR_D1: 0.01
  MOMENTUM: 0.9
  MULTI_SCALE: True
  NESTEROV: False
  OPTIMIZER: sgd
  RESUME: False
  SCALE_FACTOR: 16
  SCHEDULER: False
  SHUFFLE: True
  WD: 0.0005
WORKERS: 0
2025-01-16 18:27:57,159 Attention!!!
2025-01-16 18:27:57,160 Loaded 302 parameters!
2025-01-16 18:27:57,160 Over!!!
2025-01-16 18:28:04,664 Epoch: [0/20] Iter:[0/192], Time: 5.68, lr: [0.01], Loss: 3.952281, Loss_D: 0.693139, Acc:0.172610, Semantic loss: 0.587613
2025-01-16 18:28:20,213 Epoch: [0/20] Iter:[10/192], Time: 13.51, lr: [0.009976559445324192], Loss: 4.066879, Loss_D: 292.708038, Acc:0.230639, Semantic loss: 0.508401
2025-01-16 18:28:35,922 Epoch: [0/20] Iter:[20/192], Time: 21.29, lr: [0.009953112769592761], Loss: 3.665368, Loss_D: 211.144196, Acc:0.275582, Semantic loss: 0.477432
2025-01-16 18:28:51,615 Epoch: [0/20] Iter:[30/192], Time: 29.12, lr: [0.009929659955177281], Loss: 3.333658, Loss_D: 32.933655, Acc:0.299584, Semantic loss: 0.451640
2025-01-16 18:29:06,804 Epoch: [0/20] Iter:[40/192], Time: 36.92, lr: [0.009906200984352154], Loss: 3.008092, Loss_D: 28.424963, Acc:0.317796, Semantic loss: 0.425677
2025-01-16 18:29:21,985 Epoch: [0/20] Iter:[50/192], Time: 44.60, lr: [0.009882735839293803], Loss: 2.834940, Loss_D: 17.952047, Acc:0.329611, Semantic loss: 0.400650
2025-01-16 18:29:37,043 Epoch: [0/20] Iter:[60/192], Time: 52.24, lr: [0.00985926450207989], Loss: 2.730683, Loss_D: 14.481700, Acc:0.343685, Semantic loss: 0.382710
2025-01-16 18:29:51,980 Epoch: [0/20] Iter:[70/192], Time: 59.84, lr: [0.009835786954688485], Loss: 2.636689, Loss_D: 2.971541, Acc:0.352999, Semantic loss: 0.367869
2025-01-16 18:30:06,761 Epoch: [0/20] Iter:[80/192], Time: 67.40, lr: [0.00981230317899726], Loss: 2.572794, Loss_D: 5.722471, Acc:0.362622, Semantic loss: 0.354674
2025-01-16 18:30:21,793 Epoch: [0/20] Iter:[90/192], Time: 74.94, lr: [0.009788813156782662], Loss: 2.525028, Loss_D: 3.313553, Acc:0.367446, Semantic loss: 0.342247
2025-01-16 18:30:36,863 Epoch: [0/20] Iter:[100/192], Time: 82.46, lr: [0.009765316869719067], Loss: 2.459810, Loss_D: 0.786633, Acc:0.374345, Semantic loss: 0.331218
2025-01-16 18:30:52,289 Epoch: [0/20] Iter:[110/192], Time: 90.04, lr: [0.009741814299377942], Loss: 2.407808, Loss_D: 1.938342, Acc:0.379749, Semantic loss: 0.322386
2025-01-16 18:31:07,289 Epoch: [0/20] Iter:[120/192], Time: 97.60, lr: [0.009718305427226986], Loss: 2.368018, Loss_D: 1.422537, Acc:0.385161, Semantic loss: 0.313775
2025-01-16 18:31:22,142 Epoch: [0/20] Iter:[130/192], Time: 105.15, lr: [0.009694790234629266], Loss: 2.321891, Loss_D: 0.886532, Acc:0.390743, Semantic loss: 0.306089
2025-01-16 18:31:37,221 Epoch: [0/20] Iter:[140/192], Time: 112.69, lr: [0.009671268702842338], Loss: 2.296261, Loss_D: 0.782830, Acc:0.395629, Semantic loss: 0.299980
2025-01-16 18:31:52,076 Epoch: [0/20] Iter:[150/192], Time: 120.22, lr: [0.009647740813017376], Loss: 2.262823, Loss_D: 0.690696, Acc:0.401815, Semantic loss: 0.292997
2025-01-16 18:32:08,968 Epoch: [0/20] Iter:[160/192], Time: 127.78, lr: [0.009624206546198262], Loss: 2.231407, Loss_D: 0.701443, Acc:0.406420, Semantic loss: 0.286813
2025-01-16 18:32:25,736 Epoch: [0/20] Iter:[170/192], Time: 135.47, lr: [0.009600665883320689], Loss: 2.201190, Loss_D: 0.653214, Acc:0.409086, Semantic loss: 0.282084
2025-01-16 18:32:44,248 Epoch: [0/20] Iter:[180/192], Time: 143.28, lr: [0.009577118805211254], Loss: 2.193891, Loss_D: 0.719522, Acc:0.412336, Semantic loss: 0.277211
2025-01-16 18:33:00,509 Epoch: [0/20] Iter:[190/192], Time: 151.17, lr: [0.009553565292586523], Loss: 2.179391, Loss_D: 0.761112, Acc:0.416811, Semantic loss: 0.273156
2025-01-16 18:36:28,764 0 [0.         0.34557341 0.06846664 0.05499642 0.13522344 0.0506572
 0.04038419 0.00176606] 0.08713342100385085
2025-01-16 18:36:28,764 1 [0.         0.30046743 0.09366063 0.07346242 0.00311689 0.01960518
 0.00208594 0.00077957] 0.06164725682807579
2025-01-16 18:36:28,765 => saving checkpoint to output\loveDa\pidnet_small_loveda_train_AVDcheckpoint.pth.tar
2025-01-16 18:36:28,951 Loss: 1.577, MeanIU:  0.0616, Best_mIoU:  0.0616
2025-01-16 18:36:28,951 [0.         0.30046743 0.09366063 0.07346242 0.00311689 0.01960518
 0.00208594 0.00077957]
2025-01-16 18:36:30,502 Epoch: [1/20] Iter:[0/192], Time: 1.50, lr: [0.009548853816214998], Loss: 1.192399, Loss_D: 0.629653, Acc:0.583131, Semantic loss: 0.168914
2025-01-16 18:36:44,535 Epoch: [1/20] Iter:[10/192], Time: 8.55, lr: [0.009525292556561479], Loss: 1.885167, Loss_D: 0.657895, Acc:0.529526, Semantic loss: 0.179811
2025-01-16 18:36:58,417 Epoch: [1/20] Iter:[20/192], Time: 15.51, lr: [0.00950172481957719], Loss: 1.865973, Loss_D: 0.697110, Acc:0.531213, Semantic loss: 0.179715
2025-01-16 18:37:12,288 Epoch: [1/20] Iter:[30/192], Time: 22.46, lr: [0.009478150585620286], Loss: 1.857352, Loss_D: 0.687747, Acc:0.505172, Semantic loss: 0.184268
