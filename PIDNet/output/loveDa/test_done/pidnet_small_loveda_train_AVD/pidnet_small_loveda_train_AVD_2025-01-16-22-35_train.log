2025-01-16 22:35:03,997 Namespace(cfg='configs/loveDa/pidnet_small_loveda_train_AVD.yaml', seed=304, opts=['GPUS', '[0]', 'TRAIN.BATCH_SIZE_PER_GPU', '6'])
2025-01-16 22:35:03,997 AUTO_RESUME: False
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  DATASET: loveDa
  EXTRA_TRAIN_SET: 
  NUM_CLASSES: 8
  ROOT: data/
  SOURCE_DATASET: loveDA-Urban
  SOURCE_TEST_SET: list/loveDA-Urban/val.lst
  SOURCE_TRAIN_SET: list/loveDA-Urban/train.lst
  TARGET_DATASET: loveDA-Rural
  TARGET_SET: list/loveDa/target.lst
  TARGET_TEST_SET: list/loveDA-Rural/val.lst
  TARGET_TRAIN_SET: list/loveDA-Rural/train.lst
  TEST_SET: list/loveDa-Rural/val.lst
  TRAIN_SET: list/loveDa/train.lst
GPUS: (0,)
LOG_DIR: log
LOSS:
  BALANCE_WEIGHTS: [0.4, 1.0]
  CLASS_BALANCE: False
  OHEMKEEP: 131072
  OHEMTHRES: 0.9
  SB_WEIGHTS: 1.0
  USE_DICE: False
  USE_FOCAL: False
  USE_OHEM: True
MODEL:
  ALIGN_CORNERS: True
  NAME: pidnet_small
  NUM_OUTPUTS: 3
  PRETRAINED: pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar
OUTPUT_DIR: output
PIN_MEMORY: True
PRINT_FREQ: 10
TEST:
  BASE_SIZE: 2048
  BATCH_SIZE_PER_GPU: 6
  FLIP_TEST: False
  IMAGE_SIZE: [1024, 1024]
  MODEL_FILE: 
  MULTI_SCALE: False
  OUTPUT_INDEX: 1
TRAIN:
  ADVERSARIAL: True
  AUG: False
  AUG1: False
  AUG2: False
  AUG3: False
  AUG4: False
  AUG_CHANCE: False
  BASE_SIZE: 1440
  BATCH_SIZE_PER_GPU: 6
  BEGIN_EPOCH: 0
  END_EPOCH: 20
  EVAL_INTERVAL: 1
  EXTRA_EPOCH: 0
  EXTRA_LR: 0.001
  FLIP: True
  GAN: Vanilla
  IGNORE_LABEL: 255
  IMAGE_SIZE: [720, 720]
  LAMBDA_ADV1: 0.001
  LAMBDA_ADV2: 0.001
  LR: 0.01
  LR_D1: 0.01
  LR_D2: 0.01
  MOMENTUM: 0.9
  MULTI_SCALE: True
  NESTEROV: False
  OPTIMIZER: sgd
  RESUME: False
  SCALE_FACTOR: 16
  SCHEDULER: False
  SHUFFLE: True
  WD: 0.0005
WORKERS: 0
2025-01-16 22:35:04,144 Attention!!!
2025-01-16 22:35:04,145 Loaded 302 parameters!
2025-01-16 22:35:04,145 Over!!!
2025-01-16 22:35:09,716 Epoch: [0/20] Iter:[0/192], Time: 5.37, lr: [0.01], Loss: 4.158717, Loss_D1: 1.386266, Loss_D2: 1.386525, Acc:0.154409, Semantic loss: 0.586043
2025-01-16 22:35:24,889 Epoch: [0/20] Iter:[10/192], Time: 12.67, lr: [0.009976559445324192], Loss: 3.807264, Loss_D1: 372.303192, Loss_D2: 1108.626587, Acc:0.206701, Semantic loss: 0.537478
2025-01-16 22:35:39,665 Epoch: [0/20] Iter:[20/192], Time: 20.14, lr: [0.009953112769592761], Loss: 3.229367, Loss_D1: 28.484657, Loss_D2: 1930.278076, Acc:0.251705, Semantic loss: 0.491282
2025-01-16 22:35:54,244 Epoch: [0/20] Iter:[30/192], Time: 27.54, lr: [0.009929659955177281], Loss: 3.000612, Loss_D1: 70.973747, Loss_D2: 2784.599121, Acc:0.287271, Semantic loss: 0.453608
2025-01-16 22:36:08,677 Epoch: [0/20] Iter:[40/192], Time: 34.87, lr: [0.009906200984352154], Loss: 2.824687, Loss_D1: 2319.232666, Loss_D2: 361.207916, Acc:0.313861, Semantic loss: 0.422461
2025-01-16 22:36:23,468 Epoch: [0/20] Iter:[50/192], Time: 42.18, lr: [0.009882735839293803], Loss: 2.689096, Loss_D1: 185.290009, Loss_D2: 53.635902, Acc:0.333483, Semantic loss: 0.400272
2025-01-16 22:36:38,054 Epoch: [0/20] Iter:[60/192], Time: 49.50, lr: [0.00985926450207989], Loss: 2.583514, Loss_D1: 476.677521, Loss_D2: 4.968705, Acc:0.342926, Semantic loss: 0.383208
2025-01-16 22:36:52,406 Epoch: [0/20] Iter:[70/192], Time: 56.79, lr: [0.009835786954688485], Loss: 2.515869, Loss_D1: 48.006523, Loss_D2: 61.342159, Acc:0.357030, Semantic loss: 0.364852
2025-01-16 22:37:06,861 Epoch: [0/20] Iter:[80/192], Time: 64.06, lr: [0.00981230317899726], Loss: 2.455316, Loss_D1: 33.523823, Loss_D2: 106.338669, Acc:0.367062, Semantic loss: 0.349428
2025-01-16 22:37:21,447 Epoch: [0/20] Iter:[90/192], Time: 71.33, lr: [0.009788813156782662], Loss: 2.383119, Loss_D1: 12.516019, Loss_D2: 86.181023, Acc:0.376986, Semantic loss: 0.335748
2025-01-16 22:37:36,151 Epoch: [0/20] Iter:[100/192], Time: 78.62, lr: [0.009765316869719067], Loss: 2.347156, Loss_D1: 7.002741, Loss_D2: 14.530708, Acc:0.386308, Semantic loss: 0.323774
2025-01-16 22:37:52,408 Epoch: [0/20] Iter:[110/192], Time: 85.99, lr: [0.009741814299377942], Loss: 2.304091, Loss_D1: 3.526652, Loss_D2: 25.629124, Acc:0.390888, Semantic loss: 0.315655
2025-01-16 22:38:09,376 Epoch: [0/20] Iter:[120/192], Time: 93.52, lr: [0.009718305427226986], Loss: 2.259077, Loss_D1: 10.984076, Loss_D2: 1.667047, Acc:0.395250, Semantic loss: 0.307694
2025-01-16 22:38:25,849 Epoch: [0/20] Iter:[130/192], Time: 101.19, lr: [0.009694790234629266], Loss: 2.222166, Loss_D1: 8.877368, Loss_D2: 55.186951, Acc:0.400035, Semantic loss: 0.300775
2025-01-16 22:38:42,562 Epoch: [0/20] Iter:[140/192], Time: 108.93, lr: [0.009671268702842338], Loss: 2.186830, Loss_D1: 84.043236, Loss_D2: 26.687393, Acc:0.402656, Semantic loss: 0.294888
2025-01-16 22:38:58,875 Epoch: [0/20] Iter:[150/192], Time: 116.75, lr: [0.009647740813017376], Loss: 2.167143, Loss_D1: 3.054938, Loss_D2: 6.356151, Acc:0.406483, Semantic loss: 0.290182
2025-01-16 22:39:14,949 Epoch: [0/20] Iter:[160/192], Time: 124.61, lr: [0.009624206546198262], Loss: 2.165300, Loss_D1: 4.394536, Loss_D2: 4.199408, Acc:0.410751, Semantic loss: 0.284277
2025-01-16 22:39:30,679 Epoch: [0/20] Iter:[170/192], Time: 132.47, lr: [0.009600665883320689], Loss: 2.135559, Loss_D1: 2.099861, Loss_D2: 2.738029, Acc:0.413892, Semantic loss: 0.279853
2025-01-16 22:39:46,832 Epoch: [0/20] Iter:[180/192], Time: 140.35, lr: [0.009577118805211254], Loss: 2.128968, Loss_D1: 1.556564, Loss_D2: 2.864922, Acc:0.417150, Semantic loss: 0.275717
2025-01-16 22:40:03,707 Epoch: [0/20] Iter:[190/192], Time: 148.26, lr: [0.009553565292586523], Loss: 2.118906, Loss_D1: 1.479982, Loss_D2: 2.075873, Acc:0.421923, Semantic loss: 0.270681
2025-01-16 22:44:21,544 0 [0.         0.31279989 0.07349202 0.03375776 0.24116749 0.04031782
 0.10913288 0.00227386] 0.10161771241875411
2025-01-16 22:44:21,545 1 [0.         0.37466582 0.07113533 0.05307494 0.12498687 0.02541901
 0.14909092 0.0005472 ] 0.09986501109429971
2025-01-16 22:44:21,545 2 [0.         0.09463566 0.02910797 0.02578095 0.08972861 0.03327564
 0.04050893 0.10871675] 0.05271931535996679
2025-01-16 22:44:21,545 => saving checkpoint to output\loveDa\pidnet_small_loveda_train_AVDcheckpoint.pth.tar
2025-01-16 22:44:21,734 Loss: 1.488, MeanIU:  0.0527, Best_mIoU:  0.0527
2025-01-16 22:44:21,734 [0.         0.09463566 0.02910797 0.02578095 0.08972861 0.03327564
 0.04050893 0.10871675]
2025-01-16 22:44:23,388 Epoch: [1/20] Iter:[0/192], Time: 1.31, lr: [0.009548853816214998], Loss: 1.609767, Loss_D1: 1.381195, Loss_D2: 2.042948, Acc:0.425985, Semantic loss: 0.163755
