{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install numpy\n",
        "!pip install tensorboardX\n",
        "!pip install opencv-python\n",
        "!pip install Pillow\n",
        "!pip install yacs\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-EBAY2-PX4b",
        "outputId": "e4d6cece-fa0a-4d8d-e06b-da25fbea5b0c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (4.25.5)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from yacs) (6.0.2)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: yacs\n",
            "Successfully installed yacs-0.1.8\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/LucaIanniello/AML2024"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qvQwUMjTRRa",
        "outputId": "6bd8f5ca-121b-45f7-8c61-fe59fcb638e0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AML2024'...\n",
            "remote: Enumerating objects: 1059, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 1059 (delta 5), reused 6 (delta 3), pack-reused 1037 (from 4)\u001b[K\n",
            "Receiving objects: 100% (1059/1059), 514.52 MiB | 16.67 MiB/s, done.\n",
            "Resolving deltas: 100% (218/218), done.\n",
            "Updating files: 100% (188/188), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import subprocess\n",
        "\n",
        "# Funzione per scaricare un file e decomprimerlo\n",
        "def download_and_extract(url, zip_path, extract_path):\n",
        "    # Se il file ZIP esiste già, non scaricarlo di nuovo\n",
        "    if not os.path.exists(zip_path):\n",
        "        print(f\"Downloading {url} to {zip_path}...\")\n",
        "        # Scarica il file usando curl\n",
        "        try:\n",
        "            subprocess.run([\"curl\", \"-L\", \"-o\", zip_path, url], check=True)\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"Error downloading file: {e}\")\n",
        "            return\n",
        "\n",
        "    # Crea la directory di estrazione se non esiste\n",
        "    os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "    # Estrai il file ZIP\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_path)\n",
        "        print(f\"Extracted files to {extract_path}\")\n",
        "    except zipfile.BadZipFile as e:\n",
        "        print(f\"Error extracting {zip_path}: {e}\")\n",
        "        return\n",
        "\n",
        "    # Elenca i file estratti\n",
        "    extracted_files = os.listdir(extract_path)\n",
        "    print(f\"Extracted files in {extract_path}:\", extracted_files)\n",
        "\n",
        "# Percorsi principali\n",
        "base_dir = os.path.expanduser(\"AML2024/PIDNet/data/loveDa\")\n",
        "\n",
        "# Crea la directory base se non esiste\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Dataset Val\n",
        "val_url = \"https://zenodo.org/records/5706578/files/Val.zip?download=1\"\n",
        "val_zip_path = os.path.join(base_dir, \"Val.zip\")\n",
        "val_extract_path = os.path.join(base_dir, \"\")\n",
        "download_and_extract(val_url, val_zip_path, val_extract_path)\n",
        "\n",
        "# Dataset Train\n",
        "train_url = \"https://zenodo.org/records/5706578/files/Train.zip?download=1\"\n",
        "train_zip_path = os.path.join(base_dir, \"Train.zip\")\n",
        "train_extract_path = os.path.join(base_dir, \"\")\n",
        "download_and_extract(train_url, train_zip_path, train_extract_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kn4aqFfZTP7v",
        "outputId": "4f5503fe-8e71-4123-b63f-3ccf4b88401d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://zenodo.org/records/5706578/files/Val.zip?download=1 to AML2024/PIDNet/data/loveDa/Val.zip...\n",
            "Extracted files to AML2024/PIDNet/data/loveDa/\n",
            "Extracted files in AML2024/PIDNet/data/loveDa/: ['Val', '.gitignore', 'Val.zip']\n",
            "Downloading https://zenodo.org/records/5706578/files/Train.zip?download=1 to AML2024/PIDNet/data/loveDa/Train.zip...\n",
            "Extracted files to AML2024/PIDNet/data/loveDa/\n",
            "Extracted files in AML2024/PIDNet/data/loveDa/: ['Train.zip', 'Train', 'Val', '.gitignore', 'Val.zip']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sys\n",
        "\n",
        "def get_gpu_info():\n",
        "    # Verifica se CUDA è disponibile\n",
        "    cuda_available = torch.cuda.is_available()\n",
        "    print(f\"CUDA è disponibile: {cuda_available}\")\n",
        "\n",
        "    if cuda_available:\n",
        "        # Numero di GPU disponibili\n",
        "        gpu_count = torch.cuda.device_count()\n",
        "        print(f\"\\nNumero di GPU disponibili: {gpu_count}\")\n",
        "\n",
        "        # Informazioni per ogni GPU\n",
        "        for i in range(gpu_count):\n",
        "            print(f\"\\nDettagli GPU {i}:\")\n",
        "            print(f\"Nome: {torch.cuda.get_device_name(i)}\")\n",
        "            print(f\"Memoria totale: {torch.cuda.get_device_properties(i).total_memory / 1024**2:.0f} MB\")\n",
        "            print(f\"Compute capability: {torch.cuda.get_device_properties(i).major}.{torch.cuda.get_device_properties(i).minor}\")\n",
        "\n",
        "        # GPU corrente\n",
        "        print(f\"\\nGPU corrente: {torch.cuda.current_device()}\")\n",
        "\n",
        "        # Versione CUDA\n",
        "        print(f\"Versione CUDA: {torch.version.cuda}\")\n",
        "\n",
        "    # Versione PyTorch\n",
        "    print(f\"\\nVersione PyTorch: {torch.__version__}\")\n",
        "    print(f\"Versione Python: {sys.version.split()[0]}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    get_gpu_info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YSejMFpcFPu",
        "outputId": "32fe5743-91e7-4307-e192-765f8f6f95f6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA è disponibile: True\n",
            "\n",
            "Numero di GPU disponibili: 1\n",
            "\n",
            "Dettagli GPU 0:\n",
            "Nome: Tesla T4\n",
            "Memoria totale: 15102 MB\n",
            "Compute capability: 7.5\n",
            "\n",
            "GPU corrente: 0\n",
            "Versione CUDA: 12.1\n",
            "\n",
            "Versione PyTorch: 2.5.1+cu121\n",
            "Versione Python: 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Ottieni il percorso corrente\n",
        "current_path = os.getcwd()\n",
        "print(current_path)\n",
        "\n",
        "# Cambia directory\n",
        "os.chdir('AML2024/PIDNet')\n",
        "\n",
        "# Ottieni il nuovo percorso\n",
        "current_path = os.getcwd()\n",
        "print(current_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-bSgnhGc3g0",
        "outputId": "c5656446-662f-4406-d2d2-cf794f32d384"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/AML2024/PIDNet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bisongna aggiungere AML2024/PIDNet/ a un po di path"
      ],
      "metadata": {
        "id": "1gBzZfa2fFxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ottieni il nuovo percorso\n",
        "current_path = os.getcwd()\n",
        "print(current_path)\n",
        "!python tools/train.py --cfg configs/loveda/pidnet_small_loveda.yaml GPUS \"[0]\" TRAIN.BATCH_SIZE_PER_GPU 6\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vhny-u4YTe25",
        "outputId": "4c69fd5d-7b9c-4ef7-a300-f269e812a6fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AML2024/PIDNet\n",
            "Seeding with 304\n",
            "=> creating output/loveDa/pidnet_small_loveda\n",
            "=> creating log/loveDa/pidnet_small/pidnet_small_loveda_2025-01-04-09-10\n",
            "Namespace(cfg='configs/loveda/pidnet_small_loveda.yaml', seed=304, opts=['GPUS', '[0]', 'TRAIN.BATCH_SIZE_PER_GPU', '6'])\n",
            "AUTO_RESUME: False\n",
            "CUDNN:\n",
            "  BENCHMARK: True\n",
            "  DETERMINISTIC: False\n",
            "  ENABLED: True\n",
            "DATASET:\n",
            "  DATASET: loveDa\n",
            "  EXTRA_TRAIN_SET: \n",
            "  NUM_CLASSES: 8\n",
            "  ROOT: data/\n",
            "  TEST_SET: list/loveDa/val.lst\n",
            "  TRAIN_SET: list/loveDa/train.lst\n",
            "GPUS: (0,)\n",
            "LOG_DIR: log\n",
            "LOSS:\n",
            "  BALANCE_WEIGHTS: [0.4, 1.0]\n",
            "  CLASS_BALANCE: False\n",
            "  OHEMKEEP: 131072\n",
            "  OHEMTHRES: 0.7\n",
            "  SB_WEIGHTS: 0.5\n",
            "  USE_OHEM: True\n",
            "MODEL:\n",
            "  ALIGN_CORNERS: True\n",
            "  NAME: pidnet_small\n",
            "  NUM_OUTPUTS: 2\n",
            "  PRETRAINED: pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar\n",
            "OUTPUT_DIR: output\n",
            "PIN_MEMORY: True\n",
            "PRINT_FREQ: 10\n",
            "TEST:\n",
            "  BASE_SIZE: 2048\n",
            "  BATCH_SIZE_PER_GPU: 20\n",
            "  FLIP_TEST: False\n",
            "  IMAGE_SIZE: [1024, 1024]\n",
            "  MODEL_FILE: \n",
            "  MULTI_SCALE: False\n",
            "  OUTPUT_INDEX: 1\n",
            "TRAIN:\n",
            "  BASE_SIZE: 2048\n",
            "  BATCH_SIZE_PER_GPU: 6\n",
            "  BEGIN_EPOCH: 1\n",
            "  END_EPOCH: 20\n",
            "  EXTRA_EPOCH: 0\n",
            "  EXTRA_LR: 0.001\n",
            "  FLIP: True\n",
            "  IGNORE_LABEL: 0\n",
            "  IMAGE_SIZE: [1024, 1024]\n",
            "  LR: 0.01\n",
            "  MOMENTUM: 0.9\n",
            "  MULTI_SCALE: True\n",
            "  NESTEROV: False\n",
            "  OPTIMIZER: sgd\n",
            "  RESUME: False\n",
            "  SCALE_FACTOR: 16\n",
            "  SHUFFLE: True\n",
            "  WD: 0.0005\n",
            "WORKERS: 0\n",
            "/content/AML2024/PIDNet/tools/../models/pidnet.py:194: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  pretrained_state = torch.load(cfg.MODEL.PRETRAINED, map_location='cpu')['state_dict']\n",
            "Attention!!!\n",
            "Loaded 302 parameters!\n",
            "Over!!!\n",
            "Epoch: [0/20] Iter:[0/192], Time: 12.78, lr: [0.01], Loss: 5.791713, Acc:0.134423, Semantic loss: 0.641518, BCE loss: 4.903901, SB loss: 0.246295\n",
            "Epoch: [0/20] Iter:[10/192], Time: 2.80, lr: [0.009976559445324192], Loss: 3.629312, Acc:0.230979, Semantic loss: 0.563902, BCE loss: 2.862471, SB loss: 0.202940\n",
            "Epoch: [0/20] Iter:[20/192], Time: 2.28, lr: [0.009953112769592761], Loss: 3.167342, Acc:0.267311, Semantic loss: 0.528253, BCE loss: 2.452799, SB loss: 0.186290\n",
            "Epoch: [0/20] Iter:[30/192], Time: 2.10, lr: [0.009929659955177281], Loss: 2.858850, Acc:0.301587, Semantic loss: 0.485113, BCE loss: 2.208170, SB loss: 0.165567\n"
          ]
        }
      ]
    }
  ]
}